{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#notes-and-code-command-lines-snippets","title":"Notes and code / command lines snippets","text":"<p>This repo contains my technical notes.</p> <p>It is available at https://notes.volted.net</p>"},{"location":"#deploy-with-podman-tested-under-fedora","title":"Deploy with podman (tested under Fedora)","text":"<p><code>cd</code> to repo root:</p> <pre><code>podman run --rm -it -p 8000:8000 -v ${PWD}:/docs:Z squidfunk/mkdocs-material:latest\n</code></pre> <p>to start devel server and display site at http://localhost:8000</p> <p>To build the doc</p> <pre><code>podman run --rm -it -v ${PWD}:/docs:Z squidfunk/mkdocs-material:latest build\n</code></pre>"},{"location":"Desktop/Manage_Dotfiles_with_Git/","title":"Manage Dotfiles with Git","text":""},{"location":"Desktop/Manage_Dotfiles_with_Git/#git-comes-to-rescue","title":"Git comes to rescue","text":"<p>In this example, we will use <code>$HOME/Dotfiles</code> as the Git repository, but feel free to change it to your needs.</p> <p>First of all, we will initialize this repository</p> <pre><code>git init --bare $HOME/Dotfiles\n</code></pre> <p>Then, as all the <code>git</code> commands that we will use will refer to this repository, it is advised to create an alias, such as:</p> <pre><code>alias dotfiles='/usr/bin/git --git-dir=$HOME/Dotfiles --work-tree=$HOME'\n</code></pre> <p>You can add this line to your $SHELL configuration file (<code>$HOME/.bashrc</code> if you use Bash or <code>$HOME/.zshrc</code> if you use zsh).</p> <p>Next, we will configure Git so it will not show all the untracked files. This is required as we use the entire <code>$HOME</code> as work tree.</p> <pre><code>dotfiles config --local status.showUntrackedFiles no\n</code></pre> <p>At that point, you should be able to check the state of this repository:</p> <pre><code>dotfiles status\n</code></pre> <p>Then you can add your configuration files and commit as you wish. For example, let\u2019s add our <code>.bashrc</code> :</p> <pre><code>dotfiles add .bashrc\ndotfiles commit -m \"Added .bashrc\"\n</code></pre> <p>Now just add a remote repository (your self-hosted Git or a public one) and push your changes to it:</p> <pre><code>dotfiles remote add origin git@gitlab.domain.tld:sogal/dotfiles.git\ndotfiles push\n</code></pre>"},{"location":"Desktop/Manage_Dotfiles_with_Git/#setup-a-new-machine","title":"Setup a new machine","text":"<p>Now that you have it all set, let\u2019s configure a new system with the dotfiles you have in your repository.</p> <p>First, clone locally your online repository:</p> <pre><code>git clone --bare git@gitlab.domain.tld:sogal/dotfiles.git $HOME/Dotfiles\n</code></pre> <p>Again, you have to defined the same alias as before:</p> <pre><code>alias dotfiles='/usr/bin/git --git-dir=$HOME/Dotfiles --work-tree=$HOME'\n</code></pre> <p>Remember to put it in your $SHELL configuration file. Now, just apply the changes from the repository you have just cloned to your system:</p> <pre><code>dotfiles checkout\n</code></pre> <p>If some of the files already exist, you will get an error. This will probably happen with files created by default during the openSUSE installation and user account creation, such as the <code>$HOME/.bashrc</code> file, no worries, just rename or delete them.</p> <p>Now, each time you change your configuration files tracked by Git, remember to commit and push your changes.</p>"},{"location":"Desktop/Pulseaudio%26Bluetooth/","title":"Pulseaudio&Bluetooth","text":"<p>In case of trouble with bluetooth devices and PA sound output</p> <p>Edit the file:</p> <pre><code>/etc/pulse/default.pa\n</code></pre> <p>and comment out (with an # at the beginning of the line) the following line:</p> <pre><code>load-module module-bluetooth-discover\n</code></pre> <p>now edit the file:</p> <pre><code>/usr/bin/start-pulseaudio-x11\n</code></pre> <p>and after the lines:</p> <pre><code>if [ x\u201d$SESSION_MANAGER\u201d != x ] ; then\n    /usr/bin/pactl load-module module-x11-xsmp \u201cdisplay=$DISPLAY session_manager=$SESSION_MANAGER\u201d &gt; /dev/null\nfi\n</code></pre> <p>add the following line:</p> <pre><code>/usr/bin/pactl load-module module-bluetooth-discover\n</code></pre> <p>Dans le fichier :</p> <pre><code>/etc/bluetooth/main.conf\n</code></pre> <p>Changer</p> <pre><code>ControllerMode = dual\n</code></pre> <p>en :</p> <pre><code>ControllerMode = bredr\n</code></pre> <p>Si probl\u00e8me avec gDM:</p> <pre><code>/var/lib/gdm/.pulse/client.conf\nautospawn = no\ndaemon-binary = /bin/true\n</code></pre>","tags":["desktop","cli"]},{"location":"Desktop/Sync_Github_fork/","title":"Syncing a Github fork","text":"<p>Before you can sync your fork with an upstream repository, you must configure a remote that points to the upstream repository in Git.</p> <ul> <li> <p>Open Terminal.</p> </li> <li> <p>Change the current working directory to your local project.</p> </li> <li> <p>Fetch the branches and their respective commits from the upstream repository. Commits to master will be stored in a local branch, upstream/master.</p> <pre><code>git fetch upstream\n\n&gt; remote: Counting objects: 75, done.\n&gt; remote: Compressing objects: 100% (53/53), done.\n&gt; remote: Total 62 (delta 27), reused 44 (delta 9)\n&gt; Unpacking objects: 100% (62/62), done.\n&gt; From https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY\n&gt;  * [new branch]      master     -&gt; upstream/master\n</code></pre> </li> <li> <p>Check out your fork\u2019s local master branch.</p> <pre><code>git checkout master\n\n&gt; Switched to branch 'master'\n</code></pre> </li> <li> <p>Merge the changes from upstream/master into your local master branch. This brings your fork\u2019s master branch into sync with the upstream repository, without losing your local changes.</p> <pre><code>git merge upstream/master\n\n&gt; Updating a422352..5fdff0f\n&gt; Fast-forward\n&gt;  README                    |    9 -------\n&gt;  README.md                 |    7 ++++++\n&gt;  2 files changed, 7 insertions(+), 9 deletions(-)\n&gt;  delete mode 100644 README\n&gt;  create mode 100644 README.md\n</code></pre> </li> </ul> <p>If your local bran ch didn\u2019t have any unique commits, Git will instead perform a \u201cfast-forward\u201d:</p> <pre><code>    git merge upstream/master\n\n    &gt; Updating 34e91da..16c56ad\n    &gt; Fast-forward\n    &gt;  README.md                 |    5 +++--\n    &gt;  1 file changed, 3 insertions(+), 2 deletions(-)\n</code></pre> <p>Tip</p> <p>Syncing your fork only updates your local copy of the repository. To update your fork on GitHub, you must push your changes.</p>","tags":["cli","git"]},{"location":"Docker/Container_backup/","title":"Container backup","text":"","tags":["docker","backup"]},{"location":"Docker/Container_backup/#docker-container-backup","title":"Docker container backup","text":"<p>This config will describe a procedure of how to back up a Docker container as well as it will also show how to recover a Docker container from backup.</p> <p>To understand the Docker container backup and recovery process we first need to understand the difference between docker image and docker container. A docker image contains an operating system with possibly one or more prefigured applications. Whereas, a docker container is a running instance created from an image.</p> <p>When we need make a backup of a docker container we commit its current state and save it as a docker image.</p> <pre><code>docker ps\n\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\n78727078a04b        debian:8            \"/bin/bash\"         13 seconds ago      Up 11 seconds                           container1\n</code></pre> <p>From the above output we see a running docker container named container1 with an ID 78727078a04b. We now use commit command to take a snapshot of its current running state:</p> <pre><code>docker commit -p  78727078a04b  container1\n\ne09f9ac65c8b3095927c14ca0594868f73831bde0800ce66415afeb91aea93cf\n</code></pre> <p>With do above command we have first paused a running container with -p option, made a commit to save the entire snapshot as a docker image with a name container1:</p> <pre><code>docker images\nREPOSITORY                      TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\ncontainer1                      latest              e09f9ac65c8b        39 seconds ago      125.1 MB\n</code></pre> <p>Now we have a container backup saved as an image waiting to be redeployed again. If we wish to redeploy our container1 image on another docker host system we may push the image to some private docker repository:</p> <pre><code>docker login\ndocker push container1\n</code></pre> <p>or we can save it as a tar file and move it freely to any desired docker host system for a deployment:</p> <pre><code>docker save -o ~/container1.tar container1\n\nls -l ~/container1.tar\n-rw-r--r--. 1 root root 131017216 Jun 14 20:31 /root/container1.tar\n</code></pre>","tags":["docker","backup"]},{"location":"Docker/Container_backup/#docker-container-recovery","title":"Docker container recovery","text":"<p>The above paragraphs explained how to backup a docker container. In this section we will discuss how recover from a docker backup.</p> <p>In case that we have pushed our backed up docker container image to a private repository we can simply use docker run command to start a new instance from the container1 image. If we have transferred our container1.tar backup file to another docker host system we first need to load backed up tar file into a docker\u2019s local image repository:</p> <pre><code>docker load -i /root/container1.tar\n</code></pre> <p>Confirm that the image was loaded with:</p> <pre><code>docker images\n</code></pre> <p>Now we can use docker run command to start a new instance from the above loaded container1 image.</p>","tags":["docker","backup"]},{"location":"Docker/Databases_backup/","title":"Databases backup","text":"","tags":["docker","db"]},{"location":"Docker/Databases_backup/#postgres-db","title":"Postgres DB","text":"<pre><code>docker exec -t your-db-container pg_dumpall -c -U postgres  | gzip &gt; dump_`date +%d-%m-%Y\"_\"%H_%M_%S`.sql\n</code></pre>","tags":["docker","db"]},{"location":"Docker/Databases_backup/#restore-your-databases","title":"Restore your databases","text":"<pre><code>cat your_dump.sql | docker exec -i your-db-container psql -U postgres\n</code></pre>","tags":["docker","db"]},{"location":"Docker/Databases_backup/#with-mysql","title":"With mySQL","text":"<pre><code>cat dump.sql | docker-compose exec -T &lt;mysql_container&gt; mysql -u &lt;db-username&gt; -p&lt;db-password&gt; &lt;db-name&gt;\n</code></pre>","tags":["docker","db"]},{"location":"Docker/General_use/","title":"General use","text":"","tags":["docker"]},{"location":"Docker/General_use/#remove-image","title":"Remove image","text":"<pre><code>docker rmi $image_id\n</code></pre>","tags":["docker"]},{"location":"Docker/General_use/#get-img-size","title":"Get img size","text":"<pre><code>docker image inspect img/name:label --format='{{.Size}}'\n</code></pre>","tags":["docker"]},{"location":"Docker/General_use/#build-image","title":"Build image","text":"<pre><code>docker build --label myLabel --tag myTag:latest path/to/Dockerfile\n</code></pre>","tags":["docker"]},{"location":"Docker/General_use/#tag-for-remote-repo","title":"Tag for remote repo","text":"<pre><code>docker tag myTag:version git.server.tld:5000/myTag:version\ndocker push git.server.tld:5000/myTag:version\n</code></pre>","tags":["docker"]},{"location":"Docker/Tips/","title":"General Docker Tips and issues solutions","text":""},{"location":"Docker/Tips/#this-fixes-the-input-device-is-not-a-tty-see-httpsgithubcomdockercomposeissues5696","title":"This fixes the input device is not a TTY .. see https://github.com/docker/compose/issues/5696","text":"<pre><code>export COMPOSE_INTERACTIVE_NO_CLI=1\n</code></pre>"},{"location":"Docker/Tips/#address-a-container-in-swarm-mode","title":"Address a container in swarm mode","text":"<pre><code>SERVICE_NAME=${DEPLOY_STACK}\n# Get deployed service information as json output\nSERVICE_JSON=$(docker service ps $SERVICE_NAME --no-trunc --format '{{ json . }}' -f desired-state=running)\n# Parse the output, get swarm node on which service has been deployed\nSWARM_NODE=$(echo \"$SERVICE_JSON\" | jq -r '.Node')\n\n# Wait just to give time for service to be deployed\nsleep 10\n\n# Get container ID and run command via SSH on the swarm node\nssh -t $SWARM_NODE \"docker exec -it $(echo $SERVICE_JSON | jq -r '.Name').$(echo $SERVICE_JSON | jq -r '.ID') make permissions\"\n</code></pre>"},{"location":"Docker/Tips/#have-env-vars-exported-when-deploying-a-stack","title":"Have <code>.env</code> vars exported when deploying a stack","text":"<pre><code>docker-compose config | docker stack deploy --compose-file - &lt;STACK_NAME&gt;\n</code></pre> <p>If there is a <code>.env</code> entry in the compose file, it will be read and vars replaced in the compose file.</p>"},{"location":"Filesystems/Filesystems_tricks/","title":"Filesystems tricks","text":"","tags":["filesystem"]},{"location":"Filesystems/Filesystems_tricks/#step-1-find-inode-number-of-any-file-using-following-command-on-terminal","title":"Step 1: Find inode number of any file using following command on terminal.","text":"<pre><code>ls -i /var/log/messages 13377 /var/log/messages\n</code></pre>","tags":["filesystem"]},{"location":"Filesystems/Filesystems_tricks/#step-2-find-file-creation-time-crtime","title":"Step 2: Find File Creation Time (crtime)","text":"<pre><code>debugfs -R 'stat &lt;inode_number&gt;' /dev/sda1\n</code></pre>","tags":["filesystem"]},{"location":"Filesystems/Filesystems_tricks/#clean-an-inconsistent-ntfs-volume","title":"Clean an inconsistent NTFS volume","text":"<pre><code>ntfsfix /dev/sdX1\n</code></pre>","tags":["filesystem"]},{"location":"Filesystems/GlusterFS/","title":"GlusterFS","text":"<p>source</p>","tags":["fs","server","linux"]},{"location":"Filesystems/GlusterFS/#glusterfs","title":"GlusterFS","text":"<p>GlusterFS  est un syst\u00e8me de fichiers r\u00e9seau client/serveur permettant d\u2019agr\u00e9ger  diff\u00e9rents n\u0153uds de stockage afin de fournir un environnement NAS  hautement disponible.</p>","tags":["fs","server","linux"]},{"location":"Filesystems/GlusterFS/#pour-quoi-faire","title":"Pour quoi faire\u00a0?","text":"<p>Admettons que  j\u2019ai une application Web lambda, je vais pouvoir d\u00e9ployer plusieurs  instances Apache ou Nginx qui se trouveront derri\u00e8re un \u00e9quilibreur de  charge, lui-m\u00eame hautement disponible. Sur chaque instance de serveur  Web, il me sera facile de d\u00e9ployer l\u2019application. Toutefois chaque  instance aura besoin d\u2019acc\u00e9der \u00e0 des fichiers communs, g\u00e9n\u00e9r\u00e9s ou non  par l\u2019application. Bien souvent, je vais rencontrer dans ce cas un  serveur NFS qui va donc lui-m\u00eame constituer un point de faiblesse dans  l\u2019architecture. Gluster permet de mettre en cluster plusieurs  n\u0153uds de stockage (\u00e0 minima deux), ce qui permet de r\u00e9pondre \u00e0 deux  probl\u00e9matiques majeures d\u00e8s qu\u2019une application a besoin de pouvoir  monter en charge\u00a0: la parall\u00e9lisation et la r\u00e9plication du stockage.  Pour fournir ces fonctionnalit\u00e9s sur un volume, une \u00ab\u00a0brick\u00a0\u00bb en langage  Gluster, le syst\u00e8me s\u2019appuie sur des syst\u00e8mes de fichiers  traditionnels, XFS ou EXT4 au-dessus d\u2019un p\u00e9riph\u00e9rique en mode bloc  (partition, LVM, RAID, etc..). Gluster travaille donc principalement au  niveau fichier. Contrairement \u00e0 un certain nombre d\u2019autres  syst\u00e8mes de fichiers de ce type, Gluster offre l\u2019immense avantage de ne  pas n\u00e9cessiter de serveur de m\u00e9ta donn\u00e9es pour fonctionner. De fait,  cette absence ne constitue pas un point de faiblesse ou un \u00e9l\u00e9ment  suppl\u00e9mentaire \u00e0 maintenir dans l\u2019infrastructure de stockage. De plus,  chaque fois que l\u2019on ajoute un n\u0153ud au cluster, le syst\u00e8me devient plus  performant et l\u2019augmentation de la performance est lin\u00e9aire avec  l\u2019extension de l\u2019infrastructure. Dernier point pour mettre en \u00e9vidence  cette simplicit\u00e9 de conception, il n\u2019existe pas de notion de ma\u00eetre ou  d\u2019esclave avec GlusterFS.</p>","tags":["fs","server","linux"]},{"location":"Filesystems/GlusterFS/#les-volumes-glusterfs","title":"Les volumes GlusterFS","text":"<p>Un  volume est une agr\u00e9gation de plusieurs bricks r\u00e9partis sur diff\u00e9rents  n\u0153uds de stockage. Le choix du type de volume se fait en fonction des  attentes de performances, de s\u00e9curit\u00e9 ou de la combinaison des deux.  Voyons les types de volumes standards, sachant qu\u2019il existe des modes  g\u00e9o-r\u00e9pliqu\u00e9s, stripp\u00e9s ou bas\u00e9s sur l\u2019erasure coding pour des workflows  sp\u00e9cifiques.</p>","tags":["fs","server","linux"]},{"location":"Filesystems/GlusterFS/#volume-distribue","title":"Volume distribu\u00e9","text":"<p>Ce mode est le mode  par d\u00e9faut de GlusterFS. Les fichiers sont r\u00e9partis sur l\u2019ensemble des  bricks du volume sans redondance aucune. Par cons\u00e9quent, lors de la  perte d\u2019un n\u0153ud, les donn\u00e9es de celui-ci sont perdues et il faudra se  baser sur des m\u00e9canismes compl\u00e9mentaires pour assurer la reprise apr\u00e8s  incident. La volum\u00e9trie utile est celle de l\u2019ensemble des n\u0153uds du  cluster Ce mode permet une croissance ais\u00e9e de la volum\u00e9trie en ajoutant  simplement des n\u0153uds au volume. Il faut donc au minimum deux n\u0153uds, et  la distribution peut se faire sur autant de n\u0153uds du cluster (voir  figure 1).</p>","tags":["fs","server","linux"]},{"location":"Filesystems/GlusterFS/#volume-replique","title":"Volume r\u00e9pliqu\u00e9","text":"<p>Ce  mode permet de r\u00e9pondre au probl\u00e8me de la s\u00e9curit\u00e9 de la donn\u00e9e pos\u00e9  par le mode distribu\u00e9. Dans ce mode op\u00e9ratoire, le syst\u00e8me maintient n  copies de chaque fichier au sein des \u00ab\u00a0bricks\u00a0\u00bb sp\u00e9cifi\u00e9es. Il faut donc  autant de n\u0153uds au cluster que de r\u00e9plicas d\u00e9sir\u00e9s. De la m\u00eame fa\u00e7on  que sur du RAID1, la volum\u00e9trie utile est la moiti\u00e9 de la volum\u00e9trie  allou\u00e9e (voir figure 2).</p>","tags":["fs","server","linux"]},{"location":"Filesystems/GlusterFS/#volume-distribue-replique","title":"Volume distribu\u00e9 r\u00e9pliqu\u00e9","text":"<p>Vous  l\u2019aurez compris, ce mode est une combinaison des deux modes pr\u00e9c\u00e9dents.  Cela permet de traiter des workflows n\u00e9cessitant disponibilit\u00e9 et  capacit\u00e9 \u00e0 monter en charge. Le nombre de bricks n\u00e9cessaires est un  multiple du niveau de r\u00e9plication attendu. De plus, la r\u00e9plication entre  les bricks est d\u00e9finie par leur ordre de d\u00e9claration \u00e0 la cr\u00e9ation du  volume. Pour quatre bricks avec deux r\u00e9plicas, les deux premi\u00e8res bricks  r\u00e9pliquent ensemble et de m\u00eame pour les deux suivantes (voir figure 3).  Si nous souhaitions quatre r\u00e9plicas, il nous faudrait donc huit bricks  et les quatre premi\u00e8res r\u00e9pliqueraient entre elles.</p>","tags":["fs","server","linux"]},{"location":"Filesystems/GlusterFS/#lenvironnement","title":"L\u2019environnement","text":"<p>GlusterFS  est assez agnostique par rapport \u00e0 l\u2019environnement et \u00e0 la  distribution. Pour ma part, les d\u00e9monstrations suivantes seront toutes  r\u00e9alis\u00e9es sous Ubuntu 16.04. Un point indispensable \u00e9tant que les n\u0153uds  soient capables de discuter par leur nom, qu\u2019il soit r\u00e9solu par DNS ou  par le fichier hosts, mais pas par adresse IP. Pour la suite, je  partirai sur deux VMs stor0 et stor1 afin de monter un cluster \u00e0 deux n\u0153uds. Chaque  serveur dispose d\u2019un second disque virtuel de 10 Gio pour la  d\u00e9monstration. Le p\u00e9riph\u00e9rique doit par contre imp\u00e9rativement disposer  d\u2019un syst\u00e8me de fichiers supportant les attributs \u00e9tendus, ext4 ou XFS  sachant qu\u2019XFS est de loin le syst\u00e8me de fichiers recommand\u00e9. La  convention de nommage veut, mais n\u2019impose pas, que les donn\u00e9es soient  plac\u00e9es dans /data/glusterfs/volume/brick. La cr\u00e9ation des volumes peut se faire simplement comme ceci\u00a0:</p> <pre><code>apt-get -y install lvm2 acl attr xfsprogs\n$(echo o; echo n; echo p; echo 1; echo ; echo; echo t; echo 8E; echo w) | fdisk /dev/sdb\npvcreate /dev/sdb1\nvgcreate VG-Brick0 /dev/sdb1\nlvcreate -l 100%VG -n LV-Brick0 VG-Brick0\nmkfs.xfs -i size=512 -L Brick0 /dev/VG-Brick0/LV-Brick0\nmkdir -p /data/glusterfs/vol0/\necho \"/dev/VG-Brick0/LV-Brick0 /data/glusterfs/vol0/ xfs defaults 1 2\" &gt;&gt; /etc/fstab\nmount /data/glusterfs/vol0/\nmkdir /data/glusterfs/vol0/brick0\n</code></pre> <p>Le LVM n\u2019est pas obligatoire, mais s\u2019y tenir permet d\u2019avoir les  bons r\u00e9flexes pour de la production. Pour le reste, l\u2019installation des  packages est tr\u00e8s simple, cette simple commande suffit\u00a0:</p> <p>apt-get -y install glusterfs-server</p> <p>Par  souci de simplification, aucun pare-feu n\u2019est activ\u00e9 sur les  diff\u00e9rentes machines. Point de vigilance, il ne faudra pas cloner les  machines avec le disque de donn\u00e9es suppl\u00e9mentaire.</p>","tags":["fs","server","linux"]},{"location":"Filesystems/GlusterFS/#le-trusted-pool","title":"Le trusted pool","text":"<p>Avant  d\u2019\u00eatre en mesure de g\u00e9rer des volumes de stockage, les membres d\u2019un  cluster GlusterFS doivent se reconna\u00eetre entre eux et faire partie d\u2019un  m\u00eame trusted pool. Tant que cette op\u00e9ration n\u2019est pas r\u00e9alis\u00e9e, il n\u2019est  pas possible pour un h\u00f4te de joindre le r\u00e9seau de stockage. Pour cela,  c\u2019est tr\u00e8s simple, il suffit depuis un n\u0153ud de sonder avec la commande  gluster peer probe d\u2019ajouter les autres n\u0153uds\u00a0:</p> <pre><code>root@stor1:~# gluster peer probe stor0\npeer probe: success.\n</code></pre> <p>Pour v\u00e9rifier\u00a0:</p> <pre><code>root@stor1:~# gluster peer status\n\nNumber of Peers: 1\nHostname: stor0\nUuid: a920b020-9e5a-46f6-b073-1cc8ec00ba0e\nState: Peer in Cluster (Connected)\n</code></pre>","tags":["fs","server","linux"]},{"location":"Filesystems/GlusterFS/#un-volume-replique","title":"Un volume r\u00e9pliqu\u00e9","text":"<p>On  va poursuivre notre itin\u00e9raire au sein de GlusterFS en cr\u00e9ant un volume  r\u00e9pliqu\u00e9 \u00e0 deux n\u0153uds. J\u2019ai donn\u00e9 en introduction un exemple bas\u00e9 sur  des attentes de haute disponibilit\u00e9 du stockage, il me semble pertinent  de poursuivre sur cet exemple qui parlera sans doute davantage. Notre  cluster ayant deux n\u0153uds, avec conservation de deux copies, cela nous  fait donc un syst\u00e8me en miroir. Sur chaque serveur, on indique le  dossier dans lequel se trouvent les donn\u00e9es. Par s\u00e9curit\u00e9, il est  pr\u00e9conis\u00e9 de cr\u00e9er le volume dans un sous-r\u00e9pertoire du point de montage  afin qu\u2019en cas d\u2019\u00e9chec de montage du volume, cela n\u2019ait pas d\u2019incidence  sur la r\u00e9plication gluster. Du fait du risque d\u2019avoir un dossier vide  sur un membre du cluster lors du d\u00e9marrage des services, le comportement  ne serait pas forc\u00e9ment pr\u00e9visible.</p> <pre><code>root@stor1:~# gluster volume create repl-vol replica 2 transport tcp stor0:/data/glusterfs/vol0/brick0/ stor1:/data/glusterfs/vol0/brick0/\n\nvolume create: repl-vol: success: please start the volume to access data\nroot@stor1:~# gluster volume start repl-vol\nvolume start: repl-vol: success\n</code></pre> <p>On peut donc v\u00e9rifier que tout  est en ordre avec la commande ci-dessous. Le volume doit \u00eatre marqu\u00e9  comme online sur l\u2019ensemble des n\u0153uds\u00a0:</p> <pre><code>root@stor1:~# gluster volume status\nStatus of volume: repl-vol\n\nGluster process\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 TCP Port\u00a0 RDMA Port\u00a0 Online\u00a0 Pid\n------------------------------------------------------------------------------\nBrick stor0:/data/glusterfs/vol0/brick0\u00a0\u00a0\u00a0\u00a0 49152\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Y\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 2536\nBrick stor1:/data/glusterfs/vol0/brick0\u00a0\u00a0\u00a0\u00a0 49152\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Y\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 2338\nNFS Server on localhost\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 2049\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Y\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 2359\nSelf-heal Daemon on localhost\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a0\u00a0\u00a0\u00a0\u00a0N/A\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 N/A\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Y\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 2364\nNFS Server on stor0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 2049\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Y\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 2557\nSelf-heal Daemon on stor0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 N/A\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 N/A\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Y\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 2562\nTask Status of Volume repl-vol\n------------------------------------------------------------------------------\nThere are no active volume tasks\n</code></pre>","tags":["fs","server","linux"]},{"location":"Filesystems/GlusterFS/#connexion-dun-client","title":"Connexion d\u2019un client","text":"<p>Il existe trois m\u00e9canismes d\u2019acc\u00e8s principaux c\u00f4t\u00e9 client\u00a0: \u2013  le client natif acc\u00e9d\u00e9 au travers de FUSE, le syst\u00e8me permettant de  cr\u00e9er des pilotes de filesystem au niveau userland. Il suffit pour cela  d\u2019installer les packages n\u00e9cessaires. \u2013 via NFS, Gluster  imp\u00e9mentant nativement le support NFS. Si vous avez \u00e9t\u00e9 vigilant lors de  l\u2019installation du package glusterfs-server, vous avez s\u00fbrement remarqu\u00e9  certaines d\u00e9pendances. Le serveur NFS n\u2019est pas activ\u00e9 par d\u00e9faut  cependant. \u2013 en CIFS, avec un serveur Samba. Dans les deux  derniers cas, il est souhaitable d\u2019associer les serveurs \u00e0 un syst\u00e8me de  type CTDB pour fournir de la haute disponibilit\u00e9. NFS et Samba ne  savent en effet pas tirer parti de l\u2019ensemble des fonctionnalit\u00e9s  contrairement au client natif. Connectons donc un premier client\u00a0:</p> <pre><code>apt-get -y install glusterfs-client\nmkdir /data\nmount -t glusterfs stor1:/repl-vol /data\n</code></pre> <p>Cr\u00e9ons un fichier al\u00e9atoire avec par exemple la commande ci-dessous.</p> <pre><code>dd if=/dev/urandom of=/data/toto bs=1024 count=10240\n</code></pre> <p>Pour  confirmer que la r\u00e9plication est fonctionnelle, il suffit de v\u00e9rifier  avec une simple commande ls que le fichier est pr\u00e9sent sur les bricks de  chacun des deux serveurs GlusterFS\u00a0:</p> <pre><code>ls -l /data/glusterfs/vol0/brick0/toto\n-rw-r--r-- 2 root root 10485760 sept.\u00a0 9 19:58 /data/glusterfs/vol0/brick0/toto\n</code></pre> <p>Un  point qui a d\u00fb vous surprendre est la commande de montage. On a en  effet explicitement sp\u00e9cifi\u00e9 l\u2019un des serveurs alors que l\u2019on est cens\u00e9  avoir d\u00e9ploy\u00e9 un stockage hautement disponible. En pratique, le client  natif glusterfs ne fait que r\u00e9cup\u00e9rer lors de la commande de mount les  informations de configuration du cluster. Il communiquera directement  avec l\u2019ensemble des serveurs d\u00e9finis dans les volfile (dans le  r\u00e9pertoire /var/lib/glusterd/vols/repl-vol sur les  n\u0153uds de stockage). Un bon moyen de v\u00e9rifier est d\u2019arr\u00eater\u00a0 le n\u0153ud vers  lequel on a r\u00e9alis\u00e9 le montage (un halt -p sur stor1 dans ce cas)\u00a0: le  client doit continuer \u00e0 fonctionner. C\u00f4t\u00e9 client, la perte de connexion  doit \u00eatre visible dans le fichier /var/log/glusterfs/data.log</p> <pre><code>[2017-09-09 18:01:18.933835] W [socket.c:588:__socket_rwv] 0-glusterfs: readv on 192.168.69.61:24007 failed (Aucune donn\u00e9e disponible)\n[2017-09-09 18:01:37.954070] W [socket.c:588:__socket_rwv] 0-repl-vol-client-1: readv on 192.168.69.61:49152 failed (Connexion termin\u00e9e par expiration du d\u00e9lai d'attente)\n</code></pre> <p>Un  point que vous aurez not\u00e9 \u00e9galement, c\u2019est que la bascule n\u2019est pas  imm\u00e9diate. En pratique, le d\u00e9lai est de 42 secondes. Pour ramener ce  d\u00e9lai \u00e0 une valeur plus raisonnable de 5 secondes, modifions notre n\u0153ud  comme suit\u00a0:</p> <pre><code>root@stor1:~# gluster volume set repl-vol network.ping-timeout 5\nvolume set: success\n</code></pre> <p>Ce changement est trac\u00e9 dans le log /var/log/glusterfs/glustershd.log avec une ligne par n\u0153ud comme celle-ci\u00a0:</p> <pre><code>[2017-09-09 18:33:19.591108] I [rpc-clnt.c:1823:rpc_clnt_reconfig] 0-repl-vol-client-0: changing ping timeout to 5 (from 42)\n</code></pre>","tags":["fs","server","linux"]},{"location":"Filesystems/GlusterFS/#un-brin-de-securite","title":"Un brin de s\u00e9curit\u00e9","text":"<p>Jusqu\u2019ici,  on a pu monter le volume simplement en contactant l\u2019un des serveurs du  pool GlusterFS, mais aucune s\u00e9curit\u00e9 suppl\u00e9mentaire n\u2019a \u00e9t\u00e9 impos\u00e9e. Il  est possible de restreindre l\u2019acc\u00e8s \u00e0 notre volume en d\u00e9finissant une  ACL similaire \u00e0 ce qui existe en NFS via le fichier /etc/exports.</p> <pre><code>root@stor2:~# gluster volume set repl-vol auth.allow 192.168.69.104\nvolume set: success\n</code></pre> <p>Il est \u00e9galement possible de d\u00e9finir une  wildcard, par exemple 192.168.69. afin d\u2019autoriser tout un r\u00e9seau. Dans  cet exemple, nous avons autoris\u00e9 explicitement une adresse IP \u00e0 se  connecter au volume. Nous aurions \u00e9galement pu autoriser un nom  d\u2019h\u00f4te ou plusieurs adresses IP ou noms s\u00e9par\u00e9s par des virgules. Le  fait de d\u00e9finir l\u2019attribut auth.allow a comme effet imm\u00e9diat d\u2019interdire  toutes les autres machines qui n\u2019ont pas \u00e9t\u00e9 explicitement autoris\u00e9es.  Pour revenir au comportement par d\u00e9faut, il faut autoriser le caract\u00e8re  wildcard () tout simplement. A l\u2019inverse, l\u2019attribut auth.reject  n\u2019interdit aucune machine par d\u00e9faut (auth.reject avec comme valeur  NONE). Il sert comme vous l\u2019avez devin\u00e9 \u00e0 interdire explicitement une  machine. Pour r\u00e9sumer, le contr\u00f4le d\u2019acc\u00e8s a une logique similaire avec  ce qui existe c\u00f4t\u00e9 TCP Wrappers.</p>","tags":["fs","server","linux"]},{"location":"Filesystems/GlusterFS/#une-corbeille-sur-le-volume","title":"Une corbeille sur le volume","text":"<p>GlusterFS  sait g\u00e9rer une corbeille au niveau volume pour conserver les fichiers  supprim\u00e9s. Le dossier est cr\u00e9\u00e9 automatiquement par gluster et ne peut  \u00eatre supprim\u00e9. Fait int\u00e9ressant, gluster sait si on le lui dit, tirer  parti de cette corbeille pour ses op\u00e9rations internes. Activons donc une  corbeille pour les fichiers de moins de 10 Mio\u00a0:</p> <pre><code>gluster volume set repl-vol features.trash on\ngluster volume set repl-vol features.trash-dir \"Corbeille\"\ngluster volume set repl-vol features.trash-max-filesize 10485760\ngluster volume set repl-vol features.trash-internal-op on\n</code></pre>","tags":["fs","server","linux"]},{"location":"Filesystems/GlusterFS/#node-hs-pas-de-panique","title":"Node HS\u00a0? Pas de panique\u00a0!","text":"<p>Un  incident majeur sur un \u00e9quipement sensible d\u2019un syst\u00e8me d\u2019information,  c\u2019est bien entendu quelque chose auquel on se doit d\u2019\u00eatre pr\u00e9par\u00e9. Dans  un syst\u00e8me hautement disponible, tout \u00e9l\u00e9ment qui n\u2019est pas consid\u00e9r\u00e9  comme un point unique de d\u00e9faillance (SPOF) doit pouvoir \u00eatre  indisponible sans impacter fortement le bon fonctionnement du syst\u00e8me.  Nous nous retrouvons dans un \u00e9tat de fonctionnement d\u00e9grad\u00e9. Si le  syst\u00e8me d\u00e9faillant ne peut \u00eatre d\u00e9pann\u00e9, un processus de reconstruction  doit \u00eatre mis en \u0153uvre. Nous allons consid\u00e9rer que le n\u0153ud stor0  est irr\u00e9m\u00e9diablement d\u00e9faillant, la VM est m\u00eame supprim\u00e9e. Cela se  v\u00e9rifie par la commande suivante\u00a0:</p> <pre><code>root@stor1:~# gluster volume heal repl-vol info\n\nBrick stor0:/data/glusterfs/vol0/brick0\nStatus: Noeud final de transport n'est pas connect\u00e9\nBrick stor1:/data/glusterfs/vol0/brick0\nNumber of entries: 0\n</code></pre> <p>Voyons \u00e9tape par \u00e9tape comment le nouveau  serveur nomm\u00e9 stor2 va prendre de relais de celui-ci. Pour cela, la  premi\u00e8re \u00e9tape que je ne vais pas d\u00e9tailler consiste \u00e0 provisionner un  nouveau serveur avec le disque de donn\u00e9es et les d\u00e9pendances comme  indiqu\u00e9 pr\u00e9c\u00e9demment. Premi\u00e8rement, on ajoute le nouveau n\u0153ud et  on va confirmer qu\u2019on a bien un nouveau n\u0153ud pr\u00e9sent, et un ancien  toujours connu du cluster mais manquant\u00a0:</p> <pre><code>root@stor1:~# gluster peer probe stor2\npeer probe: success.\nroot@stor1:~# gluster peer status\nNumber of Peers: 2\n\nHostname: stor0\nUuid: a920b020-9e5a-46f6-b073-1cc8ec00ba0e\nState: Peer in Cluster (Disconnected)\n\nHostname: stor2\nUuid: f2a03465-11bb-4c2a-a882-22933cfa2d08\nState: Peer in Cluster (Connected)\n</code></pre> <p>Rempla\u00e7ons maintenant la brick du stor0 par celle de notre nouveau serveur stor2 et v\u00e9rifions son \u00e9tat de sant\u00e9\u00a0:</p> <pre><code>root@stor1:~# gluster volume replace-brick repl-vol stor0:/data/glusterfs/vol0/brick0 stor2:/data/glusterfs/vol0/brick0 commit force\nvolume replace-brick: success: replace-brick commit force operation successful\n</code></pre> <p>On r\u00e9concilie le volume :</p> <pre><code>root@stor1:~# gluster volume heal repl-vol full\n\nLaunching heal operation to perform full self heal on volume repl-vol has been successful\nUse heal info commands to check status\nroot@stor1:~# gluster volume heal repl-vol info\nBrick stor2:/data/glusterfs/vol0/brick0\nNumber of entries: 0\nBrick stor1:/data/glusterfs/vol0/brick0\nNumber of entries: 0\n</code></pre> <p>Et depuis le nouveau node, lan\u00e7ons une synchronisation\u00a0:</p> <pre><code>root@stor2:/data/glusterfs/vol0/brick0# gluster volume sync stor1 repl-vol\nSync volume may make data inaccessible while the sync is in progress. Do you want to continue? (y/n) y\n</code></pre> <p>Il  nous reste une derni\u00e8re \u00e9tape\u00a0: r\u00e9pliquer le volume id dans les  attributs \u00e9tendus du syst\u00e8me de fichiers et le propager au second  serveur. Pour le r\u00e9cup\u00e9rer, il faut lancer la commande suivante\u00a0:</p> <pre><code>root@stor1:~# getfattr\u00a0 -n trusted.glusterfs.volume-id /data/glusterfs/vol0/brick0/\ngetfattr: Suppression des \u00ab\u00a0/\u00a0\u00bb en t\u00eate des chemins absolus\n\n# file: data/glusterfs/vol0/brick0/ trusted.glusterfs.volume-id=0seEhN1zXZTFOXmRGV92ibvw==\n</code></pre> <p>Sur le nouveau serveur, on applique l\u2019ID du volume sur la brick\u00a0:</p> <pre><code>root@stor2:/data/glusterfs/vol0/brick0# setfattr -n trusted.glusterfs.volume-id -v '0seEhN1zXZTFOXmRGV92ibvw==' /data/glusterfs/vol0/brick0/\nservice glusterfs-server restart\n</code></pre> <p>La configuration de notre  volume est bien mise \u00e0 jour comme on peut le voir ci-dessous. Dans le  cadre d\u2019un volume distribu\u00e9, il faudrait lancer un r\u00e9\u00e9quilibrage  (rebalance) du volume\u00a0:</p> <pre><code>root@stor1:~# gluster volume info repl-vol\nVolume Name: repl-vol\nType: Replicate\nVolume ID: 1c493043-9c2d-4be6-afcd-8512577342c9\nStatus: Started\nNumber of Bricks: 1 x 2 = 2\nTransport-type: tcp\nBricks:\nBrick1: stor2:/data/glusterfs/vol0/brick0\nBrick2: stor1:/data/glusterfs/vol0/brick0\nOptions Reconfigured:\nperformance.readdir-ahead: on\ncluster.self-heal-daemon: enable\nnetwork.ping-timeout: 5\n</code></pre> <p>Enfin, il ne reste plus qu\u2019\u00e0 retirer l\u2019ancien n\u0153ud des peers autoris\u00e9s dans le trusted pool\u00a0:</p> <pre><code>root@stor1:~# gluster peer detach stor0\npeer detach: success\n\nroot@stor1:~# gluster peer status\nNumber of Peers: 1\nHostname: stor2\nUuid: f2a03465-11bb-4c2a-a882-22933cfa2d08\nState: Peer in Cluster (Connected)\n</code></pre> <p>Il ne doit plus appara\u00eetre dans la liste des n\u0153uds\u00a0:</p> <pre><code>root@stor1:~# gluster pool list\nUUID\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Hostname\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 State\n0cb0f3b6-10e5-41c4-ad7e-cb9ca794db9e\u00a0\u00a0\u00a0 stor2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Connected\nd5ff9617-6989-48ae-be3a-3e1286060ea1\u00a0\u00a0\u00a0 localhost\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Connected\n</code></pre> <p>Vous  savez d\u00e9sormais comment remplacer un n\u0153ud d\u00e9faillant, sachant que ce  processus s\u2019applique \u00e9galement en cas de migration de la brick de stor0 vers un nouveau serveur.</p>","tags":["fs","server","linux"]},{"location":"Filesystems/GlusterFS/#etendre-le-volume","title":"\u00c9tendre le volume","text":"<p>Quand  l\u2019espace disque commence \u00e0 manquer, une premi\u00e8re solution peut \u00eatre  d\u2019\u00e9tendre l\u2019espace libre sur les bricks, d\u2019o\u00f9 l\u2019int\u00e9r\u00eat d\u2019\u00eatre partis au  d\u00e9part sur du LVM. Une autre solution est d\u2019\u00e9tendre le cluster avec de  nouveaux n\u0153uds afin d\u2019am\u00e9liorer la disponibilit\u00e9 du syst\u00e8me dans son  ensemble. Cette extension du cluster se fait en outre sans interruption  de service. Pour \u00e9tendre un cluster r\u00e9pliqu\u00e9, il faut ajouter un  nombre de bricks avec un nombre multiple du nombre de r\u00e9plicas. Nous  avons mont\u00e9 un volume \u00e0 deux r\u00e9plicas, il nous faut donc ajouter deux  bricks suppl\u00e9mentaires. La commande gluster volume info repl-vol nous permet de le confirmer (1\u00d72). Nous allons ajouter donc deux serveurs stor3 et stor4, avec le volume disque pr\u00e9par\u00e9 et le package glusterfs-server install\u00e9. La premi\u00e8re \u00e9tape consiste \u00e0 autoriser les deux n\u0153uds avec la commande gluster peer probe vue pr\u00e9c\u00e9demment. On peut donc ensuite ajouter des bricks au volume en sp\u00e9cifiant les bricks de nos deux nouveaux serveurs\u00a0:</p> <pre><code>root@stor2:~# gluster volume add-brick repl-vol stor3:/data/glusterfs/vol0/brick0 stor4:/data/glusterfs/vol0/brick0\n\nvolume add-brick: success\n</code></pre> <p>V\u00e9rifions notre volume, nous devons retrouver nos deux bricks suppl\u00e9mentaires.</p> <pre><code>root@stor2:~# gluster volume info repl-vol\nVolume Name: repl-vol\nType: Distributed-Replicate\nVolume ID: 78484dd7-35d9-4c53-9799-1195f7689bbf\nStatus: Started\nNumber of Bricks: 2 x 2 = 4\nTransport-type: tcp\nBricks:\nBrick1: stor2:/data/glusterfs/vol0/brick0\nBrick2: stor1:/data/glusterfs/vol0/brick0\nBrick3: stor3:/data/glusterfs/vol0/brick0\nBrick4: stor4:/data/glusterfs/vol0/brick0\nOptions Reconfigured:\nperformance.readdir-ahead: on\n</code></pre> <p>Notre volume \u00e0 deux r\u00e9plicas  comportant quatre n\u0153uds se comporte donc d\u00e9sormais comme un volume  distribu\u00e9 r\u00e9pliqu\u00e9 par la magie de l\u2019extension du volume. Seul probl\u00e8me,  il n\u2019y a aucune donn\u00e9e sur les serveurs stor3 et stor4,  ce qui n\u2019a pas eu pour effet de lib\u00e9rer de l\u2019espace disque sur les deux  premiers serveurs. Il est donc n\u00e9cessaire de r\u00e9partir la volum\u00e9trie sur  l\u2019ensemble des bricks qui composent le volume\u00a0:</p> <pre><code>root@stor2:~# gluster volume rebalance repl-vol start&lt; volume rebalance: repl-vol: success: Rebalance on repl-vol has been started successfully. Use rebalance status command to check status of the rebalance process. \nID: dffbed2e-3a0c-4d7d-9f43-9d978a546b04\n</code></pre> <p>Pour v\u00e9rifier il suffit de lancer la m\u00eame commande avec le param\u00e8tre status\u00a0:</p> <pre><code>root@stor2:~# gluster volume rebalance repl-vol status\nNode Rebalanced-files\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 size\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 scanned \u00a0\u00a0\u00a0\u00a0\u00a0failures\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 skipped\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 status\u00a0\u00a0 run time in secs\n---------\u00a0\u00a0\u00a0\u00a0\u00a0 -----------\u00a0\u00a0 -----------\u00a0\u00a0 -----------\u00a0\u00a0 -----------\u00a0\u00a0 -----------\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 ------------\u00a0\u00a0\u00a0\u00a0 --------------\nlocalhost\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 5\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0Bytes\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 10\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 completed\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 2.00\nstor1\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0Bytes\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 completed \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a01.00\nstor3\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0Bytes\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 2\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 completed\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 1.00\nstor4\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0Bytes\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \u00a00\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 completed\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 1.00\nvolume rebalance: repl-vol: success\n</code></pre>","tags":["fs","server","linux"]},{"location":"Filesystems/GlusterFS/#les-quotas","title":"Les quotas","text":"<p>GlusterFS  dispose d\u2019un m\u00e9canisme permettant de d\u00e9finir des quotas au niveau  dossier. Ils ne sont pas activ\u00e9s par d\u00e9faut. Pour changer ce  comportement\u00a0:</p> <p>root@stor2:~# gluster volume quota repl-vol enable volume quota : success</p> <p>Nous allons appliquer une limite \u00e0 1Gio  sur le sous-dossier subdir de notre volume. Ce dossier devra avoir \u00e9t\u00e9  imp\u00e9rativement cr\u00e9\u00e9 depuis le client glusterfs ajout\u00e9 pr\u00e9c\u00e9demment. Pour  cr\u00e9er ce quota :</p> <pre><code>root@stor2:~# gluster volume quota repl-vol limit-usage /subdir 1GB\nvolume quota : success\n</code></pre> <p>Si nous avions souhait\u00e9 cr\u00e9er un quota au  niveau du volume, il suffit d\u2019indiquer / dans le chemin. Cr\u00e9ons un  fichier approchant le quota depuis notre client GlusterFS\u00a0:</p> <pre><code>root@desktop:/data/subdir# dd if=/dev/zero of=/data/subdir/toto bs=1024 count=1024000\n1024000+0\u00a0enregistrements lus\n1024000+0\u00a0enregistrements \u00e9crits\n1048576000 bytes (1,0 GB, 1000 MiB) copied, 223,044 s, 4,7 MB/s\n</code></pre> <p>Et voyons l\u2019\u00e9tat du quota\u00a0:</p> <p>root@stor1:~# gluster volume quota repl-vol list Path\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Hard-limit\u00a0 Soft-limit\u00a0\u00a0\u00a0\u00a0\u00a0 Used\u00a0 Available\u00a0 Soft-limit exceeded? Hard-limit exceeded?</p> <p>/subdir\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 1.0GB\u00a0\u00a0\u00a0\u00a0 80%(819.2MB) 1000.0MB\u00a0 24.0MB\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 Yes\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 No</p> <p>Reprenons  notre commande pr\u00e9c\u00e9dente, en cr\u00e9ant un fichier au nom diff\u00e9rent, la  cr\u00e9ation est bien interrompue sur le d\u00e9passement de quota hard\u00a0:</p> <pre><code>root@desktop:/data# dd if=/dev/zero of=/data/subdir/tata bs=1024 count=1024000\n\ndd: erreur d'\u00e9criture de '/data/subdir/tata': D\u00e9bordement du quota d'espace disque\ndd: fermeture du fichier de sortie '/data/subdir/tata': D\u00e9bordement du quota d'espace disque\n</code></pre> <p>Il  est difficile d\u2019\u00eatre exhaustif sur un sujet aussi vaste. J\u2019esp\u00e8re  toutefois avoir aiguis\u00e9 votre app\u00e9tit sur GlusterFS et vous avoir donn\u00e9  l\u2019envie de tester ce qui n\u2019a pas \u00e9t\u00e9 d\u00e9taill\u00e9 ici.</p>","tags":["fs","server","linux"]},{"location":"Filesystems/LUKS/","title":"LUKS","text":"","tags":["cli","linux","fs"]},{"location":"Filesystems/LUKS/#change-luks-passphrase","title":"Change LUKS passphrase","text":"<p>Mount the partition and use the following to identified it:</p> <pre><code>blkid | grep \"crypto_LUKS\"\n/dev/sda5: UUID=\"7a805bed-e309-44e0-8dfa-6994a13d29a1\" TYPE=\"crypto_LUKS\" PARTUUID=\"0001c467-05\"\n/dev/sde1: UUID=\"1862f1c7-b546-4109-8a2d-03ce47baca6e\" TYPE=\"crypto_LUKS\" PARTUUID=\"8f60cf56-7a68-484d-83c4-2caf8aad230f\"\n</code></pre> <p>Then set the new passphrase:</p> <pre><code>cryptsetup luksChangeKey /dev/sde1\n</code></pre>","tags":["cli","linux","fs"]},{"location":"Filesystems/LVM/","title":"LVM","text":"","tags":["server","linux","fs"]},{"location":"Filesystems/LVM/#fix-lvm-errors","title":"Fix LVM errors","text":"<p>Exemple:</p> <pre><code>#Errors:\n/dev/sdk: read failed after 0 of 4096 at 6442442752: Input/output error\n/dev/sdk: read failed after 0 of 4096 at 4096: Input/output error\n</code></pre>","tags":["server","linux","fs"]},{"location":"Filesystems/LVM/#solution","title":"Solution :","text":"<p>1) Check which Volume Group have the issue , run \u201cvgscan\u201d command .</p> <p>2) Find out the Logical Volumes attached with that Volume Group .</p> <p>3) Inactive the logical volumes as :</p> <pre><code>lvchange -an &lt;lv-name&gt;\n</code></pre> <p>4) Inactive Volume group as :</p> <pre><code>vgchange -an &lt;vg-name&gt;\n</code></pre> <p>5) Again Scan Volume group using \u201cvgscan\u201d .</p> <p>6) Now activate the Volume Group :</p> <pre><code>vgchange -ay &lt;volume-group-name&gt;\n</code></pre> <p>7) Run command \u201clvscan\u201d , the error should be gone now .</p> <p>8) Now activate the Logical Volume Name :</p> <pre><code>lvchange -ay &lt;lv-name&gt;\n</code></pre>","tags":["server","linux","fs"]},{"location":"Filesystems/LVM/#resize-filesystem-with-lvm","title":"Resize filesystem with LVM","text":"<ul> <li>resize disk in virtual machine manager (Proxmox or KVM)</li> <li>resize partition with <code>fdisk</code> or <code>parted</code></li> <li>resize pv     pvresize /dev/vdaX</li> <li>resize lv to full available size     lvresize -l +100%FREE /dev/mapper/lv-xxx</li> <li>resize filesystem     resize2fs /dev/mapper/lv-xxx</li> </ul>","tags":["server","linux","fs"]},{"location":"Filesystems/RAID_Rebuild/","title":"RAID Rebuild","text":"","tags":["raid","server","fs"]},{"location":"Filesystems/RAID_Rebuild/#how-to-rebuild-an-mdadm-raid","title":"How to rebuild an MDadm Raid","text":"","tags":["raid","server","fs"]},{"location":"Filesystems/RAID_Rebuild/#get-disk-serial","title":"Get disk serial","text":"<pre><code>udevadm info --query=all --name=/dev/sda | grep ID_SERIAL\n</code></pre>","tags":["raid","server","fs"]},{"location":"Filesystems/RAID_Rebuild/#replacing-a-failed-hard-drive-in-a-software-raid1-array","title":"Replacing A Failed Hard Drive In A Software RAID1 Array","text":"<p>This guide shows how to remove a failed hard drive from a Linux RAID1 array (software RAID), and how to add a new hard disk to the RAID1 array without losing data.</p> <p>NOTE: There is a new version of this tutorial available that uses gdisk instead of sfdisk to support GPT partitions.</p>","tags":["raid","server","fs"]},{"location":"Filesystems/RAID_Rebuild/#context","title":"Context","text":"<p>In this example I have two hard drives, /dev/sda and /dev/sdb, with the partitions /dev/sda1 and /dev/sda2 as well as /dev/sdb1 and /dev/sdb2.</p> <ul> <li>/dev/sda1 and /dev/sdb1 make up the RAID1 array /dev/md0.</li> <li>/dev/sda2 and /dev/sdb2 make up the RAID1 array /dev/md1.</li> <li>/dev/sda1 + /dev/sdb1 = /dev/md0</li> <li>/dev/sda2 + /dev/sdb2 = /dev/md1</li> <li>/dev/sdb has failed, and we want to replace it.</li> </ul>","tags":["raid","server","fs"]},{"location":"Filesystems/RAID_Rebuild/#how-do-i-tell-if-a-hard-disk-has-failed","title":"How Do I Tell If A Hard Disk Has Failed?","text":"<p>If a disk has failed, you will probably find a lot of error messages in the log files, e.g. /var/log/messages or /var/log/syslog.</p> <p>You can also run</p> <pre><code>cat /proc/mdstat\n</code></pre> <p>and instead of the string [UU] you will see [U_] if you have a degraded RAID1 array.</p>","tags":["raid","server","fs"]},{"location":"Filesystems/RAID_Rebuild/#removing-the-failed-disk","title":"Removing The Failed Disk","text":"<p>To remove /dev/sdb, we will mark /dev/sdb1 and /dev/sdb2 as failed and remove them from their respective RAID arrays (/dev/md0 and /dev/md1).</p> <p>First we mark /dev/sdb1 as failed:</p> <pre><code>mdadm --manage /dev/md0 --fail /dev/sdb1\n</code></pre> <p>The output of</p> <pre><code>cat /proc/mdstat\n</code></pre> <p>should look like this:</p> <pre><code>Personalities : [linear] [multipath] [raid0] [raid1] [raid5] [raid4] [raid6] [raid10]\nmd0 : active raid1 sda1[0] sdb1[2](F)\n    24418688 blocks [2/1] [U_]\n\nmd1 : active raid1 sda2[0] sdb2[1]\n\n    24418688 blocks [2/2] [UU]\n\nunused devices: &lt;none&gt;\n</code></pre> <p>Then we remove /dev/sdb1 from /dev/md0:</p> <pre><code>mdadm --manage /dev/md0 --remove /dev/sdb1\n</code></pre> <p>The output should be like this:</p> <pre><code>mdadm --manage /dev/md0 --remove /dev/sdb1\nmdadm: hot removed /dev/sdb1\n</code></pre> <p>And</p> <pre><code>cat /proc/mdstat\n</code></pre> <p>should show this:</p> <pre><code>Personalities : [linear] [multipath] [raid0] [raid1] [raid5] [raid4] [raid6] [raid10]\nmd0 : active raid1 sda1[0]\n    24418688 blocks [2/1] [U_]\n\nmd1 : active raid1 sda2[0] sdb2[1]\n\n    24418688 blocks [2/2] [UU]\n\nunused devices: &lt;none&gt;\n</code></pre> <p>Now we do the same steps again for /dev/sdb2 (which is part of /dev/md1):</p> <pre><code>mdadm --manage /dev/md1 --fail /dev/sdb2\n\ncat /proc/mdstat\n\nPersonalities : [linear] [multipath] [raid0] [raid1] [raid5] [raid4] [raid6] [raid10]\nmd0 : active raid1 sda1[0]\n    24418688 blocks [2/1] [U_]\n\nmd1 : active raid1 sda2[0] sdb2[2](F)\n\n    24418688 blocks [2/1] [U_]\n\nunused devices: &lt;none&gt;\n\nmdadm --manage /dev/md1 --remove /dev/sdb2\n\nmdadm: hot removed /dev/sdb2\n\ncat /proc/mdstat\n\nPersonalities : [linear] [multipath] [raid0] [raid1] [raid5] [raid4] [raid6] [raid10]\nmd0 : active raid1 sda1[0]\n    24418688 blocks [2/1] [U_]\n\nmd1 : active raid1 sda2[0]\n\n    24418688 blocks [2/1] [U_]\n\nunused devices: &lt;none&gt;\n</code></pre> <p>Then power down the system:</p> <pre><code>shutdown -h now\n</code></pre> <p>and replace the old /dev/sdb hard drive with a new one (it must have at least the same size as the old one - if it\u2019s only a few MB smaller than the old one then rebuilding the arrays will fail).</p>","tags":["raid","server","fs"]},{"location":"Filesystems/RAID_Rebuild/#adding-the-new-hard-disk","title":"Adding The New Hard Disk","text":"<p>After you have changed the hard disk /dev/sdb, boot the system.</p> <p>The first thing we must do now is to create the exact same partitioning as on /dev/sda. We can do this with one simple command:</p> <pre><code>sfdisk -d /dev/sda | sfdisk /dev/sdb\n</code></pre> <p>You can run</p> <pre><code>fdisk -l\n</code></pre> <p>to check if both hard drives have the same partitioning now.</p> <p>Next we add /dev/sdb1 to /dev/md0 and /dev/sdb2 to /dev/md1:</p> <pre><code>mdadm --manage /dev/md0 --add /dev/sdb1\n\nmdadm: re-added /dev/sdb1\n\nmdadm --manage /dev/md1 --add /dev/sdb2\n\nmdadm: re-added /dev/sdb2\n</code></pre> <p>Now both arays (/dev/md0 and /dev/md1) will be synchronized. Run</p> <pre><code>cat /proc/mdstat\n</code></pre> <p>to see when it\u2019s finished.</p> <p>During the synchronization the output will look like this:</p> <pre><code>server1:~# cat /proc/mdstat\nPersonalities : [linear] [multipath] [raid0] [raid1] [raid5] [raid4] [raid6] [raid10]\nmd0 : active raid1 sda1[0] sdb1[1]\n    24418688 blocks [2/1] [U_]\n    [=&gt;...................]  recovery =  9.9% (2423168/24418688) finish=2.8min speed=127535K/sec\n\nmd1 : active raid1 sda2[0] sdb2[1]\n\n    24418688 blocks [2/1] [U_]\n    [=&gt;...................]  recovery =  6.4% (1572096/24418688) finish=1.9min speed=196512K/sec\n\nunused devices: &lt;none&gt;\n</code></pre> <p>When the synchronization is finished, the output will look like this:</p> <pre><code>server1:~# cat /proc/mdstat\nPersonalities : [linear] [multipath] [raid0] [raid1] [raid5] [raid4] [raid6] [raid10]\nmd0 : active raid1 sda1[0] sdb1[1]\n    24418688 blocks [2/2] [UU]\n\nmd1 : active raid1 sda2[0] sdb2[1]\n\n    24418688 blocks [2/2] [UU]\n\nunused devices: &lt;none&gt;\n</code></pre> <p>That\u2019s it, you have successfully replaced /dev/sdb!</p>","tags":["raid","server","fs"]},{"location":"Filesystems/RAID_Resize/","title":"RAID Resize","text":"","tags":["raid","server","fs"]},{"location":"Filesystems/RAID_Resize/#how-to-resize-raid-partitions-shrink-grow-software-raid","title":"How To Resize RAID Partitions (Shrink &amp; Grow) (Software RAID)","text":"<p>Version 1.0 | Author: Falko Timme</p> <p>This article describes how you can shrink and grow existing software RAID partitions. I have tested this with non-LVM RAID1 partitions that use ext3 as the file system. I will describe this procedure for an intact RAID array and also a degraded RAID array.</p> <p>If you use LVM on your RAID partitions, the procedure will be different, so do not use this tutorial in this case!</p>","tags":["raid","server","fs"]},{"location":"Filesystems/RAID_Resize/#preliminary-note","title":"Preliminary Note","text":"<p>A few days ago I found out that one of my servers had a degraded RAID1 array (/dev/md2, made up of /dev/sda3 and /dev/sdb3; /dev/sda3 had failed, /dev/sdb3 was still active):</p> <pre><code>server1:~# cat /proc/mdstat\nPersonalities : [raid1]\nmd2 : active raid1 sdb3[1]\n    4594496 blocks [2/1] [_U]\n\nmd1 : active raid1 sda2[0] sdb2[1]\n\n    497920 blocks [2/2] [UU]\n\nmd0 : active raid1 sda1[0] sdb1[1]\n\n    144448 blocks [2/2] [UU]\n\nunused devices: &lt;none&gt;\n</code></pre> <p>I tried to fix it (using this tutorial), but unfortunately at the end of the sync process (with 99.9% complete), the sync stopped and started over again. As I found out, this happened because there were some defect sectors at the end of the (working) partition /dev/sdb3 - this was in /var/log/kern.log:</p> <pre><code>Nov 22 18:51:06 server1 kernel: sdb: Current: sense key: Aborted Command\nNov 22 18:51:06 server1 kernel: end_request: I/O error, dev sdb, sector 1465142856\n</code></pre> <p>So this was the worst case that could happen - /dev/sda dead and /dev/sdb about to die. To fix this, I imagined I could shrink /dev/md2 so that it leaves out the broken sectors at the end of /dev/sdb3, then add the new /dev/sda3 (from the replaced hard drive) to /dev/md2, let the sync finish, remove /dev/sdb3 from the array and replace /dev/sdb with a new hard drive, add the new /dev/sdb3 to /dev/md2, and grow /dev/md2 again.</p> <p>This is one of the use cases for the following procedures (I will describe the process for an intact array and a degraded array).</p> <p>Please note that /dev/md2 is my system partition (mount point /), so I had to use a rescue system (e.g. Knoppix Live-CD) to resize the array. If the array you want to resize is not your system partition, you probably don\u2019t need to boot into a rescue system; but in either case, make sure that the array is unmounted!</p>","tags":["raid","server","fs"]},{"location":"Filesystems/RAID_Resize/#intact-array","title":"Intact Array","text":"<p>I will describe how to resize the array /dev/md2, made up of /dev/sda3 and /dev/sdb3.</p>","tags":["raid","server","fs"]},{"location":"Filesystems/RAID_Resize/#shrinking-an-intact-array","title":"Shrinking An Intact Array","text":"<p>Boot into your rescue system and activate all needed modules:</p> <pre><code>modprobe md\nmodprobe linear\nmodprobe multipath\nmodprobe raid0\nmodprobe raid1\nmodprobe raid5\nmodprobe raid6\nmodprobe raid10\n</code></pre> <p>Then activate your RAID arrays:</p> <pre><code>cp /etc/mdadm/mdadm.conf /etc/mdadm/mdadm.conf_orig\nmdadm --examine --scan &gt;&gt; /etc/mdadm/mdadm.conf\n\nmdadm -A --scan\n</code></pre> <p>Run</p> <pre><code>e2fsck -f /dev/md2\n</code></pre> <p>to check the file system.</p> <p>/dev/md2 has a size of 40GB; I want to shrink it to 30GB. First we have to shrink the file system with resize2fs; to make sure that the file system fits into the 30GB, we make it a little bit smaller (25GB) so we have a little security margin, shrink /dev/md2 to 30GB, and the resize the file system (again with resize2fs) to the max. possible value:</p> <pre><code>resize2fs /dev/md2 25G\n</code></pre> <p>Now we shrink /dev/md2 to 30GB. The \u2013size value must be in KiBytes (30 x 1024 x 1024 = 31457280); make sure it can be divided by 64:</p> <pre><code>mdadm --grow /dev/md2 --size=31457280\n</code></pre> <p>Next we grow the file system to the largest possible value (if you don\u2019t specify a size, resize2fs will use the largest possible value)\u2026</p> <pre><code>resize2fs /dev/md2\n</code></pre> <p>\u2026 and run a file system check again:</p> <pre><code>e2fsck -f /dev/md2\n</code></pre> <p>That\u2019s it - you can now boot into the normal system again.</p>","tags":["raid","server","fs"]},{"location":"Filesystems/RAID_Resize/#growing-an-intact-array","title":"Growing An Intact Array","text":"<p>Boot into your rescue system and activate all needed modules:</p> <pre><code>modprobe md\nmodprobe linear\nmodprobe multipath\nmodprobe raid0\nmodprobe raid1\nmodprobe raid5\nmodprobe raid6\nmodprobe raid10\n</code></pre> <p>Then activate your RAID arrays:</p> <pre><code>cp /etc/mdadm/mdadm.conf /etc/mdadm/mdadm.conf_orig\nmdadm --examine --scan &gt;&gt; /etc/mdadm/mdadm.conf\n\nmdadm -A --scan\n</code></pre> <p>Now we can grow /dev/md2 as follows:</p> <pre><code>mdadm --grow /dev/md2 --size=max\n</code></pre> <p>\u2013size=max means the largest possible value. You can as well specify a size in KiBytes (see previous chapter).</p> <p>Then we run a file system check\u2026</p> <pre><code>e2fsck -f /dev/md2\n</code></pre> <p>\u2026, resize the file system\u2026</p> <pre><code>resize2fs /dev/md2\n</code></pre> <p>\u2026 and check the file system again:</p> <pre><code>e2fsck -f /dev/md2\n</code></pre> <p>Afterwards you can boot back into your normal system.</p>","tags":["raid","server","fs"]},{"location":"Filesystems/RAID_Resize/#procedure-courte-pour-resize-un-raid1","title":"Proc\u00e9dure courte pour resize un RAID1","text":"<ol> <li>Booter sur un live CD, style Linux Mint que j\u2019ai utilis\u00e9</li> <li>installer mdadm : apt-get install mdadm</li> <li>charger les modules n\u00e9cessaires : modprobe {mdio, md, raid0, raid1, raid5, raid6, raid10, linear, mulipath}</li> <li>examiner l\u2019\u00e9tat des RAID : mdadm \u2013examine \u2013scan</li> <li>activer les volumes RAID trouv\u00e9s : mdadm -A \u2013scan</li> <li>monter la partition : mount /dev/mdX /mnt</li> <li>redimensionner le syst\u00e8me de fichiers : btrfs filesystem resize -10G /mnt</li> <li>umount /mnt</li> <li>mettre un disque en faulty : mdadm /dev/md/RAID \u2013fail /dev/sdaX</li> <li>le retirer du RAID : mdadm /dev/md/RAID \u2013remove /dev/sdaX</li> <li>redimensionner la partition un poil plus grand que le fs : parted /dev/sda \u2192 resizepart X \u2192 end \u2192 Yes \u2192 quit</li> <li>v\u00e9rifier le syst\u00e8me de fichier : btrfs check /dev/sdaX \u2192 echo $? pour \u00eatre s^ur qu\u2019il sort bien \u00e0 0 malgr\u00e9 les messages</li> <li>r\u00e9duire le RAID : mdadm \u2013grow /dev/md/RAID \u2013size=xxxx  (xxGB * 1024 * 1024) mais environ 500 Mo de moins que les partitions qui le composent !</li> <li>rajouter le disque au RAID : mdadm /dev/md/RAID \u2013add /dev/sdaX</li> <li>attendre la reconstruction de la grappe : cat /proc/mdstat</li> <li>faire pareil avec l\u2019autre disque (\u00e9tapes 8 \u00e0  14 mais pas la 13 !)</li> <li>agrandir le RAID au max : mdadm \u2013grow /dev/mdXXX \u2013size max</li> <li>reboot</li> </ol>","tags":["raid","server","fs"]},{"location":"Filesystems/ZFS/","title":"ZFS","text":"","tags":["fs","server","linux"]},{"location":"Filesystems/ZFS/#zfs-tips-and-tricks","title":"ZFS tips and tricks","text":"","tags":["fs","server","linux"]},{"location":"Filesystems/ZFS/#create-pool-with-raid","title":"Create pool with raid","text":"<pre><code>zpool create raidz2 &lt;pool name&gt; &lt;disk1&gt; ... &lt;diskN&gt;\n</code></pre> <p>Create pool with RAID 5 double parity</p>","tags":["fs","server","linux"]},{"location":"Filesystems/ZFS/#zfs-caches","title":"ZFS caches","text":"<ul> <li>ARC: RAM cache</li> <li>L2ARC: Level 2 ARC, on SSD, no need for redundancy</li> <li>ZIL (ZFS Intent Log) SLOG (Separate intent Log): persistent write cache, redundancy needed</li> </ul>","tags":["fs","server","linux"]},{"location":"Filesystems/ZFS/#add-l2arc-cache-to-existing-pool","title":"Add L2ARC cache to existing pool","text":"<pre><code>zpool add &lt;pool name&gt; cache &lt;disk&gt;\n</code></pre>","tags":["fs","server","linux"]},{"location":"Filesystems/ZFS/#add-slog-disk-cache-to-existing-pool","title":"Add SLOG disk cache to existing pool","text":"<pre><code>zpool add &lt;pool name&gt; log mirror &lt;disk ssd1&gt; &lt;disk ssd2&gt;\n</code></pre>","tags":["fs","server","linux"]},{"location":"Filesystems/ZFS/#stats","title":"Stats","text":"","tags":["fs","server","linux"]},{"location":"Filesystems/ZFS/#view-iostat","title":"View iostat","text":"<p>Since boot</p> <pre><code>zpool iostat\n</code></pre> <p>Dynamic view with 1sec interval</p> <pre><code>zpool iostat 1\n</code></pre> <p>including virtual drives</p> <pre><code>zpool iostat 1 -v\n</code></pre>","tags":["fs","server","linux"]},{"location":"Filesystems/ZFS/#quotas","title":"Quotas","text":"<pre><code>zfs set quota=XXG &lt;pool name&gt;\n</code></pre>","tags":["fs","server","linux"]},{"location":"Filesystems/ZFS/#manage-cache-file","title":"Manage cache file","text":"<p>Re-generate the <code>zpool.cache</code> configuration file</p> <pre><code>zpool set cachefile=/etc/zfs/zpool.cache &lt;pool name&gt;\n</code></pre>","tags":["fs","server","linux"]},{"location":"Filesystems/sfdisk_usage/","title":"Sfdisk usage","text":"","tags":["server","linux","fs"]},{"location":"Filesystems/sfdisk_usage/#sfdisk","title":"SFDISK","text":"","tags":["server","linux","fs"]},{"location":"Filesystems/sfdisk_usage/#background","title":"Background:","text":"<p>Each drive has 1 partition table. A partition table can have a maximum of 4 primary partitions. If the drive is called sdc, the the primary partitions are called sdc1, sdc2, sdc3, sdc4. A partition table can have at most 1 extended partition. The extended partition must also have a name whose numerical part is between 1 and 4: that is, the extended partition must be named sdc1 or sdc2 or sdc3 or sdc4. Logical partitions always have device names whose numerical part is greater than or equal to 5. (e.g. sdc5, sdc6, etc.) The partition table is located at sectors 447\u2013512 on the drive. A sector = 512 bytes. You can save the partition table in its native binary format with the command</p> <pre><code>sudo dd if=/dev/sdc of=PT_sdc.img bs=1 count=66 skip=446\n</code></pre> <p>and you can restore the partition table with the command</p> <pre><code>sudo dd of=/dev/sdc if=PT_sdc.img bs=1 count=66 skip=446\n</code></pre> <p>I mention this so you can have a picture in your mind about where the partition table is located. We won\u2019t be using dd to manipulate the partition table, however. We\u2019ll use sfdisk instead.</p>","tags":["server","linux","fs"]},{"location":"Filesystems/sfdisk_usage/#the-sfdisk-commands","title":"The sfdisk commands","text":"<p>You can save the partition table in an ascii format with the command</p> <pre><code>sudo sfdisk -d /dev/sdc &gt; PT.txt\n</code></pre> <p>This saves the partition table on /dev/sdc to a file called PT.txt. What\u2019s particularly lovely is that is file is in ASCII format.</p> <p>You can edit it in a normal text editor, then tell sfdisk to write a new partition table based on our edited PT.txt:</p> <pre><code>sudo sfdisk --no-reread -f /dev/sdc -O PT.save &lt; PT.txt\n</code></pre> <p>\u201c\u2013no-reread\u201d means don\u2019t check if disk is unmounted -f force \u201c-O PT.save\u201d means save a backup of original partition table in PT.save. PT.save is in binary format.</p>","tags":["server","linux","fs"]},{"location":"Filesystems/sfdisk_usage/#to-restore-the-partition-table-using-ptsave","title":"To restore the partition table using PT.save","text":"<pre><code>sudo sfdisk --force -I PT.save /dev/sdc\n</code></pre>","tags":["server","linux","fs"]},{"location":"Filesystems/sfdisk_usage/#transfer-part-table","title":"Transfer part table","text":"<pre><code>sfdisk -d /dev/sda | sfdisk --force /dev/sdb\n</code></pre>","tags":["server","linux","fs"]},{"location":"Filesystems/sfdisk_usage/#gpt-part-table","title":"GPT part table","text":"<pre><code>apt-get install gdisk\n</code></pre>","tags":["server","linux","fs"]},{"location":"Filesystems/sfdisk_usage/#clone-gpt-table-from-devsda-to-devsdb","title":"clone GPT table from /dev/sda to /dev/sdb","text":"<pre><code>sgdisk -R=/dev/sdb /dev/sda\n</code></pre>","tags":["server","linux","fs"]},{"location":"Filesystems/sfdisk_usage/#make-unique-its-guid-as-it-was-cloned-and-is-identical-with-devsda","title":"make unique its GUID as it was cloned and is identical with /dev/sda","text":"<pre><code>sgdisk -G /dev/sdb\n</code></pre>","tags":["server","linux","fs"]},{"location":"GitLab/local_s3_cache/","title":"Create a local bucket for runners\u2019 cache","text":""},{"location":"GitLab/local_s3_cache/#get-the-server-binary","title":"Get the server binary","text":"<pre><code>curl -O https://dl.minio.io/server/minio/release/linux-amd64/minio\n</code></pre> <p>Make it executable:</p> <pre><code>chmod +x minio\nmv minio /usr/local/bin\n</code></pre>"},{"location":"GitLab/local_s3_cache/#add-dedicated-user-and-set-its-rights","title":"Add dedicated user and set its rights","text":"<pre><code>useradd -r minio-user -s /sbin/nologin\n\nchown minio-user:minio-user /usr/local/bin/minio\n</code></pre> <p>Create the directory where minio will cache objects:</p> <pre><code>mkdir /usr/local/share/minio\nchown minio-user:minio-user /usr/local/share/minio\n</code></pre>"},{"location":"GitLab/local_s3_cache/#configure-the-service","title":"Configure the service","text":"<pre><code>mkdir /etc/minio\nchown minio-user:minio-user /etc/minio\n\nvim /etc/default/minio #add the following with your own credentials\n\nMINIO_VOLUMES=\"/usr/local/share/minio/\nMINIO_OPTS=\"-C /etc/minio --address 0.0.0.0:9005\"\nMINIO_ACCESS_KEY=\"YOUR_SECRET_HERE\"\nMINIO_SECRET_KEY=\"YOUR_SECRET_HERE\"\nMINIO_REIGON=\"eu-west-1\"\nMINIO_ROOT_USER=\"YOUR_SECRET_HERE\"\nMINIO_ROOT_PASSWORD=\"YOUR_SECRET_HERE\"\n</code></pre>"},{"location":"GitLab/local_s3_cache/#get-the-systemd-unit-file","title":"Get the systemd unit file","text":"<pre><code>curl -O https://raw.githubusercontent.com/minio/minio-service/master/linux-systemd/minio.service\nmv minio.service /etc/systemd/system\n</code></pre> <p>Check that you have the following content:</p> <pre><code>[Unit]\nDescription=MinIO\nDocumentation=https://docs.min.io\nWants=network-online.target\nAfter=network-online.target\nAssertFileIsExecutable=/usr/local/bin/minio\n\n[Service]\nWorkingDirectory=/usr/local/\n\nUser=minio-user\nGroup=minio-user\n\nEnvironmentFile=/etc/default/minio\nExecStartPre=/bin/bash -c \"if [ -z \\\"${MINIO_VOLUMES}\\\" ]; then echo \\\"Variable MINIO_VOLUMES not set in /etc/default/minio\\\"; exit 1; fi\"\n\nExecStart=/usr/local/bin/minio server $MINIO_OPTS $MINIO_VOLUMES\n\n# Let systemd restart this service always\nRestart=always\n\n# Specifies the maximum file descriptor number that can be opened by this process\nLimitNOFILE=65536\n\n# Specifies the maximum number of threads this process can create\nTasksMax=infinity\n\n# Disable timeout logic and wait until process is stopped\nTimeoutStopSec=infinity\nSendSIGKILL=no\n\n[Install]\nWantedBy=multi-user.target\n\n# Built for ${project.name}-${project.version} (${project.name})\n</code></pre> <p>Reload systemd daemon:</p> <pre><code>systemctl daemon-reload\n</code></pre> <p>Enable and start minio service:</p> <pre><code>systemctl enable minio --now\n</code></pre> <p>Access the web interface, using specified credentials, at <code>https://minio.host.ip:9005</code>.</p>"},{"location":"GitLab/registry_clean/","title":"Registry Management","text":""},{"location":"GitLab/registry_clean/#clean-old-tags","title":"Clean old tags","text":"<p>Get registry ID</p> <pre><code>curl -sNH \"Private-Token: TOKEN_WITH_FULL_API_SCOPE\" \"https://gitlab.blabla.net/api/v4/projects/PROJET_ID/registry/repositories\"\n</code></pre> <p>Remove all but the last 5 tags</p> <pre><code>curl --request DELETE --data 'name_regex_delete=.*' --data 'keep_n=5' --header \"Private-Token: TOKEN_WITH_FULL_API_SCOPE\" \"https://gitlab.blabla.net/api/v4/projects/PROJET_ID/registry/repositories/REPO_ID/tags\"\n</code></pre>"},{"location":"LDAP/ACL/","title":"LDAP ACL","text":"<p>https://www.vincentliefooghe.net/content/modifier-les-acl-dun-annuaire-openldap https://www.vincentliefooghe.net/content/les-acl-dans-openldap</p>"},{"location":"LDAP/ConfigAdmin/","title":"Setup Config Admin","text":"<p>First of all, let\u2019s search for the right entry in our ldap-tree:</p> <pre><code>dr@tardis:# ldapsearch -LLL -Y EXTERNAL -H ldapi:/// -b cn=config\n</code></pre> <p>In this output we can find our <code>cn=admin,cn=config</code></p> <pre><code>dn: olcDatabase={0}config,cn=config\nobjectClass: olcDatabaseConfig\nolcDatabase: {0}config\nolcAccess: {0}to * by dn.exact=gidNumber=0+uidNumber=0,cn=peercred,cn=external\n ,cn=auth manage by * break\n olcRootDN: cn=admin,cn=config\n</code></pre> <p>Now lets encode our password using the following command:</p> <pre><code>slappasswd -h {SHA}\n</code></pre> <p>So we can create our modification.ldif now:</p> <pre><code>dn: olcDatabase={0}config,cn=config\nchangetype: modify\nadd: olcRootPW\nolcRootPW: {SSHA}\n</code></pre> <p>And enable it with the following command</p> <pre><code>ldapmodify -Y EXTERNAL -H ldapi:/// -f modification.ldif\n</code></pre> <p>source: https://tech.feedyourhead.at/content/openldap-set-config-admin-password</p>"},{"location":"LDAP/LDAP_tunning/","title":"LDAP tunning","text":"","tags":["server","ldap"]},{"location":"LDAP/LDAP_tunning/#threads","title":"Threads","text":"<p>G\u00e9n\u00e9ralement fonction du nombre de c\u0153ur r\u00e9el. Contre-intuitivement, un nombre de threads sup\u00e9rieur \u00e0 16 entra\u00eene une baisse de performance des les op\u00e9rations de lecture. En revanche les op\u00e9rations intensives d\u2019\u00e9criture sont plus rapides.</p>","tags":["server","ldap"]},{"location":"LDAP/Monitoring_LDAP/","title":"Monitoring LDAP","text":"","tags":["ldap","server"]},{"location":"LDAP/Monitoring_LDAP/#get-current-connections-number","title":"Get current connections number","text":"<pre><code>perl check_ldap_monitor.pl -vvv -H localhost -D cn=monitor,dc=server,dc=tld -P password  -T currentconnections -w 250 -c 300 -m greater -f\n</code></pre>","tags":["ldap","server"]},{"location":"LDAP/Monitoring_LDAP/#check-that-a-record-is-present","title":"Check that a record is present","text":"<pre><code>perl check_ldap_dn.pl -H localhost -p 389 -D cn=monitor,dc=server,dc=tld -W password -b cn=Active,cn=Threads,cn=monitor\n</code></pre>","tags":["ldap","server"]},{"location":"LDAP/Monitoring_LDAP/#count-the-number-of-returned-records","title":"Count the number of returned records","text":"<pre><code>perl check_ldap_query.pl -H localhost -p 389 -D cn=monitor,dc=server,dc=tld -P password -b cn=Open,cn=Threads,cn=monitor -w 200 -c 250 -m greater -v\n</code></pre>","tags":["ldap","server"]},{"location":"LDAP/Monitoring_LDAP/#monitoring","title":"Monitoring","text":"<p>https://www.openldap.org/doc/admin24/monitoringslapd.html</p> <ul> <li> <p>Example</p> <pre><code>ldapsearch -h localhost -D cn=monitor,dc=server,dc=tld -b cn=Tasklist,cn=Threads,cn=monitor -w password -s sub '(objectClass=\\*)' '*' '+'\n</code></pre> </li> <li> <p>Report only a specific metric</p> <pre><code>ldapsearch -h localhost -D cn=monitor,dc=server,dc=tld -b cn=Read,cn=Waiters,cn=monitor -w password -LL -s sub '(objectClass=*)' monitorCounter | grep monitorCounter | cut -d\" \" -f2\n</code></pre> </li> </ul>","tags":["ldap","server"]},{"location":"LDAP/Recover_admin_password/","title":"Recover admin password lost","text":"","tags":["ldap"]},{"location":"LDAP/Recover_admin_password/#stop-service","title":"Stop service","text":"<pre><code>service slapd stop\n</code></pre>","tags":["ldap"]},{"location":"LDAP/Recover_admin_password/#save-ldap-base","title":"Save ldap base","text":"<pre><code>slapcat -n 2 &gt; /root/slapcat.txt\n</code></pre>","tags":["ldap"]},{"location":"LDAP/Recover_admin_password/#remove-ldap-base","title":"Remove ldap base","text":"<pre><code>mkdir /tmp/ldap.bak\nmv /var/lib/ldap/* /tmp/ldap.bak/\n</code></pre>","tags":["ldap"]},{"location":"LDAP/Recover_admin_password/#edit-file","title":"Edit file","text":"<pre><code>vim slapcat.txt\n##=&gt; change admin password\n</code></pre>","tags":["ldap"]},{"location":"LDAP/Recover_admin_password/#import-base","title":"Import base","text":"<pre><code>slapadd -l /root/slapcat.txt  -n 2\n</code></pre>","tags":["ldap"]},{"location":"LDAP/Recover_admin_password/#set-rights","title":"Set rights","text":"<pre><code>chown -R openldap:openldap /var/lib/ldap/\n</code></pre>","tags":["ldap"]},{"location":"LDAP/Recover_admin_password/#restart-service","title":"Restart service","text":"<pre><code>service slapd start\n</code></pre>","tags":["ldap"]},{"location":"LDAP/Reset_slave_state/","title":"Reset slave state","text":"","tags":["ldap","server"]},{"location":"LDAP/Reset_slave_state/#reinitialiser-letat-dun-consumer-ldap","title":"R\u00e9initialiser l\u2019\u00e9tat d\u2019un consumer LDAP","text":"<p>Cette proc\u00e9dure est utile dans le cas d\u2019un cluster provider-consumer LDAP o\u00f9, pour X raison, le consumer est mal synchronis\u00e9 avec le provider et o\u00f9 on souhaite r\u00e9initialiser compl\u00e8tement la synchronisation.</p>","tags":["ldap","server"]},{"location":"LDAP/Reset_slave_state/#remettre-le-consumer-a-zero","title":"Remettre le consumer \u00e0 z\u00e9ro","text":"<ul> <li> <p>Pr\u00e9parer un .ldif pour supprimer la synchro</p> <pre><code>vim reset_syncrepl.ldif\n\ndn: olcDatabase={1}mdb,cn=config\nchangetype: modify\ndelete:olcSyncrepl\nolcSyncrepl: {0}rid=001 \n  provider=ldap://ldap.example.com\n  type=refreshAndPersist\n  retry=\"5 5 300 +\" \n  searchbase=\"dc=example,dc=com\"\n  attrs=\"*,+\"\n  bindmethod=simple\n  binddn=\"uid=user,ou=my_ou,dc=example,dc=com\"\n  credentials=my_password\n</code></pre> </li> <li> <p>int\u00e9grer le .ldif</p> <pre><code>ldapadd -vv -Y EXTERNAL -H ldapi:/// -f reset_syncrepl.ldif\n</code></pre> </li> <li> <p>arr\u00eater le service</p> <pre><code>systemctl stop slapd\n</code></pre> </li> <li> <p>d\u00e9placer la base</p> <pre><code>mkdir save_ldap\nmv /var/lib/ldap/* save_ldap/\n</code></pre> </li> </ul>","tags":["ldap","server"]},{"location":"LDAP/Reset_slave_state/#relancer-la-synchro","title":"Relancer la synchro","text":"<ul> <li> <p>pr\u00e9parer le .ldif de configuration de la synchro</p> <pre><code>vim syncrepl.ldif\n\ndn: olcDatabase={1}mdb,cn=config\nchangetype: modify\nadd:olcSyncrepl\nolcSyncrepl: {0}rid=001 \n  provider=ldap://ldap.example.com\n  type=refreshAndPersist\n  retry=\"5 5 300 +\" \n  searchbase=\"dc=example,dc=com\"\n  attrs=\"*,+\"\n  bindmethod=simple\n  binddn=\"uid=user,ou=my_ou,dc=example,dc=com\"\n  credentials=my_password\n</code></pre> </li> <li> <p>d\u00e9marrer le service</p> <pre><code>systemctl start slapd\n</code></pre> </li> <li> <p>int\u00e9grer le .ldif</p> <pre><code>ldapadd -vv -Y EXTERNAL -H ldapi:/// -f syncrepl.ldif\n</code></pre> </li> <li> <p>une fois fait, arr\u00eater le service \u00e0 nouveau</p> <pre><code>systemctl stop slapd\n</code></pre> </li> <li> <p>lancer le d\u00e9mon slapd \u00e0 la main en for\u00e7ant la remise \u00e0 z\u00e9ro du cookie de synchro</p> <pre><code>slapd -c rid=001,csn=0 -F /etc/ldap/slapd.d\n</code></pre> </li> </ul> <p>(Note: le rid correspond au num\u00e9ro pass\u00e9 dans le .ldif. Le csn doit \u00eatre 0.)</p> <ul> <li> <p>surveiller que la synchro se fait bien en lan\u00e7ant par exemple un tcpdump sur le provider</p> <pre><code>tcpdump host &lt;ip du consumer&gt; and port 389\n</code></pre> </li> <li> <p>une fois la re-synchro finie, arr\u00eater le processus slapd en cours et d\u00e9marrer le service</p> <pre><code>killall slapd\npgrep slapd # ne doit rien renvoyer\nsystemctl start slapd\n</code></pre> </li> </ul>","tags":["ldap","server"]},{"location":"Linux/Bluetooth/","title":"Bluetooth","text":"","tags":["bluetooth"]},{"location":"Linux/Bluetooth/#edit-the-file","title":"Edit the file:","text":"<pre><code>/etc/pulse/default.pa\n</code></pre>","tags":["bluetooth"]},{"location":"Linux/Bluetooth/#and-comment-out-with-an-at-the-beginning-of-the-line-the-following-line","title":"and comment out (with an # at the beginning of the line) the following line:","text":"<pre><code>load-module module-bluetooth-discover\n</code></pre>","tags":["bluetooth"]},{"location":"Linux/Bluetooth/#now-edit-the-file","title":"now edit the file:","text":"<pre><code>/usr/bin/start-pulseaudio-x11\n</code></pre>","tags":["bluetooth"]},{"location":"Linux/Bluetooth/#and-after-the-lines","title":"and after the lines:","text":"<pre><code>if [ x\u201d$SESSION_MANAGER\u201d != x ] ; then\n    /usr/bin/pactl load-module module-x11-xsmp \u201cdisplay=$DISPLAY session_manager=$SESSION_MANAGER\u201d &gt; /dev/null\nfi\n</code></pre>","tags":["bluetooth"]},{"location":"Linux/Bluetooth/#add-the-following-line","title":"add the following line:","text":"<pre><code>/usr/bin/pactl load-module module-bluetooth-discover\n</code></pre>","tags":["bluetooth"]},{"location":"Linux/Bluetooth/#dans-le-fichier","title":"Dans le fichier :","text":"<pre><code>/etc/bluetooth/main.conf\n</code></pre>","tags":["bluetooth"]},{"location":"Linux/Bluetooth/#changer","title":"Changer:","text":"<pre><code>ControllerMode = dual\n</code></pre>","tags":["bluetooth"]},{"location":"Linux/Bluetooth/#en","title":"en :","text":"<pre><code>ControllerMode = bredr\n</code></pre>","tags":["bluetooth"]},{"location":"Linux/Bluetooth/#si-probleme-avec-gdm","title":"Si probl\u00e8me avec gDM:","text":"<pre><code>cd /var/lib/gdm/.pulse/client.conf\nautospawn = no\ndaemon-binary = /bin/true\n</code></pre>","tags":["bluetooth"]},{"location":"Linux/Busybox/","title":"Busybox","text":"<p>Start with busybox in Grub</p> <pre><code>init=/bin/busybox\n</code></pre> <p>Use it:</p> <pre><code>busybox-static ls # ou dmesg ou autre commande\n</code></pre> <p>Like it states in \u2013help output: create some symlinks to it:</p> <pre><code>mkdir xxx\ncd xxx\nfor f in $(/usr/bin/busybox-static --list); do \\\nln -s /usr/bin/busybox-static $f; done\n./uname\nLinux\n</code></pre> <p>FWIW: one could also build the \u2018coreutils\u2019 package to have an all-in-one program which acts the same:</p> <pre><code>./configure --help\n...\n--enable-single-binary=shebangs|symlinks\n                        Compile all the tools in a single binary, reducing\n                        the overall size. When compiled this way, shebangs\n                        (default when enabled) or symlinks are installed for\n                        each tool that points to the single binary.\n</code></pre>","tags":["linux"]},{"location":"Linux/Copy_sparse_files/","title":"Copier un fichier sparse sur le r\u00e9seau","text":"<p>par Paul Chevalier | 24 Mai 2018 </p> <p>Les fichiers dits \u00ab sparse \u00bb sont allou\u00e9s avec une taille sup\u00e9rieur \u00e0 la taille r\u00e9ellement occup\u00e9e sur le disque dur. Cela permet de n\u2019occuper l\u2019espace disque que si le fichier fait face \u00e0 un accroissement. On les rencontre couramment en virtualisation o\u00f9 l\u2019on parle aussi de \u00ab thin provisioning \u00bb.</p> <p>Le terme \u00ab sparse \u00bb se traduit par \u00ab clairsem\u00e9 \u00bb en fran\u00e7ais et \u00ab thin provisionning \u00bb par \u00ab provisionnement all\u00e9g\u00e9 \u00bb.</p> <p>Avec rsync et l\u2019option -S ou \u2013sparse permet de respecter le caract\u00e8re \u00ab sparse \u00bb du fichier qui ne prendra pas plus de place disque sur la source que sur la cible. Cependant l\u2019utilisation de cette option a un inconv\u00e9nient : la taille d\u2019allocation totale transite par le r\u00e9seau, ce qui est peu efficient.</p> <p>Pour \u00e9viter ce d\u00e9sagr\u00e9ment on peut faire appel \u00e0 une archive tar en mode sparse (-S). Le fichier obtenu peut ainsi \u00eatre transf\u00e9r\u00e9 via n\u2019importe quel protocole pour \u00eatre d\u00e9-tar\u00e9 sur place.</p> <pre><code>tar Scvf image.qcow2.tar image.qcow2\nrsync image.qcow2.tar serveur-cible:/chemin/\n</code></pre> <p>Une variante consiste \u00e0 utiliser tar en mode flux avec un pipe comme indiqu\u00e9 sur cette page \u00ab How to copy sparse files faster\u00ab .</p> <pre><code>tar cvzSpf \u2013 image.qcow2 | ssh user@serveur-distant \u2018(cd /tmp; tar xzSpf -)\u2019\n</code></pre> <p>L\u2019utilisation de tar conjointement avec SSH est une bonne id\u00e9e afin de b\u00e9n\u00e9ficier de l\u2019option sparse, mais aussi pour remplir les trames r\u00e9seau et acc\u00e9l\u00e9rer les \u00e9changes par rapport \u00e0 rsync, en particulier en cas de petits fichiers. Voir diff\u00e9rent exemples ici ou encore celui qui suit.</p> <pre><code>tar -cS /dossier | ssh serveur-distant 'tar -xvf - -C /destination/'\n</code></pre>","tags":["filesystem"]},{"location":"Linux/Create_floppy_disk/","title":"Create floppy disk","text":"","tags":["linux","fs","cli"]},{"location":"Linux/Create_floppy_disk/#how-to-create-a-floppy-disk","title":"How to create a floppy disk","text":"<p>The necessary commands to perform this task are as follows:</p> <pre><code>dd if=/dev/zero of=floppy.img bs=1k count=1440\n\nsudo losetup /dev/loop0 floppy.img\nsudo mkfs -t vfat /dev/loop0\n\nsudo losetup -d /dev/loop0\n\nsudo mkdir /media/floppy\n\nsudo mount floppy.img /media/floppy\n\nsudo cp * /media/floppy\n\nsudo umount /media/floppy\n\nsudo rmdir /media/floppy\n</code></pre>","tags":["linux","fs","cli"]},{"location":"Linux/Create_img_disk/","title":"Create img disk","text":"","tags":["fs","linux","various"]},{"location":"Linux/Create_img_disk/#how-to-create-an-img-disk","title":"How to create an \u201cimg\u201d disk","text":"<ul> <li> <p>The necessary commands to perform this task are as follows:</p> <p>dd if=/dev/zero of=floppy.img bs=1k count=1440</p> <p>sudo losetup /dev/loop0 floppy.img sudo mkfs -t vfat /dev/loop0</p> <p>sudo losetup -d /dev/loop0</p> <p>sudo mkdir /media/floppy</p> <p>sudo mount floppy.img /media/floppy</p> <p>sudo cp * /media/floppy</p> <p>sudo umount /media/floppy</p> <p>sudo rmdir /media/floppy</p> </li> </ul>","tags":["fs","linux","various"]},{"location":"Linux/Create_iso_file/","title":"Create iso file","text":"","tags":["fs","shell"]},{"location":"Linux/Create_iso_file/#how-to-create-an-iso-including-custome-files","title":"How to create an ISO including custome files","text":"<pre><code>xorrisofs  -output monIso.iso -volid cidata -joliet -rock fichier1 fichier2 ...\n</code></pre>","tags":["fs","shell"]},{"location":"Linux/Curl/","title":"Curl","text":"","tags":["web","curl","cli","mail","imap"]},{"location":"Linux/Curl/#basic-example","title":"Basic example","text":"<pre><code>curl -v -s https://linuxfr.org\n</code></pre>","tags":["web","curl","cli","mail","imap"]},{"location":"Linux/Curl/#get-a-file","title":"Get a file","text":"<pre><code>curl -ROL https://fichier\n</code></pre>","tags":["web","curl","cli","mail","imap"]},{"location":"Linux/Curl/#to-tell-curl-to-use-a-user-and-password-for-authentication","title":"To tell curl to use a user and password for authentication:","text":"<pre><code>curl --user name:password http://www.example.com\n</code></pre>","tags":["web","curl","cli","mail","imap"]},{"location":"Linux/Curl/#resolve-on-a-different-name","title":"Resolve on a different name","text":"<pre><code>curl --resolve www.server.com:443:213.162.53.103 https://www.server.com/\n</code></pre>","tags":["web","curl","cli","mail","imap"]},{"location":"Linux/Curl/#mail","title":"Mail","text":"<pre><code>curl -v imap://user:password@in.server.com/\ncurl \u201cimaps://user:password@in.example.com/\u201d\n</code></pre>","tags":["web","curl","cli","mail","imap"]},{"location":"Linux/Curl/#in-case-you-need-to-use-special-chars-like-you-have-to-escape-in-according-to-rfc-3986-example-password-pssword-is-escaped-using-40","title":"In case you need to use \u201cspecial\u201d chars like @ you have to escape in according to  RFC 3986 | Example (password: p@ssword) @ is escaped using %40","text":"<pre><code>curl \u201cimap://username:p%40ssword@in.example.com\u201d\n</code></pre>","tags":["web","curl","cli","mail","imap"]},{"location":"Linux/Curl/#check-new-email-inbox","title":"Check new email INBOX","text":"<pre><code>curl \u201cimap://username:password@in.example.com/INBOX?NEW\u201d\ncurl \u201cimap://username:password@in.example.com/&lt;FOLDER&gt;;UID=&lt;UID_NUMBER&gt;\u201d\n</code></pre>","tags":["web","curl","cli","mail","imap"]},{"location":"Linux/Encrypt_files/","title":"Encrypt files","text":"","tags":["cli"]},{"location":"Linux/Encrypt_files/#encrypt","title":"Encrypt","text":"<pre><code>cat file | openssl aes-256-cbc -a -salt -out file_encrypted\n</code></pre>","tags":["cli"]},{"location":"Linux/Encrypt_files/#decrypt","title":"Decrypt","text":"<pre><code>cat file_encrypted | openssl aes-256-cbc -a -d -salt -out file_decrypted\n</code></pre>","tags":["cli"]},{"location":"Linux/Entropy/","title":"Manage Linux entropy","text":"<p>To check the status of your server\u2019s entropy, just run the following:</p> <pre><code>cat /proc/sys/kernel/random/entropy_avail\n</code></pre> <p>If it returns anything less than 100-200, you have a problem. The <code>haveged</code> package and daemon can be installed to greatly increase the system entropy.</p>"},{"location":"Linux/GPG/","title":"GPG","text":"","tags":["various","gpg","cli"]},{"location":"Linux/GPG/#gpg","title":"GPG","text":"","tags":["various","gpg","cli"]},{"location":"Linux/GPG/#integrity-check-verifying-the-files-signature","title":"Integrity Check - Verifying the File\u2019s Signature","text":"<p>If you already have a trusted version of GnuPG installed, you can check the supplied signature.  For example, to check the signature of the file gnupg-2.0.30.tar.bz2, you can use this command: </p> <pre><code>gpg --verify gnupg-2.0.30.tar.bz2.sig gnupg-2.0.30.tar.bz2\n</code></pre> <p>Note: you should never use a GnuPG version you just downloaded to check the integrity of the source \u2014 use an existing, trusted GnuPG installation, e.g., the one provided by your distribution.  If the output of the above command is similar to the following, then either you don\u2019t have our distribution keys (our signing keys are here) or the signature was generated by someone else and the file should be treated suspiciously. </p> <pre><code>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ngpg: Signature made Fri 09 Oct 2015 05:41:55 PM CEST using RSA key ID 4F25E3B6\ngpg: Can't check signature: No public key\ngpg: Signature made Tue 13 Oct 2015 10:18:01 AM CEST using RSA key ID 33BD3F06\ngpg: Can't check signature: No public key\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre> <p>If you instead see: </p> <pre><code>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ngpg: Good signature from \"Werner Koch (dist sig)\" [unknown]\ngpg: WARNING: This key is not certified with a trusted signature!\ngpg:          There is no indication that the signature belongs to the owner.\nPrimary key fingerprint: D869 2123 C406 5DEA 5E0F  3AB5 249B 39D2 4F25 E3B6\ngpg: Signature made Tue 13 Oct 2015 10:18:01 AM CEST using RSA key ID 33BD3F06\ngpg: Good signature from \"NIIBE Yutaka (GnuPG Release Key) &lt;gniibe@fsij.org&gt;\" [unknown]\ngpg: WARNING: This key is not certified with a trusted signature!\ngpg:          There is no indication that the signature belongs to the owner.\nPrimary key fingerprint: 031E C253 6E58 0D8E A286  A9F2 2071 B08A 33BD 3F06\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre> <p>then you have a copy of our keys and the signatures are valid, but either you have not marked the keys as trusted or the keys are a forgery.  In this case, at the very least, you should compare the fingerprints that are shown to those on the signing keys page.  Even better is to compare the fingerprints with those shown on our business cards, which we handout at events that we attend.  Ideally, you\u2019ll see something like: </p> <pre><code>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ngpg: Signature made Fri 09 Oct 2015 05:41:55 PM CEST using RSA key ID 4F25E3B6\ngpg: Good signature from \"Werner Koch (dist sig)\" [full]\ngpg: Signature made Tue 13 Oct 2015 10:18:01 AM CEST using RSA key ID 33BD3F06\ngpg: Good signature from \"NIIBE Yutaka (GnuPG Release Key) &lt;gniibe@fsij.org&gt;\" [full]\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n</code></pre> <p>This means that the signature is valid and that you trust this key (either you signed it or someone you trusted did). </p>","tags":["various","gpg","cli"]},{"location":"Linux/GPG/#comparing-checksums","title":"Comparing Checksums","text":"<p>If you are not able to use an old version of GnuPG, you can still verify the file\u2019s SHA-1 checksum.  This is less secure, because if someone modified the files as they were transferred to you, it would not be much more effort to modify the checksums that you see on this webpage.  As such, if you use this method, you should compare the checksums with those in release announcement.  This is sent to the gnupg-announce mailing list (among others), which is widely mirrored.  Don\u2019t use the mailing list archive on this website, but find the announcement on several other websites and make sure the checksum is consistent.  This makes it more difficult for an attacker to trick you into installing a modified version of the software.  Assuming you downloaded the file gnupg-2.0.30.tar.bz2, you can run the sha1sum command like this: </p> <pre><code>sha1sum gnupg-2.0.30.tar.bz2\n</code></pre> <p>and check that the output matches the SHA-1 checksum reported on this site. An example of a sha1sum output is: </p> <pre><code>a9f024588c356a55e2fd413574bfb55b2e18794a  gnupg-2.0.30.tar.bz2\n</code></pre>","tags":["various","gpg","cli"]},{"location":"Linux/GPG/#list-of-sha-1-check-sums","title":"List of SHA-1 check-sums","text":"<p>For your convenience, all SHA-1 check-sums available for software that can be downloaded from our site, have been gathered below. </p> <pre><code>67540161c9fe289153c4a5ea60f7cdce0ef48897  gnupg-2.1.16.tar.bz2\n50b0bd286faa90e5c71417b5f2f36cf5de964084  gnupg-w32-2.1.16_20161118.exe\na9f024588c356a55e2fd413574bfb55b2e18794a  gnupg-2.0.30.tar.bz2\n8ab7494e40f80f4138edc9516981bf4afe7d9dbf  libgpg-error-1.25.tar.bz2\n5a034291e7248592605db448481478e6c963aa9c  libgcrypt-1.7.3.tar.bz2\na98385734a0c3f5b713198e8d6e6e4aeb0b76fde  libksba-1.3.5.tar.bz2\n27391cf4a820b5350ea789c30661830c9a271518  libassuan-2.4.3.tar.bz2\n1b21507cfa3f58bdd19ef2f6800ab4cb67729972  npth-1.3.tar.bz2\n85d9ac81ebad3fb082514c505c90c39a0456f1f6  pinentry-1.0.0.tar.bz2\nefa043064dbf675fd713228c6fcfcc4116feb221  gpgme-1.8.0.tar.bz2\nc629348725c1bf5dafd57f8a70187dc89815ce60  gpa-0.9.10.tar.bz2\ne708d4aa5ce852f4de3f4b58f4e4f221f5e5c690  dirmngr-1.1.1.tar.bz2\ne3bdb585026f752ae91360f45c28e76e4a15d338  gnupg-1.4.21.tar.bz2\n8edea5cda7dc9e39d12b24cf12164b28b832918d  gnupg-w32cli-1.4.21.exe\n</code></pre>","tags":["various","gpg","cli"]},{"location":"Linux/Get_file_creation_time/","title":"Get file creation time","text":"","tags":["shell","cli","fs"]},{"location":"Linux/Get_file_creation_time/#step-1-find-inode-number-of-any-file-using-following-command-on-terminal","title":"Step 1: Find inode number of any file using following command on terminal.","text":"<pre><code>ls -i /var/log/messages 13377 /var/log/messages\n</code></pre>","tags":["shell","cli","fs"]},{"location":"Linux/Get_file_creation_time/#step-2-find-file-creation-time-crtime","title":"Step 2: Find File Creation Time (crtime)","text":"<pre><code>debugfs -R 'stat &lt;inode_number&gt;' /dev/sda1\n</code></pre>","tags":["shell","cli","fs"]},{"location":"Linux/Get_process_info/","title":"Get process info","text":"","tags":["cli","linux"]},{"location":"Linux/Get_process_info/#list-thread-of-a-process","title":"List thread of a process","text":"<pre><code>ps -C firefox -L -o pid,tid,pcpu,state,nlwp,cmd\n</code></pre>","tags":["cli","linux"]},{"location":"Linux/Get_process_info/#see-used-resident-memory","title":"See used Resident Memory","text":"<pre><code>ps -eF --sort -rss\n</code></pre>","tags":["cli","linux"]},{"location":"Linux/Get_process_info/#sort-by-process-using-swap","title":"Sort by process using SWAP","text":"<pre><code>(echo \"COMM PID SWAP\"; for file in /proc/*/status ; do awk '/^Pid|VmSwap|Name/{printf $2 \" \" $3}END{ print \"\"}' $file; done | grep kB | grep -wv \"0 kB\" | sort -k 3 -n -r) | column -t\n</code></pre>","tags":["cli","linux"]},{"location":"Linux/Git/","title":"Git","text":"","tags":["various","git","cli"]},{"location":"Linux/Git/#rename-git-branch","title":"Rename Git Branch","text":"<p>Start by switching to the local branch which you want to rename:</p> <pre><code>git checkout &lt;old_name&gt;\n</code></pre> <p>Rename the local branch by typing:</p> <pre><code>git branch -m &lt;new_name&gt;\n</code></pre> <p>At this point, you have renamed the local branch. If you\u2019ve already pushed the  branch to the remote repository, perform the next steps to rename the remote branch. Push the  local branch and reset the upstream branch: <pre><code>git push origin -u &lt;new_name&gt;\n</code></pre> <p>Delete the  remote branch: <pre><code>git push origin --delete &lt;old_name&gt;\n</code></pre>","tags":["various","git","cli"]},{"location":"Linux/Git/#sign-git-commits-with-gpg","title":"Sign Git commits with GPG","text":"<ul> <li> <p>Declare key to be used</p> <p>git config \u2013global user.signingkey A34RED67G4 </p> </li> <li> <p>now you can add the <code>-S</code> flag when committing</p> <p>git commit -S</p> </li> <li> <p>or you can ask Git to automatically sign all your future commits</p> <p>git config \u2013global commit.gpgsign true</p> </li> <li> <p>To check a commit</p> <p>git verify-commit cce09ca</p> </li> </ul>","tags":["various","git","cli"]},{"location":"Linux/Git/#clear-git-history-without-removing-repository","title":"Clear Git history without removing repository","text":"<pre><code>cd myrepo\nrm -rf .git\n\ngit init\ngit add .\ngit commit -m \"initial commit\"\n\ngit remote add origin github.com:yourhandle/yourrepo.git\ngit push -u --force origin master\n</code></pre>","tags":["various","git","cli"]},{"location":"Linux/Git/#delete-a-file-from-all-commits-in-a-branch","title":"Delete a file from all commits in a branch","text":"<pre><code>git filter-branch --tree-filter 'rm -rf path/to/file.ext' &lt;BRANCH&gt;\n</code></pre>","tags":["various","git","cli"]},{"location":"Linux/Git/#delete-all-tags-locally-and-remotely","title":"Delete all tags locally and remotely","text":"<p>Delete All local tags. (Optional Recommended)</p> <pre><code>git tag -d $(git tag -l)\n</code></pre> <p>Fetch remote All tags. (Optional Recommended)</p> <pre><code>git fetch\n</code></pre> <p>Delete All remote tags.</p> <p>Note</p> <p>pushing once should be faster than multiple times</p> <p>git push origin \u2013delete $(git tag -l) </p> <p>Delete All local tags.</p> <pre><code>git tag -d $(git tag -l)\n</code></pre>","tags":["various","git","cli"]},{"location":"Linux/Grep_regex/","title":"Grep","text":""},{"location":"Linux/Grep_regex/#adresse-ip","title":"Adresse IP","text":"<pre><code>my_command | grep -oE \"\\b([0-9]{1,3}\\.){3}[0-9]{1,3}\\b\"\n</code></pre>"},{"location":"Linux/MPD/","title":"MPD","text":"","tags":["cli","network"]},{"location":"Linux/MPD/#piper-du-fifo-via-netcat-pour-mpd","title":"Piper du fifo via netcat (pour MPD)","text":"<ul> <li> <p>Mettre nc en \u00e9coute sur le port 1234</p> <p>nc -l 1234 </p> </li> <li> <p>Sur la machine distante :</p> <p>nc 192.168.11.90 1234 &lt; /net/musique/mpd.fifo</p> </li> </ul>","tags":["cli","network"]},{"location":"Linux/Memo/","title":"Memo","text":""},{"location":"Linux/Memo/#suppr-all-output","title":"Suppr all output","text":"<pre><code>&gt;/dev/null 2&gt;&amp;1\n</code></pre>"},{"location":"Linux/Memo/#rescan-disk-size","title":"Rescan disk size","text":"<pre><code>echo 1&gt;/sys/class/block/sdd/device/rescan\n</code></pre>"},{"location":"Linux/Memo/#python-convertir-un-resultat-pipe-en-json-yaml","title":"Python: Convertir un r\u00e9sultat pip\u00e9 en json \u2192 yaml","text":"<pre><code>python -c 'import sys, yaml, json;  yaml.safe_dump(json.load(sys.stdin), sys.stdout, default_flow_style=False)'\n</code></pre>"},{"location":"Linux/Memo/#generate-tilix-bookmarks-from-ssh-config","title":"Generate Tilix bookmarks from SSH config","text":"<pre><code>#!/bin/bash\n\n# FILE=$HOME/.config/tilix/bookmarks.json\necho -e \"{\\n\\t\\\"list\\\": [\\n\" &gt; \"$FILE\"\nfor i in $(cat ~/.ssh/config | grep \"Host\\ \" | awk '{print $2}' | grep -v \"*\" | sort)\ndo\n    echo -e \"\\t\\t{\\n\\t\\t\\t\\\"command\\\": \\\"\\\",\\n\\t\\t\\t\\\"host\\\": \\\"$i\\\",\\n\\t\\t\\t\\\"name\\\": \\\"$i\\\",\\n\\t\\t\\t\\\"params\\\": \\\"\\\",\\n\\t\\t\\t\\\"port\\\": 22,\\n\\t\\t\\t\\\"protocolType\\\": \\\"SSH\\\",\\n\\t\\t\\t\\\"type\\\": \\\"REMOTE\\\",\\n\\t\\t\\t\\\"user\\\": \\\"root\\\"\\n\\t\\t},\" \\\n    | sed 's/\\t/\\ \\ \\ \\ /g'\ndone &gt;&gt; \"$FILE\"\necho -e \"\\t]\\n}\\n\" &gt;&gt; \"$FILE\"\n</code></pre>"},{"location":"Linux/RSyslog/","title":"RSyslog","text":"","tags":["server","log","linux"]},{"location":"Linux/RSyslog/#setup-for-rsyslog-configuration","title":"Setup for rsyslog configuration","text":"<pre><code>### Provides TCP syslog reception\nmodule(load=\"imtcp\" maxSessions=\"500\")\n### Config for secure TLS connection\n#    streamDriver.name=\"gtls\"\n#    streamDriver.mode=\"1\"\n#    streamDriver.authMode=\"x509/name\"\n#    permittedPeer=[\"*.accelance.net\",\"*.domain.tld\"])\n\n### Define name template for received logs\n$template RemoteHost,\"/var/log/hosts/%HOSTNAME%/%programname%.log\"\n\n### Define rules to be applied to received logs\n#   here we send them to the dynamic files defined in above template\nruleset(name=\"writeRemoteData\"\n    queue.type=\"fixedArray\"\n    queue.size=\"250000\"\n    queue.dequeueBatchSize=\"4096\"\n    queue.workerThreads=\"4\"\n    queue.workerThreadMinimumMessages=\"60000\"\n    ) {\n    action(type=\"omfile\" dynafile=\"RemoteHost\"\n    ioBufferSize=\"64k\" flushOnTXEnd=\"off\"\n    asyncWriting=\"on\")\n}\n\n### Define input module\ninput(type=\"imtcp\"\n    port=\"514\"\n    address=\"10.10.48.48\"\n    ruleset=\"writeRemoteData\")\n</code></pre>","tags":["server","log","linux"]},{"location":"Linux/RSyslog/#pf-rules","title":"pf rules","text":"<pre><code>pass quick proto tcp from { 213.162.55.19 } to { 10.10.48.48 } port 514\n</code></pre>","tags":["server","log","linux"]},{"location":"Linux/RSyslog/#configure-log-rotation-for-collected-logs","title":"configure log rotation for collected logs","text":"<pre><code>/var/log/hosts/*/*.log\n{\n    missingok\n    compress\n    create 0400 root root\n    daily\n    dateformat %Y%m%d\n    rotate 90\n}\n</code></pre>","tags":["server","log","linux"]},{"location":"Linux/Repair_broken_GRUB/","title":"Repair broken GRUB","text":"","tags":["cli","linux"]},{"location":"Linux/Repair_broken_GRUB/#how-to-fix-a-broken-grub","title":"How to fix a broken GRUB","text":"<ul> <li> <p>D\u00e9marrer sur un live</p> </li> <li> <p>Monter partition racine</p> <p>mount /dev/sda1 /mnt cd /mnt</p> </li> <li> <p>Monter les syst\u00e8mes volatils</p> <p>mount -t proc proc proc/ mount \u2013rbind /sys sys/ mount \u2013rbind /dev dev/</p> </li> <li> <p>Chroot</p> <p>chroot /mnt</p> </li> <li> <p>M\u00e0J du path</p> <p>export PATH=/bin:/sbin:/usr/sbin:/usr/bin</p> </li> <li> <p>Installer Grub (commande d\u00e9pend de l\u2019OS</p> <p>grub2-install /dev/sda update-grub || grub2-mkconfig -o /boot/grub/grub.cfg update-initramfs -u</p> </li> </ul>","tags":["cli","linux"]},{"location":"Linux/SELinux/","title":"SELinux","text":"","tags":["server","linux"]},{"location":"Linux/SELinux/#selinux-tricks","title":"SELINUX tricks","text":"","tags":["server","linux"]},{"location":"Linux/SELinux/#changer-le-contexte-des-objets-http","title":"Changer le contexte des objets http","text":"<pre><code>chcon -R -v --type=httpd_sys_content_t /srv/repo/path/\n</code></pre>","tags":["server","linux"]},{"location":"Linux/SELinux/#rendre-ce-reglage-persistent","title":"Rendre ce r\u00e9glage persistent","text":"<pre><code>semanage fcontext -a -t httpd_sys_content_t \"/srv/repo/path(/.*)?\"\n</code></pre>","tags":["server","linux"]},{"location":"Linux/SELinux/#desactier-selinux-temp","title":"d\u00e9sactier selinux temp","text":"<pre><code>setenforce 0\n</code></pre>","tags":["server","linux"]},{"location":"Linux/SELinux/#voir-status","title":"voir status","text":"<pre><code>sestatus\n</code></pre>","tags":["server","linux"]},{"location":"Linux/SELinux/#preserving-selinux-contexts-when-copying","title":"Preserving SELinux Contexts When Copying","text":"<p>Use the cp \u2013preserve=context command to preserve contexts when copying:</p> <pre><code>touch file1\nls -Z file1\n-rw-rw-r--  user1 group1 unconfined_u:object_r:user_home_t:s0 file1\nls -dZ /var/www/html/\ndrwxr-xr-x  root root system_u:object_r:httpd_sys_content_t:s0 /var/www/html/\ncp --preserve=context file1 /var/www/html/\nls -Z /var/www/html/file1\n-rw-r--r--  root root unconfined_u:object_r:user_home_t:s0 /var/www/html/file1\n</code></pre>","tags":["server","linux"]},{"location":"Linux/SSH/","title":"SSH","text":"","tags":["network","cli","ssh"]},{"location":"Linux/SSH/#start-graphical-app-via-ssh","title":"Start graphical app via SSH","text":"<p>You have to set DISPLAY and XAUTHORITY properly, e.g.:</p> <pre><code>ssh host\n</code></pre> <p>on host:</p> <pre><code>export DISPLAY=:0.0\nexport XAUTHORITY=$HOME/.local/share/sddm/.Xauthority\nstart_graphical_application\n</code></pre>","tags":["network","cli","ssh"]},{"location":"Linux/SSH/#pipe-between-2-servers","title":"Pipe between 2 servers","text":"<pre><code>ssh server1 'cat /root/file' | ssh server2 'cat &gt; destfile'\n</code></pre>","tags":["network","cli","ssh"]},{"location":"Linux/SSH/#reverse-ssh","title":"Reverse SSH","text":"","tags":["network","cli","ssh"]},{"location":"Linux/SSH/#connexion-directe","title":"Connexion directe","text":"","tags":["network","cli","ssh"]},{"location":"Linux/SSH/#creation-dun-utilisateur-dedie-sur-le-poste-local","title":"Cr\u00e9ation d\u2019un utilisateur d\u00e9di\u00e9 sur le poste local","text":"<p>Cr\u00e9ez un nouvel utilisateur sp\u00e9cialement pour cette connexion afin que l\u2019utilisateur userD du poste distant ne puisse pas avoir un acc\u00e8s complet au poste local. Ce nouvel utilisateur cr\u00e9\u00e9 pourra cependant avoir des droits personnalis\u00e9s. Saisissez dans un terminal sur local la commande suivante :</p> <pre><code>sudo adduser --no-create-home userL\n</code></pre> <p>o\u00f9 :</p> <ul> <li>\u2013no-create-home est l\u2019option sp\u00e9cifi\u00e9e pour ne pas cr\u00e9er de dossier /home/userL sur le poste local.</li> <li>userL est \u00e0 remplacer par le nom de votre choix mais suffisamment explicite pour savoir sur quelle machine vous \u00eates. Le mot de passe cr\u00e9\u00e9 servira pour se connecter lors de l\u2019\u00e9tape suivante.</li> </ul>","tags":["network","cli","ssh"]},{"location":"Linux/SSH/#connexion-au-poste-local-depuis-le-poste-distant","title":"Connexion au poste local depuis le poste distant","text":"<p>Initiez une connexion \u00e0 local en saisissant sur le poste distant:</p> <pre><code>ssh -NR 12345:localhost:22 userL@local\n</code></pre> <p>o\u00f9</p> <ul> <li>12345 est \u00e0 remplacer par un num\u00e9ro de port al\u00e9atoire (entre 1024 et 65535 qui sont r\u00e9serv\u00e9s pour des applications utilisateurs) et non utilis\u00e9 de votre choix</li> <li>userL et le mot de passe de connexion sont ceux d\u00e9fini pr\u00e9c\u00e9demment.</li> <li>local est l\u2019adresse IP publique de la machine locale (au besoin avec une r\u00e8gle NAT dans la box locale pour \u00eatre joignable de l\u2019ext\u00e9rieur)</li> </ul>","tags":["network","cli","ssh"]},{"location":"Linux/SSH/#connexion-au-poste-distant-depuis-le-poste-local","title":"Connexion au poste distant depuis le poste local","text":"<p>La connexion \u00e9tant d\u00e9sormais activ\u00e9e depuis distant vers local, le pare-feu va donc laisser rentrer la connexion reverse, \u00e0 savoir depuis local vers distant. Pour cela taper dans un terminal sur local:</p> <pre><code>ssh -p 12345 userD@localhost\n</code></pre> <p>o\u00f9</p> <ul> <li>12345 est le port choisi auparavant</li> <li>userD est \u00e0 remplacer par le nom d\u2019utilisateur permettant de se connecter au serveur ssh sur distant</li> </ul> <p>Cette configuration est pratique quand le poste local est lui-m\u00eame derri\u00e8re un pare-feu et/ou ne dispose pas d\u2019un serveur ssh. Prenez l\u2019exemple de configuration suivant:</p>","tags":["network","cli","ssh"]},{"location":"Linux/SSH/#connexion-par-serveur-tiers","title":"Connexion par serveur tiers","text":"<p>userD@distant et userL@local ne sont pas accessibles depuis l\u2019ext\u00e9rieur</p> <p>Ici</p> <ul> <li>userD@distant correspond \u00e0 l\u2019utilisateur userD, sur le poste appel\u00e9 distant qui a les ports entrants bloqu\u00e9s et donc inaccessible depuis l\u2019ext\u00e9rieur</li> <li>userS@serveur correspond \u00e0 l\u2019utilisateur userS, sur le poste appel\u00e9 serveur qui dispose d\u2019un acc\u00e8s libre \u00e0 son serveur ssh.</li> <li>userL@local correspond \u00e0 l\u2019utilisateur userL, sur le poste appel\u00e9 local qui va acc\u00e9der \u00e0 la machine serveur pour atteindre distant</li> </ul> <p>Pour r\u00e9sum\u00e9 le principe, il s\u2019agira de:</p> <ul> <li>connecter distant sur serveur</li> <li>connecter local sur serveur</li> <li>depuis le terminal qui a initi\u00e9 la connexion local sur serveur pour atteindre distant</li> </ul>","tags":["network","cli","ssh"]},{"location":"Linux/SSH/#creation-dun-utilisateur-dedie-sur-le-poste-serveur","title":"Cr\u00e9ation d\u2019un utilisateur d\u00e9di\u00e9 sur le poste serveur","text":"<p>Cette partie est facultative si la machine serveur dispose d\u00e9j\u00e0 d\u2019un utilisateur public</p> <p>Taper dans un terminal :</p> <pre><code>sudo adduser --no-create-home userS\n</code></pre>","tags":["network","cli","ssh"]},{"location":"Linux/SSH/#connexion-sur-le-poste-serveur-depuis-le-poste-distant","title":"Connexion sur le poste serveur depuis le poste distant","text":"<p>Initiez une connexion sur serveur en tapant dans un terminal de la machine distant :</p> <pre><code>ssh -R 12345:localhost:22 userS@serveur\n</code></pre> <p>o\u00f9</p> <ul> <li>12345 est \u00e0 remplacer par un num\u00e9ro de port al\u00e9atoire de votre choix,</li> <li>le port 22 est le port d\u2019\u00e9coute ssh sur la machine distant,</li> <li>userS et le mot de passe de connexion sont ceux d\u00e9fini pr\u00e9c\u00e9demment</li> <li>serveur est l\u2019adresse ip ou le nom de domaine du serveur tiers</li> </ul> <p>Note</p> <p>L\u2019option -N peut \u00e9galement \u00eatre ajout\u00e9e pour ne pas faire apparaitre d\u2019invite de terminal sur distant</p>","tags":["network","cli","ssh"]},{"location":"Linux/SSH/#connexion-sur-le-poste-serveur-depuis-le-poste-local","title":"Connexion sur le poste serveur depuis le poste local","text":"<p>Cr\u00e9er un pont entre serveur et local en tapant dans un terminal de ce dernier</p> <pre><code>ssh userS@serveur\n</code></pre>","tags":["network","cli","ssh"]},{"location":"Linux/SSH/#acces-a-la-machine-distante-depuis-la-machine-locale","title":"Acc\u00e8s \u00e0 la machine distante depuis la machine locale","text":"<p>Vous pouvez d\u00e9sormais atteindre le poste distant en saisissant dans le terminal du poste local connect\u00e9 pr\u00e9c\u00e9demment sur serveur</p> <pre><code>ssh -p 12345 userD@localhost\n</code></pre>","tags":["network","cli","ssh"]},{"location":"Linux/SSH/#obtenir-les-cles-de-la-machine-locale","title":"Obtenir les cl\u00e9s de la machine locale","text":"<pre><code>ssh-keyscan -t ecdsa-sha2-nistp256 localhost | ssh-keygen -lf -\n</code></pre>","tags":["network","cli","ssh"]},{"location":"Linux/Sed/","title":"Sed","text":"","tags":["cli","sed","linux","shell"]},{"location":"Linux/Sed/#sed-tricks","title":"Sed tricks","text":"","tags":["cli","sed","linux","shell"]},{"location":"Linux/Sed/#to-remove-the-line-and-print-the-output-to-standard-out","title":"To remove the line and print the output to standard out:","text":"<pre><code>sed '/pattern to match/d' ./infile\n</code></pre>","tags":["cli","sed","linux","shell"]},{"location":"Linux/Sed/#to-directly-modify-the-file","title":"To directly modify the file:","text":"<pre><code>sed -i '/pattern to match/d' ./infile\n</code></pre>","tags":["cli","sed","linux","shell"]},{"location":"Linux/Sed/#to-directly-modify-the-file-and-create-a-backup","title":"To directly modify the file (and create a backup):","text":"<pre><code>sed -i.bak '/pattern to match/d' ./infile\n</code></pre>","tags":["cli","sed","linux","shell"]},{"location":"Linux/Sed/#delete-n-lines-in-a-file","title":"Delete N lines in a file","text":"<p>As long as the file is not a symlink or hardlink, you can use sed, tail, or awk. Example below.</p> <pre><code>$ cat t.txt\n12\n34\n56\n78\n90\n\n$ sed -e '1,3d' &lt; t.txt\n78\n90\n</code></pre>","tags":["cli","sed","linux","shell"]},{"location":"Linux/Sed/#delete-empty-lines","title":"Delete empty lines","text":"<pre><code>sed '/^\\s*$/d'\n</code></pre>","tags":["cli","sed","linux","shell"]},{"location":"Linux/Sed/#sed-remove-and-empty-lines-with-one-sed-command","title":"sed + remove # and empty lines with one sed command","text":"<pre><code>sed -e 's/#.*$//' -e '/^$/d' inputFile\n</code></pre>","tags":["cli","sed","linux","shell"]},{"location":"Linux/Sed/#remove-trailing-witespaces","title":"Remove trailing witespaces","text":"<pre><code>sed -i 's/[ \\t]*$//' file\n</code></pre>","tags":["cli","sed","linux","shell"]},{"location":"Linux/Sed/#replace-between-strings","title":"Replace between strings","text":"<pre><code>sed -n -e '/Word A/,/Word D/ p' file\n</code></pre>","tags":["cli","sed","linux","shell"]},{"location":"Linux/Sed/#remove-carriage-return-and-merge-lines","title":"Remove carriage return and merge lines","text":"<pre><code># exemple to remove 'server_alias' from line 2 and merge it with line 1:\nsed -e ':a' -e 'N' -e '$!ba' -e 's/\\;\\n  server_alias//g' -i file\n</code></pre>","tags":["cli","sed","linux","shell"]},{"location":"Linux/Sed/#insert-new-line-at-top-of-file","title":"Insert new line at top of file","text":"<pre><code># 1i is important, the leading \\ pushes the content at line 2\nsed -i -e '1i# {{ ansible_managed }}\\' $file\n</code></pre>","tags":["cli","sed","linux","shell"]},{"location":"Linux/Sed/#replace-new-lines-by-spaces","title":"Replace new lines by spaces","text":"<pre><code>sed ':a;N;$!ba;s/\\n/ /g' $file\n</code></pre>","tags":["cli","sed","linux","shell"]},{"location":"Linux/Set_Kernel_in_Grub/","title":"Set Kernel version in Grub","text":"<p>1) Find the $menuentry_id_option for the submenu:</p> <pre><code>    grep submenu /boot/grub/grub.cfg\n\n    submenu 'Advanced options for Debian GNU/Linux' $menuentry_id_option 'gnulinux-advanced-38ea4a12-6cfe-4ed9-a8b5-036295e62ffc' {\n</code></pre> <p>1) Find the $menuentry_id_option for the menu entry for the kernel you want to use:</p> <pre><code>    grep gnulinux /boot/grub/grub.cfg\n\n    menuentry 'Debian GNU/Linux' --class debian --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-simple-38ea4a12-6cfe-4ed9-a8b5-036295e62ffc' {\n    submenu 'Advanced options for Debian GNU/Linux' $menuentry_id_option 'gnulinux-advanced-38ea4a12-6cfe-4ed9-a8b5-036295e62ffc' {\n        menuentry 'Debian GNU/Linux, with Linux 4.18.0-0.bpo.1-rt-amd64' --class debian --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.18.0-0.bpo.1-rt-amd64-advanced-38ea4a12-6cfe-4ed9-a8b5-036295e62ffc' {\n        menuentry 'Debian GNU/Linux, with Linux 4.18.0-0.bpo.1-rt-amd64 (recovery mode)' --class debian --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.18.0-0.bpo.1-rt-amd64-recovery-38ea4a12-6cfe-4ed9-a8b5-036295e62ffc' {\n        menuentry 'Debian GNU/Linux, with Linux 4.18.0-0.bpo.1-amd64' --class debian --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.18.0-0.bpo.1-amd64-advanced-38ea4a12-6cfe-4ed9-a8b5-036295e62ffc' {\n        menuentry 'Debian GNU/Linux, with Linux 4.18.0-0.bpo.1-amd64 (recovery mode)' --class debian --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.18.0-0.bpo.1-amd64-recovery-38ea4a12-6cfe-4ed9-a8b5-036295e62ffc' {\n        menuentry 'Debian GNU/Linux, with Linux 4.17.0-0.bpo.1-amd64' --class debian --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.17.0-0.bpo.1-amd64-advanced-38ea4a12-6cfe-4ed9-a8b5-036295e62ffc' {\n        menuentry 'Debian GNU/Linux, with Linux 4.17.0-0.bpo.1-amd64 (recovery mode)' --class debian --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.17.0-0.bpo.1-amd64-recovery-38ea4a12-6cfe-4ed9-a8b5-036295e62ffc' {\n        menuentry 'Debian GNU/Linux, with Linux 4.9.0-8-amd64' --class debian --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.9.0-8-amd64-advanced-38ea4a12-6cfe-4ed9-a8b5-036295e62ffc' {\n        menuentry 'Debian GNU/Linux, with Linux 4.9.0-8-amd64 (recovery mode)' --class debian --class gnu-linux --class gnu --class os $menuentry_id_option 'gnulinux-4.9.0-8-amd64-recovery-38ea4a12-6cfe-4ed9-a8b5-036295e62ffc' {\n</code></pre> <p>1) Comment out your current default grub in <code>/etc/default/grub</code> and replace it with the sub-menu\u2019s $menuentry_id_option from step one, and the selected kernel\u2019s $menuentry_id_option from step two separated by \u2018&gt;\u2019.</p> <p>In my case the modified GRUB_DEFAULT is:</p> <pre><code>#GRUB_DEFAULT=0\n\nGRUB_DEFAULT=\"gnulinux-advanced-38ea4a12-6cfe-4ed9-a8b5-036295e62ffc&gt;gnulinux-4.18.0-0.bpo.1-amd64-advanced-38ea4a12-6cfe-4ed9-a8b5-036295e62ffc\"\n</code></pre> <p>1) Update grub to make the changes. For Debian this is done like so:</p> <pre><code>    update-grub\n</code></pre> <p>Done. Now when you boot, the advanced menu should have an asterisk and you should boot into the selected kernel. You can confirm this with uname.</p> <pre><code>uname -a\nLinux NAME 4.18.0-0.bpo.1-amd64 #1 SMP Debian 4.18.0-0 (2018-09-13) x86_64 GNU/Linux\n</code></pre> <p>Changing this back to the most recent kernel is as simple as commenting out the new line and uncommenting <code>#GRUB_DEFAULT=0</code></p> <pre><code>GRUB_DEFAULT=0\n\n#GRUB_DEFAULT=\"gnulinux-advanced-38ea4a12-6cfe-4ed9-a8b5-036295e62ffc&gt;gnulinux-4.18.0-0.bpo.1-amd64-advanced-38ea4a12-6cfe-4ed9-a8b5-036295e62ffc\"\n</code></pre> <p>then rerunning</p> <pre><code>update-grub\n</code></pre>"},{"location":"Linux/Tmpfs/","title":"Add userland tmpfs","text":"<ol> <li> <p>Create dir</p> <p>mkdir $HOME/tmp</p> </li> <li> <p>Add entry in <code>/etc/fstab</code></p> <p>tmpfs                                   /home/sebastien/tmp     tmpfs   user,exec,rw,size=2G                0 0</p> </li> </ol>"},{"location":"Linux/Tmux/","title":"Tmux","text":""},{"location":"Linux/Tmux/#autostart-tmux-with-systemd","title":"Autostart Tmux with systemd","text":"<pre><code>\\#/etc/systemd/system/tmux@.service\n\n[Unit]\nDescription=Start tmux in detached session\n\n[Service]\nType=forking\nUser=%I\nWorkingDirectory=/home/%I\nExecStart=/usr/bin/tmux new-session -s %u -d\nExecStop=/usr/bin/tmux kill-session -t %u\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"Linux/Vim/","title":"Vim","text":"","tags":["cli","vim"]},{"location":"Linux/Vim/#vim","title":"Vim","text":"<ul> <li> <p>Remplacer un caract\u00e8re par un retour \u00e0 la ligne :</p> <p>Utiliser \u201c \\r \u201c au lieu de \u201d\\n\u201d.</p> </li> </ul> <p>Running a macro (http://vim.wikia.com/wiki/Macros) Use this mapping as a convenient way to play a macro recorded to register q:</p> <pre><code>:nnoremap &lt;Space&gt; @q\n</code></pre> <p>\u2022 Start recording keystrokes by typing qq. \u2022 End recording with q (first press Escape if you are in insert mode). \u2022 Play the recorded keystrokes by hitting space. Suppose you have a macro which operates on the text in a single line. You can run the macro on each line in a visual selection in a single operation: \u2022 Visually select some lines (for example, type vip to select the current paragraph). \u2022 Type :normal @q to run the macro from register q on each line.</p> <p>Vim has a very powerful built-in sort utility, or it can interface with an external one. In order to keep only unique lines in Vim, you would:</p> <pre><code>:{range}sort u\n</code></pre> <ul> <li> <p>Remove all trailing spaces</p> <p>:%s/\\s+$//e</p> </li> <li> <p>Vimdiff local and remote files via ssh</p> <p>vimdiff /path/to/file scp://remotehost//path/to/file</p> </li> <li> <p>Enregistrer un fichier en tant que root</p> <p>:w !sudo tee %</p> </li> <li> <p>Remove blank line from a file</p> <p>:g/^$/d</p> </li> </ul>","tags":["cli","vim"]},{"location":"Linux/openSSL/","title":"openSSL","text":"","tags":["ssl","cert","libvirt"]},{"location":"Linux/openSSL/#check-ssl-state","title":"Check SSL state","text":"<pre><code>openssl s_client -connect HOTE:443 -CApath /etc/ssl/certs\n</code></pre>","tags":["ssl","cert","libvirt"]},{"location":"Linux/openSSL/#generate-a-self-signed-certificate","title":"Generate a self signed certificate","text":"<pre><code># create custom CA\n\nCANAME=MyOrg-RootCA\n\n# optional, create a directory\n\nmkdir $CANAME\ncd $CANAME\n\n# generate aes encrypted private key\n\nopenssl genrsa -aes256 -out $CANAME.key 4096\n\n# create certificate, 1826 days = 5 years, 3650 days = 10 years, 7300 days \u00b1 20 years\n\nopenssl req -x509 -new -nodes -key $CANAME.key -sha256 -days 1826 -out $CANAME.crt -subj '/CN=My Root CA/C=AT/ST=MyCountry/L=MyCity/O=MyOrganisation'\n\n# create certificate for service\n\nMYCERT=myserver.local\nopenssl req -new -nodes -out $MYCERT.csr -newkey rsa:4096 -keyout $MYCERT.key -subj '/CN=My Firewall/C=AT/ST=MyCountry/L=MyCity/O=MyOrganisation'\n\n# create a v3 ext file for SAN properties\n\ncat &gt; $MYCERT.v3.ext &lt;&lt; EOF\nauthorityKeyIdentifier=keyid,issuer\nbasicConstraints=CA:FALSE\nkeyUsage = digitalSignature, nonRepudiation, keyEncipherment, dataEncipherment\nsubjectAltName = @alt_names\n[alt_names]\nDNS.1 = myserver.local\nDNS.2 = myserver1.local\nIP.1 = 192.168.1.1\nIP.2 = 192.168.2.1\nEOF\n\n# sign the certificate\nopenssl x509 -req -in $MYCERT.csr -CA $CANAME.crt -CAkey $CANAME.key -CAcreateserial -out $MYCERT.crt -days 730 -sha256 -extfile $MYCERT.v3.ext\n</code></pre>","tags":["ssl","cert","libvirt"]},{"location":"Linux/openSSL/#decode-certif-p12","title":"Decode certif p12","text":"<pre><code>openssl pkcs12 -in keyStore.pfx -out keyStore.pem -nodes\n</code></pre>","tags":["ssl","cert","libvirt"]},{"location":"Linux/openSSL/#libvirt-cert-creation-script","title":"Libvirt cert creation script","text":"<pre><code>#!/bin/bash\n\nSERVER_KEY=server-key.pem\n\n# creating a key for our ca\nif [ ! -e ca-key.pem ]; then\n openssl genrsa -des3 -out ca-key.pem 1024\nfi\n# creating a ca\nif [ ! -e ca-cert.pem ]; then\n openssl req -new -x509 -days 1095 -key ca-key.pem -out ca-cert.pem  -subj \"/C=IL/L=Raanana/O=Red Hat/CN=my CA\"\nfi\n# create server key\nif [ ! -e $SERVER_KEY ]; then\n openssl genrsa -out $SERVER_KEY 1024\nfi\n# create a certificate signing request (csr)\nif [ ! -e server-key.csr ]; then\n openssl req -new -key $SERVER_KEY -out server-key.csr -subj \"/C=IL/L=Raanana/O=Red Hat/CN=my server\"\nfi\n# signing our server certificate with this ca\nif [ ! -e server-cert.pem ]; then\n openssl x509 -req -days 1095 -in server-key.csr -CA ca-cert.pem -CAkey ca-key.pem -set_serial 01 -out server-cert.pem\nfi\n\n# now create a key that doesn't require a passphrase\nopenssl rsa -in $SERVER_KEY -out $SERVER_KEY.insecure\nmv $SERVER_KEY $SERVER_KEY.secure\nmv $SERVER_KEY.insecure $SERVER_KEY\n\n# show the results (no other effect)\nopenssl rsa -noout -text -in $SERVER_KEY\nopenssl rsa -noout -text -in ca-key.pem\nopenssl req -noout -text -in server-key.csr\nopenssl x509 -noout -text -in server-cert.pem\nopenssl x509 -noout -text -in ca-cert.pem\n\n# copy *.pem file to /etc/pki/libvirt-spice\nif [[ ! -d \"/etc/pki/libvirt-spice\" ]] \nthen\n mkdir -p /etc/pki/libvirt-spice\nfi\ncp ./*.pem /etc/pki/libvirt-spice\n\n# echo --host-subject\necho \"your --host-subject is\" \\\"`openssl x509 -noout -text -in server-cert.pem | grep Subject: | cut -f 10- -d \" \"`\\\"\n\necho \"copy ca-cert.pem to %APPDATA%\\spicec\\spice_truststore.pem or ~/.spice/spice_truststore.pem in your clients\"\n</code></pre>","tags":["ssl","cert","libvirt"]},{"location":"Linux/Cockpit/auth/","title":"Authentication","text":""},{"location":"Linux/Cockpit/auth/#prevent-root-login","title":"Prevent root login","text":"<p>You can prevent <code>root</code> login into Cockpit Web UI by adding</p> <pre><code>auth requisite pam_succeed_if.so uid &gt;= 1000\n</code></pre> <p>to <code>/etc/pam.d/cockpit</code></p>"},{"location":"Linux/Cockpit/cockpit/","title":"Cockpit","text":""},{"location":"Linux/Cockpit/cockpit/#configure-2-factor-authentication","title":"Configure 2 factor authentication","text":"<ul> <li> <p>Install requierments</p> <pre><code>dnf install google-authenticator\n</code></pre> </li> <li> <p>Configuration</p> </li> </ul> <p>As user, initialize package configuration with the following command:</p> <pre><code>  google-authenticator\n</code></pre> <p>It will ask you a set of questions, once answered, check the given code and copy the recovery codes (keep them in a safe place).</p> <p>To avoid issue with SELinux preventing Cockpit\u2019s access to this file and to others to be created temporary files, create a dedicated directory and set the rigth SELinux context (see below).</p> <pre><code>    mkdir ~/.secrets\n    mv .google_authenticator* .secrets/\n</code></pre> <ul> <li>Configure <code>pam</code></li> </ul> <p>Edit <code>/etc/pam.d/cockpit</code> and add the following:</p> <pre><code>  auth       required     pam_google_authenticator.so secret=/home/${USER}/.secrets/.google_authenticator\n</code></pre>"},{"location":"Linux/Cockpit/cockpit/#configure-selinux-for-cockpit","title":"Configure SELinux for Cockpit","text":"<ul> <li>Set the rigth context<pre><code>semanage fcontext -a -t cockpit_tmp_t \"/home/$USER/.secrets(/.*)?\"\nrestorecon -R -v /home/$USER/.secrets\n</code></pre> </li> </ul>"},{"location":"Mail/Postfix/","title":"Postfix","text":"","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#various-notes","title":"Various notes","text":"<p>For system admins who are using postfix as their mail server :</p> <p>As my routine system administration I usually use some of the following commands frequently.</p>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#view-the-postfix-version","title":"View the postfix version","text":"<pre><code>postconf  mail_version\nmail_version = 2.3.3\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#check-the-postfix-installation","title":"Check the postfix installation","text":"<pre><code>postfix check\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#show-default-postfix-values","title":"Show default postfix values","text":"<pre><code>postconf -d\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#to-show-non-default-postfix-values","title":"To show non default postfix values","text":"<pre><code>postconf -n\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#to-restart-postfix-mail-server","title":"To restart postfix mail server","text":"<pre><code>postfix reload\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#flush-the-mail-queue","title":"Flush the mail queue","text":"<pre><code>postfix  flush\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#or-you-can-use","title":"Or you can use","text":"<pre><code>postfix  -f\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#to-see-mail-queue","title":"To see mail queue :","text":"<pre><code>mailq\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#in-send-mail-sendmail-bp","title":"( in send mail sendmail -bp )","text":"<pre><code>mailq | wc -l\n</code></pre> <p>(will give the total no of mails in queue )</p>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#to-remove-all-mail-from-the-queue","title":"To remove all mail from the queue","text":"<pre><code>postsuper -d ALL\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#to-remove-all-mails-in-the-deferred-queue","title":"To remove all mails in the deferred queue","text":"<pre><code>postsuper -d ALL deferred\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#to-see-the-mails-in-a-tree-structure","title":"To see the mails in a tree structure","text":"<pre><code>qshape\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#view-the-mail-content","title":"View the mail content","text":"<pre><code>postcat -q  AFD4A228 37C\n</code></pre> <p>You will get the above id from mailq or you can view the mails from postfix mail spool. Usually postfix will store the mails in <code>/var/spool/postfix/active/</code> from this location also you can view the mails. We can change the queue directory from the postfix conf.</p>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#sort-by-from-address","title":"Sort by from address","text":"<pre><code>mailq | awk '/^[0-9,A-F]/ {print $7}' | sort | uniq -c | sort -n\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#to-remove-all-mails-sent-by-email-protected-from-the-queue","title":"To remove all mails sent by [email protected] from the queue","text":"<pre><code>mailq| grep '^[A-Z0-9]'|grep [email\u00a0protected]|cut -f1 -d' ' |tr -d \\*|postsuper -d -\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#to-remove-all-mails-being-sent-using-the-from-address-email-protected","title":"To remove all mails being sent using the From address \u201c[email protected]\u201d","text":"<pre><code>mailq | awk '/^[0-9,A-F].*[email\u00a0protected] / {print $1}' | cut -d '!' -f 1 | postsuper -d -\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#to-remove-all-mails-sent-by-the-domain-adminlogsinfo-from-the-queue","title":"To remove all mails sent by the domain adminlogs.info from the queue","text":"<pre><code>mailq| grep '^[A-Z0-9]'|grep @adminlogs.info|cut -f1 -d' ' |tr -d \\*|postsuper -d\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#test-your-own-mailserver-against-attacks","title":"Test your own Mailserver against attacks","text":"<pre><code>telnet mail-abuse.org\n</code></pre>","tags":["server","linux","mail"]},{"location":"Mail/Postfix/#fix-for-postfix-error-postdrop-warning-unable-to-look-up-publicpickup-no-such-file-or-directory","title":"Fix For Postfix Error: <code>postdrop: Warning: Unable To Look Up Public/pickup: No Such File Or Directory</code>","text":"<p>Apr\u00e8s installation de postfix, lors de l\u2019envoi du premier mail, il y a cette erreur\u202f:</p> <pre><code>postdrop: warning: unable to look up public/pickup: No such file or directory.\n</code></pre> <p>Cela se produit car sendmail est install\u00e9 et entre en conflit avec postfix Pour corriger il faut l\u2019arr\u00eater et cr\u00e9er un dossier manquant:</p> <pre><code>sudo systemctl disable --now sendmail\nsudo dnf remove sendmail\n\nmkfifo /var/spool/postfix/public/pickup\n\nsudo systemctl restart postfix\n</code></pre> <p>source: https://westonganger.com/posts/fix-for-postfix-error-postdrop-warning-unable-to-look-up-public-pickup-no-such-file-or-directory</p>","tags":["server","linux","mail"]},{"location":"Mail/Telnet/","title":"Use Telnet to send mail","text":"<pre><code>telnet mail.server.tld 25\nEHLO my.host.name\nMAIL FROM: &lt;me@address.com&gt;\nRCPT TO: &lt;you@other.net&gt;\nDATA\nSubject: Test\n\nBlabla\n\n.\n250 2.0.0 Ok: queued as XXXXXXX\n</code></pre>","tags":["cli","linux","network"]},{"location":"Network/App_jail/","title":"App jail","text":"","tags":["network","systemd","cli"]},{"location":"Network/App_jail/#launch-an-app-in-network-jail","title":"Launch an app in network jail","text":"<p>You may try network namespaces: https://lmddgtfy.net/?q=linux%20netns</p> <p>You can create a new network namespace, without attaching any interfaces to it, and run your application in it.</p> <p>Example:</p> <pre><code>sudo ip netns add isolated\nsudo ip netns exec isolated sudo -u my_username -i\n</code></pre> <p>This will start new shell session running as your user, but without any access to network.</p> <p>If you want to start graphical application in it, you need to execute</p> <pre><code>export DISPLAY=unix:0\n</code></pre>","tags":["network","systemd","cli"]},{"location":"Network/Carp/","title":"CARP (openBSD)","text":"","tags":["network"]},{"location":"Network/Carp/#si-un-fw-master-a-bascule-en-backup","title":"Si un FW master a bascul\u00e9 en backup","text":"<pre><code>ifconfig -g carp\n</code></pre>","tags":["network"]},{"location":"Network/Carp/#le-compte-le-plus-petit-est-master-donc-augmenter-le-compte-de-celui-qui-doit-passer-en-backup","title":"le compte le plus petit est Master, donc augmenter le compte de celui qui doit passer en Backup :","text":"<pre><code>ifconfig -g carp carpdemote 40\n</code></pre>","tags":["network"]},{"location":"Network/FirewallD/","title":"FirewallD","text":"","tags":["server","network","cli"]},{"location":"Network/FirewallD/#voir-letat-de-fonctionnement-du-pare-feu","title":"Voir l\u2019\u00e9tat de fonctionnement du pare-feu :","text":"<pre><code>firewall-cmd --state\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#obtenir-la-liste-des-zones-supportees","title":"Obtenir la liste des zones support\u00e9es :","text":"<pre><code>firewall-cmd --get-zones\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#obtenir-la-liste-des-services-supportes","title":"Obtenir la liste des services support\u00e9s :","text":"<pre><code>firewall-cmd --get-services\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#lister-ce-qui-est-active-sur-toutes-les-zones","title":"Lister ce qui est activ\u00e9 sur toutes les zones :","text":"<pre><code>firewall-cmd --list-all-zones\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#voir-ce-qui-est-active-sur-la-zone-public","title":"Voir ce qui est activ\u00e9 sur la zone \u2018public\u2019 :","text":"<pre><code>firewall-cmd --zone=public --list-all\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#lister-les-services-actifs-de-la-zone-public","title":"Lister les services actifs de la zone \u2018public\u2019 :","text":"<pre><code>firewall-cmd --zone=public --list-services\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#voir-la-zone-par-defaut-pour-les-connexions-reseau","title":"Voir la zone par d\u00e9faut pour les connexions r\u00e9seau :","text":"<pre><code>firewall-cmd --get-default-zone\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#definir-la-zone-par-defaut-a-public","title":"D\u00e9finir la zone par d\u00e9faut \u00e0 \u2018public\u2019 :","text":"<pre><code>firewall-cmd --set-default-zone=public\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#lister-les-zones-actives","title":"Lister les zones actives :","text":"<pre><code>firewall-cmd --get-active-zones\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#ajouter-ouvrir-le-port-8080-protocole-tcp-a-la-zone-public","title":"Ajouter (ouvrir) le port 8080 (protocole tcp) \u00e0 la zone \u2018public\u2019 :","text":"<pre><code>firewall-cmd --zone=public --add-port=8080/tcp --permanent\nfirewall-cmd --zone=public --add-port=7000-8000/tcp\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#supprimer-fermer-le-port-8080-protocole-tcp-pour-la-zone-public","title":"Supprimer (fermer) le port 8080 (protocole tcp) pour la zone \u2018public\u2019 :","text":"<pre><code>firewall-cmd --zone=public --remove-port=8080/tcp\nfirewall-cmd --zone=public --remove-port=7000-8000/tcp\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#ajouter-ouvrir-le-service-http-pour-la-zone-public","title":"Ajouter (ouvrir) le service http pour la zone \u2018public\u2019 :","text":"<pre><code>firewall-cmd --zone=public --add-service=http\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#supprimer-fermer-le-service-http-pour-la-zone-public","title":"Supprimer (fermer) le service http pour la zone \u2018public\u2019 :","text":"<pre><code>firewall-cmd --zone=public --remove-service=http\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#verifier-si-le-service-http-est-actif-pour-la-zone-public","title":"V\u00e9rifier si le service http est actif pour la zone \u2018public\u2019 :","text":"<pre><code>firewall-cmd --zone=public --query-service=http\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#recharger-la-configuration","title":"Recharger la configuration :","text":"<pre><code>firewall-cmd --reload\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#rich-rules-examples","title":"Rich rules examples:","text":"<pre><code>firewall-cmd --permanent --zone=testing --add-rich-rule='rule family=ipv4 source address=10.0.0.0/24 destination address=192.168.0.10/32 port port=8080-8090 protocol=tcp accept'\nfirewall-cmd --permanent --zone=public --add-rich-rule='rule family=ipv4 source address=92.154.6.35/32 destination address=2.56.156.11/32 port port=22 protocol=tcp accept'\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#list-rich-rules","title":"List rich rules\u202f:","text":"<pre><code>firewall-cmd --permanent --zone=testing --list-rich-rules\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/FirewallD/#remove-riche-rule","title":"Remove riche rule\u202f:","text":"<pre><code>firewall-cmd --permanent --zone=testing --remove-rich-rule='rule family=ipv4 source address=10.0.0.0/24 destination address=192.168.0.10/32 port port=8080-8090 protocol=tcp accept'\n</code></pre>","tags":["server","network","cli"]},{"location":"Network/Keepalived/","title":"Set up Keepalived VIP on RockyLinux","text":""},{"location":"Network/Keepalived/#install-package","title":"Install package","text":"<p>On both nodes:</p> <pre><code>dnf install keepalived\n</code></pre>"},{"location":"Network/Keepalived/#base-config","title":"Base config","text":"<p>On both nodes:</p> <pre><code>vim /etc/sysctl.d/99-sysctl.conf\nnet.ipv4.ip_nonlocal_bind=1\nsysctl -p\n\nfirewall-cmd --add-rich-rule='rule protocol value=\"vrrp\" accept' --permanent\nfirewall-cmd --reloa\n</code></pre>"},{"location":"Network/Keepalived/#on-master-node","title":"On master node","text":"<pre><code>vim /etc/keepalived/keepalived.conf\n</code></pre> <pre><code>! Configuration File for keepalived\n\nglobal_defs {\n   notification_email {\n     toto@toto.com\n   }\n   notification_email_from toto@toto.com\n   smtp_server smtp.toto.com\n   smtp_connect_timeout 30\n   router_id VIP_TOTO\n   vrrp_skip_check_adv_addr\n   vrrp_strict\n   vrrp_garp_interval 0\n   vrrp_gna_interval 0\n}\n\nvrrp_instance VI_1 {\n    state MASTER\n    interface ens18\n    virtual_router_id 51\n    priority 101\n    advert_int 1\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    virtual_ipaddress {\n        192.168.1.1\n    }\n}\n</code></pre>"},{"location":"Network/Keepalived/#on-backup-node","title":"On backup node","text":"<pre><code>vim /etc/keepalived/keepalived.conf\n</code></pre> <pre><code>! Configuration File for keepalived\n\nglobal_defs {\n   notification_email {\n     toto@toto.com\n   }\n   notification_email_from toto@toto.com\n   smtp_server smtp.toto.com\n   smtp_connect_timeout 30\n   router_id VIP_TOTO\n   vrrp_skip_check_adv_addr\n   vrrp_strict\n   vrrp_garp_interval 0\n   vrrp_gna_interval 0\n}\n\nvrrp_instance VI_1 {\n    state BACKUP\n    interface ens18\n    virtual_router_id 51\n    priority 100\n    advert_int 1\n    authentication {\n        auth_type PASS\n        auth_pass 1111\n    }\n    virtual_ipaddress {\n        192.168.1.1\n    }\n}\n</code></pre>"},{"location":"Network/Keepalived/#on-both-nodes","title":"On both nodes","text":"<pre><code>systemctl enable --now keepalived\n</code></pre> <p>Then check ip addresses</p>"},{"location":"Network/NetworkManager/","title":"Start shell script on Network Manager successful connection","text":"<p>by Marko</p> <p>The other day I was writing a script that needed to do its job only when specific network interface is triggered (wireless broadband ppp0 in my case). Pinging Google every 10 seconds to detect Internet access was out of the question. There is a more elegant way to do this. If you are interested please proceed.</p> <p>Do you know that authors of Network Manager built option to trigger scripts right into this great application. To use this option you need to write bash script with some specific bash variables and put it to \u201c/etc/NetworkManager/dispatcher.d/\u201d directory. Specific variables are necessary to receive instructions from Network Manager about network interface that triggers execution of your script and should it be executed on \u201cup\u201d or \u201cdown\u201d operation on that interface.</p> <p>The following example script starts command1 after ppp0 goes \u201cup\u201d, \u201ccommand2\u201d just before ppp0 goes \u201cdown\u201d, \u201ccommand3\u201d just before ppp0 is \u201cup\u201d, and \u201ccommand4\u201d just after ppp0 goes \u201cdown\u201d. Replace commands with what you want to accomplish, you can leave some of the command \u201cfields\u201d blank if you\u2019re not interested in some use cases like \u201cpre-up\u201d or \u201cpost-down\u201d.</p> <pre><code>#!/bin/bash\n\nIF=$1\nSTATUS=$2\n\nif [ \"$IF\" == \"ppp0\" ]\nthen\n    case \"$2\" in\n        up)\n        logger -s \"NM Script up triggered\"\n        command1\n        ;;\n        down)\n        logger -s \"NM Script down triggered\"\n        command2\n        ;;\n        pre-up)\n        logger -s \"NM Script pre-up triggered\"\n        command3\n        ;;\n        post-down)\n        logger -s \"NM Script post-down triggered\"\n        command4\n        ;;\n        *)\n        ;;\n    esac\nfi\n</code></pre> <p>This \u201c90\u201d in the name of the script means that this script will be executed in the last 10% of all scripts if you have a bunch of scripts to execute when your interface starts. You probably don\u2019t have any other scrips in \u201c/etc/NetworkManager/dispatcher.d/\u201d directory but this option is here if you need it. Now we should give permission to execute by doing \u201cchmod +x\u201d on our script and copy it in place.</p> <pre><code>chmod +x /home/$USER/Desktop/90myscriptname.sh\nsudo cp /home/$USER/Desktop/90myscriptname.sh /etc/NetworkManager/dispatcher.d/90myscriptname.sh\n</code></pre> <p>Finally we will monitor <code>/var/log/syslog</code> as it changes to make sure that everything is in order:</p> <pre><code>sudo tail -f /var/log/syslog\n</code></pre> <p>If everything is OK you will see \u201cNM Script action triggered\u201d when you connect or disconnect network interface in question. If not, retrace your steps and double check everything.</p>","tags":["reseau","cli","gnome"]},{"location":"Network/Network_Diag/","title":"Network Diag","text":"","tags":["reseau","cli"]},{"location":"Network/Network_Diag/#shows-how-many-packets-are-matched-by-each-rule-iptables-z-to-zero-the-counters","title":"Shows how many packets are matched by each rule (iptables -Z to zero the counters)","text":"<pre><code>iptables -nvL\n</code></pre>","tags":["reseau","cli"]},{"location":"Network/Network_Diag/#pour-voir-la-table-arp","title":"pour voir la table ARP","text":"<pre><code>arp \nip neigh\n</code></pre>","tags":["reseau","cli"]},{"location":"Network/Network_Diag/#voir-le-cheminement","title":"Voir le cheminement","text":"<pre><code>mtr traceroute tracepath\n\nsocat -d -d -d - TCP4:www.server.tld:80\n</code></pre>","tags":["reseau","cli"]},{"location":"Network/Network_Diag/#dump-the-full-iptables-tables","title":"dump the full iptables tables","text":"<pre><code>iptables-save\n</code></pre>","tags":["reseau","cli"]},{"location":"Network/Network_Diag/#monitorer-la-bp-sur-iface","title":"Monitorer la BP sur iface","text":"<pre><code>iftop -nNpP -i &lt;iface&gt;\n</code></pre>","tags":["reseau","cli"]},{"location":"Network/TCPdump/","title":"TCPdump","text":"","tags":["network","cli"]},{"location":"Network/TCPdump/#pipe-tcpdump-into-wireshark","title":"Pipe tcpdump into Wireshark","text":"<pre><code>ssh root@server.tld tcpdump -i any -s0 -v -w - port not ssh | wireshark -k -i -\n</code></pre>","tags":["network","cli"]},{"location":"Network/Trafic_error/","title":"Trafi error","text":"","tags":["server","various"]},{"location":"Network/Trafic_error/#fix-traffic-interface-must-be-down-error","title":"Fix traffic : interface must be down error","text":"<p>http://blackhold.nusepas.com/2016/08/06/centreon-critical-interface-speed-equal-0-interface-must-be-down/ </p> <pre><code>use -T 1000 option\n</code></pre>","tags":["server","various"]},{"location":"OS/Clonezilla_PXE/","title":"Clonezilla PXE","text":"","tags":["server","network","pxe"]},{"location":"OS/Clonezilla_PXE/#mise-en-place-dun-serveur-clonezilla-via-pxe","title":"Mise en place d\u2019un serveur Clonezilla via PXE","text":"","tags":["server","network","pxe"]},{"location":"OS/Clonezilla_PXE/#pre-requis-et-notions-preliminaires","title":"Pr\u00e9-requis et notions pr\u00e9liminaires","text":"<p>Le serveur PXE utilise Debian GNU/Linux en tant que syst\u00e8me d\u2019exploitation. Le serveur PXE (Preboot eXecution Environment, environnement de d\u00e9marrage d\u2019ordinateurs en r\u00e9seau) aura ici pour but de fournir aux postes clients connect\u00e9s une image ISO bootable de Clonezilla en vue du d\u00e9ploiement d\u2019images openSUSE adapt\u00e9es aux sp\u00e9cificit\u00e9s d\u2019\u00c9veha.</p> <p>Des paquets doivent \u00eatre install\u00e9s, le serveur doit donc avoir une connexion Internet lors de sa mise en place. Par la suite, le serveur peut n\u2019avoir qu\u2019une seule interface r\u00e9seau configur\u00e9e comme suit:</p> <pre><code>adresse IP : 192.168.1.1\nnetmask    : 255.255.255.0\nbroadcast  : 192.168.1.255\nnetwork    : 192.168.1.0 (r\u00e9seau priv\u00e9e entre serveur et clients)\ngateway    : 192.168.1.1 (le serveur lui-m\u00eame, aucune importance dans ce cadre)\nnameserver : 127.0.0.1   (le serveur lui-m\u00eame, aucune importance dans ce cadre)\n</code></pre> <p>Le serveur va fournir un service DHCP au sein du r\u00e9seau priv\u00e9, il est donc important qu\u2019il ne soit pas reli\u00e9 au r\u00e9seau ext\u00e9rieur afin d\u2019\u00e9viter tout conflit dans la fourniture du service DHCP.</p>","tags":["server","network","pxe"]},{"location":"OS/Clonezilla_PXE/#installation-des-paquets-necessaires","title":"Installation des paquets n\u00e9cessaires","text":"<pre><code>apt-get install isc-dhcp-server tftpd-hpa syslinux pxe nfs-kernel-server\n</code></pre>","tags":["server","network","pxe"]},{"location":"OS/Clonezilla_PXE/#configuration-du-service-dhcp-sur-le-serveur","title":"Configuration du service DHCP sur le serveur","text":"<p>Ce paquet fournit le daemon dhcpd et le service isc-dhcp-server.</p> <p>Il se configure via le fichier /etc/dhcp/dhcpd.conf, il faut ajouter ce qui suit:</p> <pre><code># D\u00e9but de configuration du service DHCP\n#\n# D\u00e9claration des leases et plages de service du serveur PXE:\n\nsubnet 192.168.1.0 netmask 255.255.255.0 {\n    range 192.168.1.10 192.168.1.20; # \u00e0 adapter aux nombres de postes clients\n    option broadcast-address 192.168.1.255;\n    option routers 192.168.1.1;      # IP du serveur PXE si on veut faire du routage\n    option domain-name-servers 192.168.1.1; # idem\n    filename \"pxelinux.0\";\n}\n\ngroup {\n    next-server 192.168.1.1; # si n\u00e9cessaire\n    host tftpclient {\n        filename \"pxelinux.0\";\n    }\n}\n\n#\n# Fin de configuration du service DHCP\n</code></pre> <p>Puis red\u00e9marrer le service:</p> <pre><code>service isc-dhcp-server restart\n</code></pre> <p>Il est possible que l\u2019on obtienne un fail si aucun client n\u2019est connect\u00e9 ou que la connexion est inactive.</p>","tags":["server","network","pxe"]},{"location":"OS/Clonezilla_PXE/#configuration-du-service-tftp-sur-le-serveur","title":"Configuration du service TFTP sur le serveur","text":"<p>Ce service se configure comme suit via le fichier /etc/default/tftpd-hpa:</p> <pre><code># D\u00e9but de configuration du service TFTP:\n#\n\nTFTP_USERNAME=\"tftp\"\nTFTP_DIRECTORY=\"/srv/tftp\"\nTFTP_ADDRESS=\"0.0.0.0:69\"\nTFTP_OPTIONS=\"--secure\"\n\n#\n# Fin de configuration du service TFTP\n</code></pre> <p>Puis red\u00e9marrer le service:</p> <pre><code>service tftpd-hpa restart\n</code></pre> <p>Ceci peut \u00e9chouer dans le cas o\u00f9 le dossier /srv/tftp/ n\u2019est pas pr\u00e9sent (il est normalement cr\u00e9\u00e9 automatiquement \u00e0 l\u2019installation du paquet), il suffit alors de le cr\u00e9er.</p>","tags":["server","network","pxe"]},{"location":"OS/Clonezilla_PXE/#preparation-et-mise-en-place-de-limage-clonezilla","title":"Pr\u00e9paration et mise en place de l\u2019image Clonezilla","text":"<p>T\u00e9l\u00e9charger une image .iso live de Clonezilla:</p> <pre><code>wget http://heanet.dl.sourceforge.net/project/clonezilla/clonezilla_live_stable/2.2.3-25/clonezilla-live-2.2.3-25-amd64.iso\n</code></pre> <p>Monter l\u2019image dans /mnt:</p> <pre><code>mount -o loop -t iso9660 /root/clonezilla-live-2.2.3-25-amd64.iso /mnt\n</code></pre> <p>Copier tous les fichiers dans le dossier r\u00e9serv\u00e9 du serveur tftp:</p> <pre><code>cp -ar /mnt/* /srv/tftp/clonezilla\n</code></pre>","tags":["server","network","pxe"]},{"location":"OS/Clonezilla_PXE/#configuration-du-serveur-nfs","title":"Configuration du serveur NFS","text":"<p>Les images des syst\u00e8mes que nous souhaitons booter \u00e0 distance vont \u00eatre servis aux clients via un partage NFS.</p>","tags":["server","network","pxe"]},{"location":"OS/Clonezilla_PXE/#mise-en-place-des-exports-nfs","title":"Mise en place des exports NFS","text":"<p>Cr\u00e9ation du dossier contenant l\u2019image live de Clonezilla:</p> <pre><code>mkdir /srv/tftp/clonezilla\nemacs (ou vi) /etc/exports\n</code></pre> <p>et ajout des lignes correspondantes:</p> <pre><code>/srv/tftp/clonezilla 192.168.1.0/24(async,no_root_squash,no_subtree_check,ro)\n</code></pre> <p>Note: l\u2019IP et le masque CIDR sont \u00e0 adapter au r\u00e9seau et l\u2019image doit \u00eatre de pr\u00e9f\u00e9rence en read-only.</p> <p>Puis on active les partages NFS:</p> <pre><code>service nfs-kernel-server restart\n</code></pre> <p>Et on les v\u00e9rifie:</p> <pre><code>exportfs -v\n</code></pre> <p>Cette commande doit renvoyer la liste des partages actifs.</p>","tags":["server","network","pxe"]},{"location":"OS/Clonezilla_PXE/#mise-en-place-dune-image-de-boot","title":"Mise en place d\u2019une image de boot","text":"<p>Le paquet syslinux fournit une collection de bootloader dont certains nous seront n\u00e9cessaires pour d\u00e9marrer en PXE et afficher le menu qui va bien.</p>","tags":["server","network","pxe"]},{"location":"OS/Clonezilla_PXE/#copie-des-elements-necessaires","title":"Copie des \u00e9l\u00e9ments n\u00e9cessaires","text":"<pre><code>cd /usr/lib/syslinux\ncp chain.c32 mboot.c32 menu.c32 pxelinux.0 reboot.c32 vesamenu.c32 -t /srv/tftp/\n</code></pre>","tags":["server","network","pxe"]},{"location":"OS/Clonezilla_PXE/#configuration-du-service-pxe","title":"Configuration du service PXE","text":"<pre><code>emacs (ou vi) /etc/pxe.conf\n\n# D\u00e9but de configuration du service PXE:\n# \n# which interface to use:\ninterface=eth0\ndefault_address=192.168.1.1\n\n# tftpd base dir:\ntftpdbase=/srv/tftp\n\n# domain name:\ndomain=domain.fr\n#\n# Fin de configuration du service PXE\n</code></pre>","tags":["server","network","pxe"]},{"location":"OS/Clonezilla_PXE/#mise-en-place-du-dossier-et-fichier-menu-pxe","title":"Mise en place du dossier et fichier menu PXE","text":"<pre><code>mkdir /srv/tftp/pxelinux.cfg\nemacs (ou vi) /srv/tftp/pxelinux.cfg/default\n</code></pre> <p>Ce fichier va contenir les instructions pour le menu de boot via PXE</p> <pre><code># D\u00e9but de configuration du menu PXE:\n#\n\n# Interface visuelle:\nDEFAULT vesamenu.c32\nMENU TITLE Bienvenue sur le serveur Clonezilla\nprompt 0\nkbdmap french.kbd\n\n# Entr\u00e9e du menu Clonezilla\nLABEL Demarrer Clonezilla\n    KERNEL clonezilla/live/vmlinuz\n    APPEND boot=live rootfstype=nfs netboot=nfs nfsroot=192.168.1.1:/srv/tftp/clonezilla initrd=clonezilla/live/initrd.img config --\n\n# Entr\u00e9e du menu de red\u00e9marrage\nLABEL Reboot\n    MENU LABEL Redemarrer\n    KERNEL reboot.c32\n\n#\n# Fin de configuration du menu PXE\n</code></pre> <p>Un chmod -R 775 dans ce m\u00eame dossier peut \u00eatre n\u00e9cessaire pour que le daemon TFTPD puisse les lire.</p>","tags":["server","network","pxe"]},{"location":"OS/Clonezilla_PXE/#specificites-de-clonezilla","title":"Sp\u00e9cificit\u00e9s de Clonezilla","text":"<p>L\u2019id\u00e9e \u00e9tant de booter sur un live Clonezilla pour cr\u00e9er et d\u00e9ployer des images disques, nous allons adapter notre environnement \u00e0 ce but:</p> <p>(/partimag est le dossier par d\u00e9faut de Clonezilla, on peut mettre autre chose mais cela implique de le sp\u00e9cifier manuellement \u00e0 chaque clonage/copie.)</p> <p>Ces images vont transiter par un partage NFS sur un NAS:</p> <pre><code>IP du NAS: 192.168.87.21\nNom du NAS: nfsclone\nVersion de NFS: NFSv4\nEmplacement du dossier partag\u00e9: /volume1/partimag\n</code></pre>","tags":["server","network","pxe"]},{"location":"OS/Clonezilla_PXE/#utilisation-du-serveur","title":"Utilisation du serveur","text":"<p>Il ne reste plus qu\u2019\u00e0 connecter les clients, les d\u00e9marrer via PXE, s\u00e9lectionner l\u2019entr\u00e9e de menu \u2018Clonezilla\u2019. Le reste est une utilisation classique de Clonezilla \u00e0 ceci pr\u00e8s que les images vont \u00eatre \u00e9crites/lues vers/depuis un partage NFS.</p>","tags":["server","network","pxe"]},{"location":"OS/openSUSE_memo/","title":"openSUSE memo","text":"","tags":["opensuse","linux","server"]},{"location":"OS/openSUSE_memo/#zypper-tricks","title":"Zypper tricks","text":"<p>To ensure old kernels are purged, check <code>/etc/zypp/zypp.conf</code> for the lines</p> <pre><code>multiversion = provides:multiversion(kernel)\n</code></pre> <p>and</p> <pre><code>multiversion.kernels = latest,latest-1,running\n</code></pre> <p>and ensure both are uncommented. (Refer to https://lizards.opensuse.org/tag/kernel-update/)</p> <p>You will possibly need to create an empty file in <code>/boot</code> named <code>do_purge_kernels</code>, then run (as root):</p> <pre><code>systemctl enable purge-kernels\n</code></pre> <p>Check the status by running:</p> <pre><code>systemctl status purge-kernels\n</code></pre> <p>If this shows inactive (dead) or not enabled, it may be simply because there are no kernels to purge.</p>","tags":["opensuse","linux","server"]},{"location":"OS/openSUSE_memo/#sort-rpm-packages-by-size","title":"Sort RPM packages by size","text":"<pre><code>rpm -q -a --queryformat \"%{SIZE}\\t%{INSTALLTIME:day} \\\n%{BUILDTIME:day}\\t %{SIZE}\\t  %{ARCHIVESIZE}\\t %{FILESIZES}\\t %{LONGARCHIVESIZE}\\t %{LONGFILESIZES}\\t %{LONGSIZE}\\t\n%-30{NAME}\\t%15{VERSION}-%-7{RELEASE}\\t%{arch} \\\n%25{VENDOR}%25{PACKAGER} == %{DISTRIBUTION} %{DISTTAG}\\n\"   | sort --numeric-sort | cut --fields=\"2-\" | tee rpmlist | less -S\n</code></pre>","tags":["opensuse","linux","server"]},{"location":"OS/CentOS/Apache_SeLinux/","title":"Apache SeLinux","text":"","tags":["apache","linux"]},{"location":"OS/CentOS/Apache_SeLinux/#apache-mod_proxy-error-13permission-denied-error-on-rhel","title":"Apache Mod_proxy \u2018[Error] (13)Permission Denied\u2019 Error on RHEL","text":"<p>Had an interesting issue today working on a mod_proxy setup of Apache forwarding requests in a reverse proxy setup to a backend Tomcat server. No matter what I did, I kept getting this in Apache\u2019s error log:</p> <pre><code>[error] (13)Permission denied: proxy: AJP: attempt to connect to 10.x.x.x:7009 (virtualhost.virtualdomain.com) failed\n</code></pre> <p>I thought for sure it was proxy permissions, but nothing I did fixed the issue. Then it hit me: SELinux! Why I always think of SELinux last when it\u2019s responsible for 90% of my problems, I\u2019ll never know. SELinux on RHEL/CentOS by default ships so that httpd processes cannot initiate outbound connections, which is just what mod_proxy attempts to do. If this is your problem, you\u2019ll see something like this in /var/log/audit/audit.log:</p> <pre><code>type=AVC msg=audit(1265039669.305:14): avc:  denied  { name_connect } for  pid=4343 comm=\"httpd\" dest=7009 scontext=system_u:system_r:httpd_t:s0 tcontext=system_u:object_r:port_t:s0 tclass=tcp_socket\n</code></pre> <p>To fix this, first test by setting the boolean dynamically (not permanent yet):</p> <pre><code>/usr/sbin/setsebool httpd_can_network_connect 1\n</code></pre> <p>If that works, you can set it so that the default policy is changed and this setting will persist across reboots:</p> <pre><code>/usr/sbin/setsebool -P httpd_can_network_connect 1\n</code></pre>","tags":["apache","linux"]},{"location":"OS/CentOS/Colorful_root_prompt/","title":"Colorized prompt for root","text":"<pre><code># .bashrc\n\n# User specific aliases and functions\n\nalias rm='rm -i'\nalias cp='cp -i'\nalias mv='mv -i'\n\n# Source global definitions\nif [ -f /etc/bashrc ]; then\n    . /etc/bashrc\nfi\n\n# Colorful prompt\nPS1='[ \\[\\033[01;31m\\]\\u@\\H \\w\\[\\033[02;00m\\] ]\\[\\033[00m\\] '\n</code></pre>"},{"location":"OS/CentOS/vimrc/","title":"Vimrc","text":"<p>set nocompatible set confirm</p> <p>\u201d highlight ugly trailing whitespaces highlight TrailWhitespace ctermbg=red guibg=red match TrailWhitespace  /\\v\\s+(%#)@&lt;!$/ match TrailWhitespace  /\\v\\s+(%#)@&lt;!$/</p> <p>let mapleader=\u201d \u201c</p> <p>nnoremap   :nohlsearch:echo \u201cset pastetoggle=p <p>set completeopt=longest</p> <p>set splitright set splitbelow</p> <p>\u201d Coloration syntaxique syn enable set background=dark</p> <p>\u201d Affiche les commandes au fur et \u00e0 mesure qu\u2019on les tape set showcmd</p> <p>\u201d Surligne les recherches set hlsearch</p> <p>\u201d Use case insensitive search, except when using capital letters set ignorecase set smartcase</p> <p>\u201d Affiche les possibilit\u00e9s de compl\u00e9tion dans la barre de statut set wildmenu</p> <p>fun! SetStatusLine()     let l:s1=\u201d%-3.3n\\ %f\\ %h%m%r%w\u201d     let l:s2=\u201d[%{strlen(&amp;filetype)?&amp;filetype:\u2019?\u2019},%{&amp;encoding}]\u201d     let l:s3=\u201d%=\\ 0x%-8B\\ \\ %-14.(%l,%c%V%)\\ %&lt;%P\u201d     execute \u201cset statusline=\u201d . l:s1 . l:s2 . l:s3 endfun set laststatus=2 hi StatusLine ctermfg=blue hi StatusLine ctermbg=white call SetStatusLine() <p>\u201d Don\u2019t save backups of .gpg files set backupskip+=.gpg</p> <p>\u201d donner des droits d\u2019ex\u00e9cution si le fichier commence par #! function! ModeChange()     if getline(1) =~ \u201c^#!\u201d         silent !chmod a+x      endif endfunction <p>au BufWritePost * call ModeChange()</p> <p>\u201d Toujours laisser des lignes visibles (ici 3) au dessus/en dessous \u201d du curseur quand on atteint le d\u00e9but ou la fin de l\u2019\u00e9cran : set scrolloff=3</p> <p>\u201d shebang automatique lors de l\u2019ouverture d\u2019un nouveau fichier \u201d .py, .sh (bash), modifier l\u2019ent\u00eate selon les besoins : autocmd BufNewFile .sh,.bash 0put =\"#!/bin/sh\\# -- coding: UTF8 --\\\\\"|$ autocmd BufNewFile .py 0put=\"#!/usr/bin/env python\"|1put=\"# -- coding: UTF8 --\\\\\"|$ autocmd BufNewFile .c 0put=\"#include \"|1put=\"#include \\\"|3put=\"int main(int argc, char* argv[]) {\\ \\}\"|$ <p>set modeline set modelines=5 set completeopt=longest set wildmode=longest,list,full</p> <p>if $TERM == \u2018xterm-256color\u2019     set t_Co=256 endif</p> <p>\u201d pour sortir du mode insert facilement inoremap kj  <p>autocmd FileType yaml set shiftwidth=2 tabstop=2 expandtab</p> <p>\u201d d\u00e9sactive les param\u00e8tres par d\u00e9faut de /usr/share/vim/vim80/defaults.vim \u2026 let g:skip_defaults_vim = 1 \u201d et surtout la souris set mouse=\u201d\u201c</p> <p>\u201d modif pour backspace nocompatible set backspace=indent,eol,start</p> <p>\u201d utilisation des espaces set tabstop=4 softtabstop=0 expandtab shiftwidth=4 smarttab</p>"},{"location":"OS/Centreon/SNMP_Config/","title":"Centreon","text":"","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#config-snmpv3-pour-les-serveurs","title":"Config SNMPv3 pour les serveurs","text":"<ul> <li> <p>Arreter le service snmpd     service snmpd stop</p> </li> <li> <p>Cr\u00e9ation de l\u2019utilisateur</p> </li> </ul> <p>Il existe 2 m\u00e9thodes pour la cr\u00e9ation d\u2019utilisateur SNMP V3 Une avec une commande et une autre manuelle</p>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#1-ere-methode-avec-le-script","title":"1 \u00e8re m\u00e9thode (avec le script)","text":"<pre><code>net-snmp-config --create-snmpv3-user -a SHA -x AES\n\n#####################################################\nEnter a SNMPv3 user name to create:\nsnmpuser\nEnter authentication pass-phrase:\nsfjslkfjslkgjsm\nEnter encryption pass-phrase:\nRTRGrbtyyb4566UUJ\n#####################################################\n</code></pre> <p>ceci rajoute 1 entr\u00e9e dans le fichier <code>/usr/share/snmp/snmpd.conf</code> et <code>/var/lib/net-snmp/snmpd.conf</code></p> <pre><code>/usr/share/snmp/snmpd.conf\n\n##########################\nrwuser snmpuser\n\n/var/lib/net-snmp/snmpd.conf\n##########################\n\ncreateUser snmpuser SHA \"sfjslkfjslkgjsm\" AES \"RTRGrbtyyb4566UUJ\"\n</code></pre> <ul> <li>Modifier les droits de l\u2019utilisateur snmpuser en lecture seule     vi /usr/share/snmp/snmpd.conf</li> </ul>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#_1","title":"Centreon","text":"<p>rouser snmpuser</p> <pre><code>SNMPUSERNAME     : snmpuser\nSNMPPASSWORD     : sfjslkfjslkgjsm\nSNMPAUTHPROTOCOL : SHA\nSNMPPRIVPASSWORD : RTRGrbtyyb4566UUJ\nSNMPPRIVPROTOCOL : AES\n</code></pre> <p>---- 2 \u00e8me m\u00e9thode ---- (manuelle)</p> <p>Ajouter l\u2019utilisateur SNMP V3 avec les droits en lecture seule</p>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#_2","title":"Centreon","text":"<p>vi /usr/share/snmp/snmpd.conf</p>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#_3","title":"Centreon","text":"<p>rouser snmpuser</p> <p>Rajouter votre utilisateur avec les param\u00e8tres requis (Nom d\u2019utilisateur, algorithme de hachage, mot de passe, algorithme de chiffrement, clef de chiffrement)  /var/lib/net-snmp/snmpd.conf</p>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#_4","title":"Centreon","text":"<p>createUser snmpuser SHA \u201cVuldpGEQTI4o2p\u201d AES \u201caRtz0OqaIcbHKs\u201d</p> <p>D\u00e9marrage du service snmpd</p>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#_5","title":"Centreon","text":"<p>Le d\u00e9marrage du service aura pour effet de modifier l\u2019entr\u00e9e dans le fichier /var/lib/net-snmp/snmpd.conf et cacher les clefs d\u2019authentification et de chiffrement</p>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#_6","title":"Centreon","text":"<p>service snmpd start</p>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#_7","title":"Centreon","text":"<p>/var/lib/net-snmp/snmpd.conf</p>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#_8","title":"Centreon","text":"<p>usmUser 1 3 0x80001f8880d03ab707afecd75700000000 \u201csnmpuser\u201d \u201csnmpuser\u201d NULL .1.3.6.1.6.3.10.1.1.3 0xc6910771242151aca36878ce38cda60d50b86d4a .1.3.6.1.6.3.10.1.2.4 0xb1248618de541a5995ea635aab1fb5b6 \u201c\u201d</p> <p>Pour tester la connexion snmp en local</p>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#_9","title":"Centreon","text":"<p>snmpwalk -v 3 -u snmpuser -a SHA -A \u2018VuldpGEQTI4o2p\u2019 -x AES -X \u2018aRtz0OqaIcbHKs\u2019 -l authPriv localhost</p> <p>pour tester la connexion \u00e0 partir du serveur Centreon</p>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#_10","title":"Centreon","text":"<p>/usr/lib/nagios/plugins/check_centreon_snmp_remote_storage -H bareos -n -d /backup-01 -w 80 -c 90 -v 3 -u snmpuser -p \u2018VuldpGEQTI4o2p\u2019 \u2013authprotocol SHA \u2013privpassword \u2018aRtz0OqaIcbHKs\u2019 \u2013privprotocol AES</p> <p>Pour finir ne pas oublier de d\u00e9sactiver les acc\u00e8s SNMP v1 et v2 en commentant les lignes suivantes</p>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#_11","title":"Centreon","text":"","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#rocommunity-public-127001","title":"rocommunity public 127.0.0.1","text":"","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#rwcommunity-mysecret-127001","title":"rwcommunity mysecret 127.0.0.1","text":"","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#com2sec-local-localhost-public","title":"com2sec local     localhost           public","text":"","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#com2sec-mynetwork-1921688765-public","title":"com2sec mynetwork 192.168.87.65      public","text":"","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#com2sec-mynetwork-1921688765-public_1","title":"com2sec mynetwork 192.168.87.65      public","text":"<p>Pare-Feu des \u00e9quipements \u00e0 monitorer</p>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#_12","title":"Centreon","text":"<p>UDP : 161 et 162</p> <p>Config SNMPv3 pour les PDU</p> <p>User Name : snmpuser Authentication Passphrase : VuldpGEQTI4o24ffrl845fGtfb8 Privacy Passphrase : aRtz0OqaIcbHKsQTI485dhJHt8s</p> <p>Config SNMPv3 sur les Synology</p>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#_13","title":"Centreon","text":"<p>Nom d\u2019utilisateur : snmpuser Mot de passe : VuldpGEQTI4o2p Protocole d\u2019authentification : MD5 (pour info)</p> <p>Installer module Perl manquan pour la crypto</p>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#_14","title":"Centreon","text":"<p>yum install -y epel-release.noarch</p> <p>yum install -y perl-Crypt-Rijndael</p> <p>Config commune des commandes</p>","tags":["server","various"]},{"location":"OS/Centreon/SNMP_Config/#_15","title":"Centreon","text":"<pre><code>-v 3 -u $_SERVICESNMPUSERNAME$ -p $_SERVICESNMPPASSWORD$ --authprotocol $_SERVICESNMPAUTHPROTOCOL$ --privpassword $_SERVICESNMPPRIVPASSWORD$ --privprotocol $_SERVICESNMPPRIVPROTOCOL$ --snmp-timeout 60\n</code></pre>","tags":["server","various"]},{"location":"OS/Debian/Custom_image/","title":"Custom image","text":"","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#creer-sa-debian","title":"Cr\u00e9er sa debian","text":"","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#creer-sa-propre-distribution-avec-live-build","title":"Cr\u00e9er sa propre distribution avec live-build","text":"<p>Live-build est un petit outil permettant de construire des images pour  cdrom ou usb de debian. Vous pourrez pr\u00e9-configurer cette \u00abdistribution  perso\u00bb comme si c\u2019\u00e9tait la v\u00f4tre, l\u2019utiliser comme syst\u00e8me \u201clive\u201d, et  aussi l\u2019installer telle quelle.  Cette page tentera d\u2019apporter quelques \u00e9claircissements sur  l\u2019utilisation de live-build, parfois obscure, en particulier sur la  version 3.  Sachez toutefois que la meilleure documentation se trouve sur votre  ordinateur. Une fois live-build d\u2019install\u00e9, allez jeter un oeil \u00e0 la  documentation pr\u00e9sente dans /usr/share/doc/live-manual/html/ . </p>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#installation","title":"Installation","text":"<p>Je vous conseille d\u2019installer la version disponible dans les d\u00e9p\u00f4ts. Pour une version plus r\u00e9cente si vous \u00eates en \u201coldstable\u201d, utilisez les d\u00e9pots suivants :  deb http://live.debian.net/ wheezy-snapshots main contrib non-free</p> <p>Puis installez live-build, live-manual et live-tools. </p> <pre><code>apt-get update &amp;&amp; apt-get install live-build live-manual live-tools\n</code></pre>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#preparons-le-travail","title":"Pr\u00e9parons le travail","text":"<p>On va cr\u00e9er un r\u00e9pertoire de travail, s\u2019y d\u00e9placer, puis cr\u00e9er l\u2019arbre de live build pour la suite : </p> <pre><code>mkdir masuperdebian\ncd masuperdebian\nlb config\n</code></pre> <p>D\u00e9sormais sont pr\u00e9sent dans ce dossier de nouveaux r\u00e9pertoires, tels que config. </p>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#configuration","title":"Configuration","text":"<p>La configuration se r\u00e9alise par l\u2019\u00e9dition de plusieurs fichiers pr\u00e9sents dans le r\u00e9pertoire config : binary, bootstrap, chroot, common. Cependant, comme les options de live-build peuvent changer lors du changement de version, nous allons plut\u00f4t utiliser la ligne de commande pour faire \u00e7a. Autrement dit, lorsque lb config sera lanc\u00e9, il appliquera automatiquement certains r\u00e9glages.  Tout d\u2019abord, copiez les scripts clean, config et build pr\u00e9sents dans /usr/share/live/build/examples/auto/ dans le r\u00e9pertoire auto du dossier masuperdebian : </p> <pre><code>cp /usr/share/doc/live-build/examples/auto/* auto/\n</code></pre> <p>Avec une ancienne version, c\u2019\u00e9tait cp /usr/share/live/build/examples/auto/* auto/.  D\u00e9sormais, ce seront ces scripts qui seront utilis\u00e9s lors des lb build, live config, etc. Nous les modifierons directement, afin d\u2019\u00e9viter des lignes de commande \u00e0 rallonge. Autrement dit, lorsque la commande lb config sera de nouveau ex\u00e9cut\u00e9e, ce sera le script pr\u00e9sent dans /auto/config qui sera lanc\u00e9.  Voyons donc comment configurer le tout, en modifiant le fichier  auto/config. Tout d\u2019abord, voici \u00e0 quoi il ressemble par d\u00e9faut : </p> <pre><code>#!/bin/sh\nlb config noauto \\\n\"${@}\"\n</code></pre> <p>Nous allons rajouter des options selon les besoin \u00e0 la suite. Le caract\u00e8re  permet de passer \u00e0 la ligne sans souci. Les options seront donc rajout\u00e9es entre ces deux lignes : </p> <pre><code>#!/bin/sh\nlb config noauto \\\n# AJOUTER DES OPTIONS ICI \\\n# ICI AUSSI \\\n# ET ENCORE ICI SI VOUS VOULEZ \\\n\"${@}\"\n</code></pre>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#installer-une-liste-de-paquets-personnalisee","title":"Installer une liste de paquets personnalis\u00e9e","text":"<p>Cr\u00e9ez un fichier contenant la liste des paquets \u00e0 installer, dans le dossier config/package-lists.  Attention : le fichier doit avoir l\u2019extension .list.chroot . Par exemple :  maliste.list.chroot.  Remplissez ce fichier avec les paquets vous int\u00e9ressant. </p>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#preparer-les-fichiers-de-configuration-de-lutilisateur-le-home","title":"Pr\u00e9parer les fichiers de configuration de l\u2019utilisateur (le home)","text":"<p>Vous souhaitez avoir vos marques pages de navigateur d\u00e9j\u00e0 pr\u00eat? Utiliser un th\u00e8me graphique pr\u00e9cis? Des raccourcis d\u00e9j\u00e0 tout pr\u00eats? Il s\u2019agit de la configuration de l\u2019utilisateur, g\u00e9n\u00e9ralement pr\u00e9sente sous forme de fichier cach\u00e9 dans le /home/.  Pour avoir tout \u00e7a de d\u00e9j\u00e0 pr\u00eat, on va utiliser le dossier config/includes.chroot . Dans ce dernier, cr\u00e9ez un dossier etc/skel . Il s\u2019agit du dossier contenant tout ce qu\u2019un utilisateur a dans son dossier personnel lorsqu\u2019il est cr\u00e9\u00e9. Copiez dans le config/includes.chroot/etc/skel les fichiers de configuration, comme un .bashrc, ou un .config/openbox \u2026 Tout ce que vous voulez!  L\u2019ensemble du contenu de ce dossier sera rajout\u00e9 \u00e0 votre syst\u00e8me personnalis\u00e9. Bien s\u00fbr, cette fonctionnalit\u00e9 fonctionne pour tout, pas seulement pour /etc/skel.  note en passant : L\u2019utilisateur par d\u00e9faut s\u2019appelle user </p> <p>Un syst\u00e8me en fran\u00e7ais Dans auto/config, ajoutez ces options :      \u2013bootappend-live \u201clocales=fr_FR.UTF-8 keyboard-layouts=fr\u201d \\     \u2013bootappend-install \u201clocales=fr_FR.UTF-8\u201d \\</p>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#preciser-une-autre-distribution","title":"Pr\u00e9ciser une autre distribution","text":"<p>Vous pouvez construire sid, ou oldstable, avec l\u2019option \u2013distribution :      \u2013distribution \u201cwheezy\u201d \\</p>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#utiliser-autre-chose-que-main","title":"Utiliser autre chose que main","text":"<p>Vous pouvez ajouter les sections contrib et non-free (bouh!):      \u2013archive-areas \u201cmain contrib non-free\u201d \\</p>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#installer-un-clone-du-syteme-preconfigure","title":"Installer un clone du syt\u00e8me pr\u00e9configur\u00e9","text":"<p>Pour installer le syst\u00e8me tel qu\u2019il est sur votre cl\u00e9 sur un ordinateur, voici l\u2019option \u00e0 utiliser :      \u2013debian-installer \u201clive\u201d \\ Puis assurez vous d\u2019installer le paquet debian-installer-launcher dans la liste des paquets \u00e0 installer. </p>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#pour-une-cle-usb-pas-une-iso-cdrom","title":"Pour une cl\u00e9 usb, pas une iso cdrom","text":"<pre><code>--binary-images \"hdd\" \\\n</code></pre>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#configurer-lutilisateur-nom-dutilisateur-groupes","title":"Configurer l\u2019utilisateur (nom d\u2019utilisateur, groupes)","text":"<p>Pour configurer diff\u00e9rents aspects de la session utilisateur, cela se passe en modifiant les param\u00e8tres de d\u00e9marrage, c\u2019est \u00e0 dire en rajoutant des choses dans la partie apr\u00e8s \u201cboot\u201d de cette ligne      \u2013bootappend-live \u201clocales=fr_FR.UTF-8 keyboard-layouts=fr boot=live\u201d \\</p> <p>Ainsi, pour changer les groupes et par exemple ajouter l\u2019utilisateur au groupe fuse, rajoutez : </p> <pre><code>live-config.user-default-groups=audio,cdrom,dip,floppy,video,plugdev,netdev,powerdev,scanner,bluetooth,fuse`\n</code></pre> <p>Ce qui donne :      \u2013bootappend-live \u201clocales=fr_FR.UTF-8 keyboard-layouts=fr boot=live user-default-groups=audio,cdrom,dip,floppy,video,plugdev,netdev,powerdev,scanner,bluetooth,fuse\u201d \\</p> <p>Pour modifier le nom d\u2019utilisateur, c\u2019est avec username=nom_d_utilisateur </p>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#lancer-des-scripts-pour-configurer-le-systeme","title":"Lancer des scripts pour configurer le syst\u00e8me","text":"<p>Vous pouvez avoir besoin de lancer des scripts suppl\u00e9mentaire pour  personnaliser un peu plus le syst\u00e8me. Ces scripts doivent \u00eatre lanc\u00e9s  dans le chroot, avant que l\u2019image soit construite.  Heureusement, tout est d\u00e9j\u00e0 pr\u00e9vu. Il suffit de placer ces scripts dans le dossier config/hooks. Attention, ces scripts doivent avoir l\u2019extension .chroot.  Par exemple, pour changer l\u2019alternative par d\u00e9faut du terminal, on peut cr\u00e9er un script alternatives.chroot : </p> <pre><code>!/bin/sh\nset -e\nupdate-alternatives --install /usr/bin/x-terminal-emulator x-terminal-emulator /usr/bin/urxvtcd 90\n</code></pre> <p>Dans le syst\u00e8me, ce sera urxvtcd qui sera le terminal par d\u00e9faut gr\u00e2ce \u00e0 ce script. </p>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#persistence-des-donnees","title":"Persistence des donn\u00e9es","text":"<p>Si vous souhaitez retrouvez vos donn\u00e9es entre chaque d\u00e9marrage, pour  pouvez cr\u00e9er ce qu\u2019on appelle un live persistant. Pour cela,  assurez-vous d\u2019ajouter cette option :      \u2013bootappend-live \u201cpersistence\u201d Ce qui peut donner avec d\u2019autres param\u00e8tres :      \u2013bootappend-live \u201cpersistence locales=fr_FR.UTF-8 keyboard-layouts=fr boot=live\u201d \\ Je passe rapidement sur la suite des d\u00e9tails puisqu\u2019ils sont d\u00e9taill\u00e9s ensuite :  * Construction de l\u2019image : lb config &amp;&amp; lb build  * Copie de l\u2019image : # dd if=binary.hybrid.iso of=/dev/sdb  On cr\u00e9e ensuite une nouvelle partition sur la cl\u00e9 avec cfdisk ou gparted. Ensuite, on formate cette partition, par exemple en ext4. Le point important ici est de donner le label \u201cpersistence\u201d \u00e0 cette partition :      mkfs.ext4 -L persistence /dev/sdb2</p> <p>Pour finir, on va cr\u00e9er un fichier persistence.conf (anciennement live-persistence.conf) dans cette partition, et y pr\u00e9ciser quel dossier on veut garder pour les d\u00e9marrages suivants. Ici, on choisit de conserver le /home, qui contient toutes les donn\u00e9es des utilisateurs : </p> <ul> <li>Montage de la partition : # mount -t ext4 /dev/sdb2 /mnt </li> <li>Cr\u00e9ation du fichier persistence.conf avec l\u2019option voulue : # echo \u201c/home\u201d &gt;&gt; /mnt/persistence.conf </li> <li> <p>D\u00e9montage de la cl\u00e9 : #umount /mnt  Et voil\u00e0, lors du premier d\u00e9marrage sur la cl\u00e9, /home sera copi\u00e9 sur la partition /dev/sdb2, autrement dit la deuxi\u00e8me partition de la cl\u00e9. \u00c0 chaque red\u00e9marrage suivant, vous retrouverez les changements r\u00e9alis\u00e9s au dernier lancement, sans autre manipulation.  Un autre exemple de fichier persistence.conf pour garder aussi les \u00e9ventuels programmes install\u00e9s \u00e0 posteriori sur la cl\u00e9, ainsi que la configuration de l\u2019utilisateur (merci LeDub) : </p> <p>/usr union /home /var/cache/apt</p> </li> </ul>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#construction-de-limage","title":"Construction de l\u2019image","text":"<p>Il suffit de lancer, toujours dans le r\u00e9pertoire masuperdebian : </p> <pre><code>lb config\nlb build\n</code></pre> <p>lb config pr\u00e9pare l\u2019image selon les options d\u00e9finies dans le fichier auto/config, et lb build fabrique l\u2019image. </p>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#gravure-copie-sur-usb","title":"Gravure/ copie sur usb","text":"<p>Une image iso est maintenant disponible dans le r\u00e9pertoire masuperdebian.  Si vous avez choisi le format usb, vous pouvez copier le tout sur une cl\u00e9 de cette fa\u00e7on : </p> <pre><code>dd if=binary.img of=/dev/sdb\n</code></pre> <p>o\u00f9 binary.img est l\u2019image de votre debian personnalis\u00e9e, et /dev/sdb est le chemin vers votre cl\u00e9 usb. Attention, ce n\u2019est pas /dev/sdb1 ou /dev/sdc2, mais seulement  /dev/sdb. De plus, tout sera effac\u00e9 sur votre cl\u00e9. Assurez-vous de  copier sur le bon p\u00e9riph\u00e9rique!  Il se peut aussi que vous ayez plut\u00f4t binary.hybrid.iso, ce n\u2019est pas un probl\u00e8me, il s\u2019agit juste d\u2019un format pouvant servir \u00e0 la fois pour les cl\u00e9 usb que pour les cdroms. </p> <p>On recommence La derni\u00e8re image ne correspondait pas \u00e0 vos attentes? On recommence alors. Tout d\u2019abord, on nettoie le tout :      lb clean Puis vous appliquez vos changements de configuration, et ensuite :      lb config on recommence au d\u00e9but. </p>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#rendre-les-constructions-futures-plus-rapides","title":"Rendre les constructions futures plus rapides","text":"<p>Si vous planifiez de construire des ISO r\u00e9guli\u00e8rement, une bonne id\u00e9e serait de mettre en cache les paquets localement. Installez simplement apt-cacher-ng et configurez la variable d\u2019environnement http_proxy avant la construction: </p> <pre><code>apt-get install apt-cacher-ng\n/etc/init.d/apt-cacher-ng start\nexport http_proxy=http://localhost:3142/\n.... # setup and configure your live build\nlb config --apt-http-proxy http://127.0.0.1:3142/\nlb build\n</code></pre> <p>D\u2019apr\u00e8s la documentation de Kali linux </p>","tags":["debian","linux"]},{"location":"OS/Debian/Custom_image/#exemple","title":"Exemple","text":"<pre><code>#!/bin/sh\n\nlb config noauto \\\n--architectures \"i386\" \\\n--linux-flavours \"686\" \\\n--bootappend-live \"locales=fr_FR.UTF-8 keyboard-layouts=fr\" \\\n--bootappend-install \"locales=fr_FR.UTF-8\" \\\n--binary-images \"hdd\" \\\n--distribution \"wheezy\" \\\n--archive-areas \"main contrib non-free\" \\\n--apt-indices \"false\" \\\n--apt-recommends \"false\" \\\n--includes \"none\" \\\n--memtest \"none\" \\\n--win32-loader \"false\" \\\n--source \"false\" \\\n--debug \\\n\"${@}\"\n</code></pre> <p>Liste des options disponibles \u00e0 lb config</p> <p>Pour conna\u00eetre toutes les options pouvant \u00eatre ajout\u00e9es au fichier auto/config, tapez la commande man lb_config, et vous obtiendrez quelque chose du genre : </p> <pre><code>[--apt apt|aptitude]\n[--apt-ftp-proxy URL]\n[--apt-http-proxy URL]\n[--apt-indices true|false|none]\n[--apt-options OPTION|\"OPTIONS\"]\n[--aptitude-options OPTION|\"OPTIONS\"]\n[--apt-pipeline DEPTH]\n[--apt-recommends true|false]\n[--apt-secure true|false]\n[--apt-source-archives true|false]\n[-a|--architectures ARCHITECTURE]\n[-b|--binary-images iso|iso-hybrid|net|tar|hdd|virtual-hdd]\n[--binary-filesystem fat16|fat32|ext2|ext3|ext4]\n[--bootappend-install PARAMETER|\"PARAMETERS\"]\n[--bootappend-live PARAMETER|\"PARAMETERS\"]\n[--bootloader grub|syslinux|yaboot]\n[--bootstrap cdebootstrap|cdebootstrap-static|debootstrap|copy]\n[-f|--bootstrap-flavour minimal|standard]\n[--bootstrap-keyring PACKAGE]\n[--cache true|false]\n[--cache-indices true|false]\n[--cache-packages true|false]\n[--cache-stages STAGE|\"STAGES\"]\n[--checksums md5|sha1|sha256|none]\n[--compression bzip2|gzip|lzip|none]\n[--build-with-chroot true|false]\n[--chroot-filesystem ext2|ext3|ext4|squashfs|jffs2|none]\n[--clean]\n[-c|--conffile FILE]\n[--debconf-frontend dialog|editor|noninteractive|readline]\n[--debconf-nowarnings true|false]\n[--debconf-priority low|medium|high|critical]\n[--debian-installer true|cdrom|netinst|netboot|businesscard|live|false]\n[--debian-installer-distribution daily|CODENAME]\n[--debian-installer-preseedfile FILE|URL]\n[--debian-installer-gui true|false]\n[--debug]\n[-d|--distribution CODENAME]\n[--parent-distribution CODENAME]\n[--parent-debian-installer-distribution CODENAME]\n</code></pre> <p>R\u00e9f\u00e9rences * https://debian-live.alioth.debian.org/live-manual/stable/manual/html/live-manual.en.html#117 * http://www.esdebian.org/wiki/live-helper * http://live.debian.net/ * http://live.debian.net/devel/live-build/</p>","tags":["debian","linux"]},{"location":"OS/Debian/Tricks/","title":"Tricks","text":"","tags":["debian","various"]},{"location":"OS/Debian/Tricks/#debian-tricks","title":"Debian-tricks","text":"<p>If you\u2019d like to prevent daemons from starting after installing a package, just toss a few lines into /usr/sbin/policy-rc.d:</p> <pre><code>cat &gt; /usr/sbin/policy-rc.d &lt;&lt; EOF\n#!/bin/sh\necho \"All runlevel operations denied by policy\" &gt;&amp;2\nexit 101\nEOF\n</code></pre>","tags":["debian","various"]},{"location":"OS/Debian/apt_conf/","title":"Configuration APT","text":""},{"location":"OS/Debian/apt_conf/#ne-jamais-utiliser-les-recommends","title":"Ne jamais utiliser les <code>recommends</code>","text":"<pre><code>cat &gt; /etc/apt/apt.conf.d/01norecommend &lt;&lt; EOF\nAPT::Install-Recommends \"0\";\nAPT::Install-Suggests \"0\";\nEOF\n</code></pre>"},{"location":"OS/Fedora/Manage_repositories/","title":"Manage repositories","text":"","tags":["linux","rpm"]},{"location":"OS/Fedora/Manage_repositories/#configuring-with-the-command-line","title":"Configuring with the command line","text":"","tags":["linux","rpm"]},{"location":"OS/Fedora/Manage_repositories/#see-a-list-of-all-enabled-repos","title":"See a list of all enabled repos","text":"<pre><code>sudo dnf repolist\n</code></pre>","tags":["linux","rpm"]},{"location":"OS/Fedora/Manage_repositories/#change-configuration-for-just-one-command-to-enable-or-disable-a-repo-just-once-use-a-command-option","title":"Change configuration for just one command. To enable or disable a repo just once, use a command option:","text":"<pre><code>sudo dnf --enablerepo=&lt;reponame&gt;...\nsudo dnf --disablerepo=&lt;reponame&gt;...\n</code></pre>","tags":["linux","rpm"]},{"location":"OS/Fedora/Manage_repositories/#for-instance-to-install-the-latest-kernel-from-fedoras-test-repo","title":"For instance, to install the latest kernel from Fedora\u2019s test repo:","text":"<pre><code>sudo dnf --enablerepo=updates-testing install kernel\\*\n</code></pre>","tags":["linux","rpm"]},{"location":"OS/Fedora/Manage_repositories/#you-can-combine-several-enable-and-disable-options-together-for-example","title":"You can combine several enable and disable options together. For example:","text":"<pre><code>sudo dnf --enablerepo=repo1 --disablerepo=repo2,repo3 install &lt;package&gt;\n</code></pre>","tags":["linux","rpm"]},{"location":"OS/Fedora/Manage_repositories/#if-you-want-to-change-the-defaults-permanently-use-these-commands","title":"If you want to change the defaults permanently, use these commands:","text":"<pre><code>sudo dnf config-manager --set-enabled &lt;reponame&gt;\nsudo dnf config-manager --set-disabled &lt;reponame&gt;\n</code></pre> <p>Perhaps you install, update, or remove a lot of software using different setups. In this case, things may get confusing. You might not know which software is installed from what repos. If that happens, try this.</p>","tags":["linux","rpm"]},{"location":"OS/Fedora/Manage_repositories/#first-disable-extra-repos-such-as-those-ending-in-testing-ideally-enable-only-fedora-and-updates-repos-run-this-command-for-each-unwanted-repo","title":"First, disable extra repos such as those ending in \u2013testing. Ideally, enable only fedora and updates repos. Run this command for each unwanted repo:","text":"<pre><code>sudo dnf config-manager --set-disabled &lt;unwanted-repo&gt;\n</code></pre>","tags":["linux","rpm"]},{"location":"OS/Fedora/Manage_repositories/#then-run-this-command-to-synchronize-your-system-with-just-stable-updated-packages","title":"Then run this command to synchronize your system with just stable, updated packages:","text":"<pre><code>sudo dnf distro-sync\n</code></pre> <p>This ensures your Fedora system is only using the latest packages from specific repos.</p>","tags":["linux","rpm"]},{"location":"PAM_SSSD/Disable_fprintd/","title":"Disable fprintd","text":""},{"location":"PAM_SSSD/Disable_fprintd/#issue","title":"Issue","text":"<p>Problem was found in CentOS, GDM was wainting for service to start before accepting password input.</p> <p>Log excerpt</p> <pre><code>juin 23 19:09:48 .net dbus-daemon[1338]: [system] Activating via systemd: service name='net.reactivated.Fprint' unit='fprintd.service' requested by ':1.218' (uid=1573400&gt;\njuin 23 19:09:48 .net systemd[1]: Starting Fingerprint Authentication Daemon...\njuin 23 19:09:48 .net dbus-daemon[1338]: [system] Successfully activated service 'net.reactivated.Fprint'\njuin 23 19:09:48 .net systemd[1]: Started Fingerprint Authentication Daemon.\n</code></pre> <p>Service status</p> <pre><code>[ root .net ~ ] systemctl status fprintd.service \n\u25cf fprintd.service - Fingerprint Authentication Daemon\nLoaded: loaded (/usr/lib/systemd/system/fprintd.service; static; vendor preset: disabled)\nActive: active (running) since Tue 2020-06-23 19:11:22 CEST; 24s ago\n    Docs: man:fprintd(1)\nMain PID: 5801 (fprintd)\n    Tasks: 3 (limit: 48352)\nMemory: 3.8M\nCGroup: /system.slice/fprintd.service\n        \u2514\u25005801 /usr/libexec/fprintd\n\njuin 23 19:11:22 .net systemd[1]: Starting Fingerprint Authentication Daemon...\njuin 23 19:11:22 .net systemd[1]: Started Fingerprint Authentication Daemon.\n</code></pre>"},{"location":"PAM_SSSD/Disable_fprintd/#solution","title":"Solution","text":"<pre><code>[ root .net ~ ] authconfig --disablefingerprint --update\nRunning authconfig compatibility tool.\nThe purpose of this tool is to enable authentication against chosen services with authselect and minimum configuration. It does not provide all capabilities of authconfig.\n\nIMPORTANT: authconfig is replaced by authselect, please update your scripts.\nSee man authselect-migration(7) to help you with migration to authselect\n\nExecuting: /usr/bin/authselect check\nExecuting: /usr/bin/authselect select sssd --force\n\ndnf remove fprintd-pam fprintd\n</code></pre>"},{"location":"PAM_SSSD/polkit/","title":"Autoriser Polkit Pam avec SSSD","text":"<ul> <li>Ajouter l\u2019option suivante \u00e0 la section <code>[pam]</code>:<pre><code>pam_p11_allowed_services = +polkit-1\n</code></pre> </li> </ul> <p>puis red\u00e9marrer <code>sssd</code>.</p>"},{"location":"Podman/Pods/","title":"Create pods with Podman","text":""},{"location":"Podman/Pods/#nextcloud-example","title":"Nextcloud example","text":"<ol> <li> <p>First create the pod which is just the structure</p> <pre><code>podman pod create --name nc-test -p 8080:80\n</code></pre> </li> <li> <p>then add containers</p> <pre><code>podman run -d --restart=always --pod=nc-test -e MYSQL_ROOT_PASSWORD=\"\" -e MYSQL_DATABASE=\"nc\" -e MYSQL_USER=\"nc_user\" -e MYSQL_PASSWORD=\"nextcloud\" --name=nc-db mariadb\n\npodman run --security-opt label=disable -d --restart=always --pod=nc-test -e NEXTCLOUD_TRUSTED_DOMAINS=\"domain.net\" -e NEXTCLOUD_ADMIN_USER=\"admin\" -e NEXTCLOUD_ADMIN_PASSWORD=\"nextcloud\" -e MYSQL_DATABASE=\"nc\" -e MYSQL_USER=\"nc_user\" -e MYSQL_PASSWORD=\"nextcloud\" -e MYSQL_HOST=\"127.0.0.1\" -v ./ncdata:/var/www/html:z --name=nc-app --memory=128M nextcloud\n</code></pre> </li> </ol> <p>Nextcloud must use 127.0.0.1 as DB host as all ports are managed by the pod.</p>"},{"location":"Podman/Tips/","title":"Tips and tricks about Podman","text":""},{"location":"Podman/Tips/#disable-security-in-selinux-context","title":"Disable security in SELinux context","text":"<p>Most of the time just add <code>:Z</code> after volume parameters:</p> <pre><code>podman run -dit -v ./cockpit:/tmp/cockpit:z localhost/cockpit-builder\n</code></pre> <p>If it is not working, add <code>--security-opt label=disable</code> and the <code>:z</code> option to your volume</p> <pre><code>podman run -dit  --security-opt label=disable -v ./cockpit:/tmp/cockpit:z localhost/cockpit-builder\n</code></pre>"},{"location":"SQL/MySQL/","title":"MySQL","text":"","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#mysql-and-mariadb-tricks","title":"MySQL and MariaDB tricks","text":"","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#dumper-une-table","title":"Dumper une table","text":"<pre><code>    mysqldump $base $table\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#restaurer-le-dump-dune-table","title":"Restaurer le dump d\u2019une table","text":"<pre><code>    mysql -uroot -p DatabaseName &lt; path\\TableName.sql\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#extraire-table-dun-dump","title":"Extraire table d\u2019un dump","text":"<pre><code>grep -n \"Table structure\" [MySQL_dump_filename].sql\n</code></pre> <p>This will provide you with the starting line number in the MySQL dump file which defines each table. Using this, determine the starting and ending line numbers of the table you need (the ending line number will be the starting line number of the next table, minus one).</p>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#extract-the-table-from-the-mysql-database-dump-file","title":"extract the table from the MySQL database dump file","text":"<pre><code>sed -n '[starting_line_number],[ending_line_number] p' [MySQL_dump_filename].sql &gt; [table_output_filename].sql\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#the-last-remaining-step-is-to-use-the-extracted-table","title":"The last remaining step is to use the extracted table","text":"<pre><code>mysql -u root -p [some_database_name] &lt; [table_output_filename].sql\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#gerer-les-bases-de-donnees","title":"G\u00e9rer les bases de donn\u00e9es","text":"<pre><code>show databases;\n</code></pre> <ul> <li> <p>Utiliser une base</p> <pre><code>USE nom_base;\n</code></pre> </li> <li> <p>Listes les tables dans cette base</p> <pre><code>show tables;\n</code></pre> </li> <li> <p>Pour cr\u00e9e une base de donn\u00e9es, saisir simplement</p> <pre><code>CREATE DATABASE superbase;\n</code></pre> </li> <li> <p>Pour la supprimer</p> <pre><code>DROP DATABASE superbase;\n</code></pre> </li> </ul>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#gestion-des-utilisateurs","title":"Gestion des utilisateurs","text":"<ul> <li>Voir tous les utilisateurs<pre><code>select * from mysql.user;\n</code></pre> </li> </ul>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#pour-creer-un-utilisateur","title":"Pour cr\u00e9er un utilisateur","text":"<ul> <li> <p>Quelque soit l\u2019h\u00f4te</p> <pre><code>CREATE USER 'utilisateur'@'%' IDENTIFIED BY 'motdepasse';\n</code></pre> </li> <li> <p>Que pour localhost</p> <pre><code>CREATE USER 'utilisateur'@'localhost' IDENTIFIED BY 'motdepasse';\n</code></pre> </li> </ul>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#attribuer-des-droits-aux-utilisateurs","title":"Attribuer des droits aux utilisateurs","text":"<p>Pour attribuer tous les droits \u00e0 un utilisateur (en faire en quelque sortes un deuxi\u00e8me root) :</p> <pre><code>    GRANT ALL PRIVILEGES ON * . * TO 'utilisateur'@'localhost' IDENTIFIED BY 'motdepasse' WITH GRANT OPTION MAX_QUERIES_PER_HOUR 0 MAX_CONNECTIONS_PER_HOUR 0 MAX_UPDATES_PER_HOUR 0 MAX_USER_CONNECTIONS 0 ;\n</code></pre> <ul> <li> <p>Ou m\u00eame en lecture seule</p> <pre><code>GRANT SELECT ON * . * TO 'utilisateur'@'localhost' IDENTIFIED BY 'motdepasse' ;\n</code></pre> </li> <li> <p>Tous les droits sur une base</p> <pre><code>GRANT ALL PRIVILEGES ON mydb.* TO 'myuser'@'localhost' WITH GRANT OPTION;\n</code></pre> </li> <li> <p>On peut faire du 2 en 1. Voici un exemple pour la cr\u00e9ation d\u2019un utilisateur sans mot de passe avec des droits en lecture seule</p> <pre><code>GRANT SELECT ON *.* TO 'ro'@'localhost';\n</code></pre> </li> <li> <p>De la m\u00eame fa\u00e7on, on peut supprimer ds droits avec REVOKE</p> <pre><code>REVOKE ALL ON *.* FROM 'utilisateur'@'localhost';\n</code></pre> </li> </ul>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#changer-un-mot-de-passe-dutilisateur-de-mysql","title":"Changer un mot de passe d\u2019utilisateur de MySQL","text":"<ul> <li> <p>Cette commande fonctionne uniquement pour MySQL</p> <pre><code>UPDATE mysql.USER SET password=PASSWORD(\"nouveau\") WHERE USER=\"utilisateur\";\n</code></pre> </li> <li> <p>Pour voir les utilisateurs cr\u00e9\u00e9s</p> <pre><code>SELECT USER,host,password FROM mysql.USER;\n</code></pre> </li> <li> <p>Pour un utilisateur donn\u00e9, on peut voir ses droits de la fa\u00e7on suivante</p> <pre><code>SHOW GRANTS FOR \"utilisateur\"@\"localhost\";\n</code></pre> </li> <li> <p>View permissions for individual databases</p> <pre><code>SELECT user, host, db, select_priv, insert_priv, grant_priv FROM mysql.db;\n</code></pre> </li> <li> <p>Voir les GRANTS sur une table:</p> <pre><code>select user from mysql.db where db='DB_NAME';\n</code></pre> </li> </ul>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#modifier-mot-de-passe-hasher-en-md5","title":"Modifier mot de passe hasher en MD5","text":"<pre><code>    UPDATE users SET Password = (MD5('1cb826899b7')) WHERE User = 'sgennet';\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#tables","title":"Tables","text":"","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#pour-creer-une-table-simple-voici-un-exemple","title":"Pour cr\u00e9er une table simple, voici un exemple","text":"<pre><code>    CREATE TABLE table1 ( id INT(10) NOT NULL AUTO_INCREMENT COMMENT 'id, autoincr\u00e9ment\u00e9', nom VARCHAR(20) NOT NULL, DATE DATE, message VARCHAR(255), PRIMARY KEY (id));\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#how-to-back-up-and-restore-a-mysql-database","title":"How to Back Up and Restore a MySQL Database","text":"<p>If you\u2019re storing anything in MySQL databases that you do not want to lose, it is very important to make regular backups of your data to protect it from loss. This tutorial will show you two easy ways to backup and restore the data in your MySQL database. You can also use this process to move your data to a new web server.</p> <p>Back up From the Command Line (using mysqldump)</p> <p>If you have shell or telnet access to your web server, you can backup your MySQL data by using the mysqldump command. This command connects to the MySQL server and creates an SQL dump file. The dump file contains the SQL statements necessary to re-create the database. Here is the proper syntax:</p> <pre><code>mysqldump --opt -u [uname] -p[pass] [dbname] &gt; [backupfile.sql]\n</code></pre> <p>For example, to backup a database named \u2018Tutorials\u2019 with the username \u2018root\u2019 and with no password to a file tut_backup.sql, you should accomplish this command:</p> <pre><code>mysqldump -u root -p Tutorials &gt; tut_backup.sql\n</code></pre> <p>This command will backup the \u2018Tutorials\u2019 database into a file called tut_backup.sql which will contain all the SQL statements needed to re-create the database.</p> <p>With mysqldump command you can specify certain tables of your database you want to backup. For example, to back up only php_tutorials and asp_tutorials tables from the \u2018Tutorials\u2019 database accomplish the command below. Each table name has to be separated by space.</p> <pre><code>mysqldump -u root -p Tutorials php_tutorials asp_tutorials &gt; tut_backup.sql\n</code></pre> <p>Sometimes it is necessary to back up more that one database at once. In this case you can use the \u2013database option followed by the list of databases you would like to backup. Each database name has to be separated by space.</p> <pre><code>mysqldump -u root -p --databases Tutorials Articles Comments &gt; content_backup.sql\n</code></pre> <p>If you want to back up all the databases in the server at one time you should use the \u2013all-databases option. It tells MySQL to dump all the databases it has in storage.</p> <pre><code>mysqldump -u root -p --all-databases &gt; alldb_backup.sql\n</code></pre> <p>The mysqldump command has also some other useful options:</p> <pre><code>--add-drop-table: Tells MySQL to add a DROP TABLE statement before each CREATE TABLE in the dump.\n\n--no-data: Dumps only the database structure, not the contents.\n\n--add-locks: Adds the LOCK TABLES and UNLOCK TABLES statements you can see in the dump file.\n</code></pre> <p>The mysqldump command has advantages and disadvantages. The advantages of using mysqldump are that it is simple to use and it takes care of table locking issues for you. The disadvantage is that the command locks tables. If the size of your tables is very big mysqldump can lock out users for a long period of time.</p>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#back-up-your-mysql-database-with-compress","title":"Back up your MySQL Database with Compress","text":"<p>If your mysql database is very big, you might want to compress the output of mysqldump. Just use the mysql backup command below and pipe the output to gzip, then you will get the output as gzip file.</p> <pre><code>mysqldump -u [uname] -p[pass] [dbname] | gzip -9 &gt; [backupfile.sql.gz]\n</code></pre> <p>If you want to extract the .gz file, use the command below:</p> <pre><code>gunzip [backupfile.sql.gz]\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#restoring-your-mysql-database","title":"Restoring your MySQL Database","text":"<p>Above we backup the Tutorials database into tut_backup.sql file. To re-create the Tutorials database you should follow two steps:</p> <ul> <li>Create an appropriately named database on the target machine</li> <li> <p>Load the file using the mysql command:</p> <pre><code>mysql -u [uname] -p[pass] [db_to_restore] &lt; [backupfile.sql]\n</code></pre> </li> <li> <p>Have a look how you can restore your tut_backup.sql file to the Tutorials database.</p> <pre><code>mysql -u root -p Tutorials &lt; tut_backup.sql\n</code></pre> </li> <li> <p>To restore compressed backup files you can do the following:</p> <pre><code>gunzip &lt; [backupfile.sql.gz] | mysql -u [uname] -p[pass] [dbname]\n</code></pre> </li> </ul> <p>If you need to restore a database that already exists, you\u2019ll need to use mysqlimport command. The syntax for mysqlimport is as follows:</p> <pre><code>    mysqlimport -u [uname] -p[pass] [dbname] [backupfile.sql]\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#backing-up-and-restoring-using-phpmyadmin","title":"Backing Up and Restoring using PHPMyAdmin","text":"<p>It is assumed that you have phpMyAdmin installed since a lot of web service providers use it. To backup your MySQL database using PHPMyAdmin just follow a couple of steps:</p> <ul> <li>Open phpMyAdmin.</li> <li>Select your database by clicking the database name in the list on the left of the screen.</li> <li>Click the Export link. This should bring up a new screen that says View dump of database (or something similar).</li> <li>In the Export area, click the Select All link to choose all of the tables in your database.</li> <li>In the SQL options area, click the right options.</li> <li>Click on the Save as file option and the corresponding compression option and then click the \u2018Go\u2019 button. A dialog box should appear prompting you to save the file locally.</li> </ul>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#restoring-your-database-is-easy-as-well-as-backing-it-up-make-the-following","title":"Restoring your database is easy as well as backing it up. Make the following:","text":"<ul> <li>Open phpMyAdmin.</li> <li>Create an appropriately named database and select it by clicking the database name in the list on the left of the screen. If you would like to rewrite the backup over an existing database then click on the database name, select all the check boxes next to the table names and select Drop to delete all existing tables in the database.</li> <li>Click the SQL link. This should bring up a new screen where you can either type in SQL commands, or upload your SQL file.</li> <li>Use the browse button to find the database file.</li> <li>Click Go button. This will upload the backup, execute the SQL commands and re-create your database.</li> </ul>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#script-creation-multiple","title":"Script cr\u00e9ation multiple","text":"<pre><code>#!/bin/bash\n\nwhile read line\ndo\n    DB=$(echo $line | awk '{print $1}') ; echo $DB\n    USER=$(echo $line | awk '{print $2}') ; echo $USER\n    PASS=$(echo $line | awk '{print $3}') ; echo $PASS\n\n    mysql -e \"CREATE DATABASE ${DB};\"\n    mysql -e \"CREATE USER ${USER}@localhost IDENTIFIED BY '${PASS}';\"\n    mysql -e \"GRANT ALL PRIVILEGES ON ${DB}.* TO '${USER}'@'localhost';\"\n    mysql -e \"FLUSH PRIVILEGES;\"\ndone&lt;listing3\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#mettre-a-jour-le-pass-dun-user","title":"Mettre \u00e0 jour le pass d\u2019un user","text":"<pre><code>ALTER USER 'userName'@'localhost' IDENTIFIED BY 'New-Password-Here';\nSET PASSWORD FOR 'user-name-here'@'hostname' = PASSWORD('new-password');\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#purger-les-logs-binaires","title":"Purger les logs binaires","text":"<pre><code>PURGE BINARY LOGS TO 'mysql-bin.010';\nPURGE BINARY LOGS BEFORE '2008-04-02 22:46:26';\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#gerer-les-processus","title":"G\u00e9rer les processus","text":"<pre><code>mysql&gt; SHOW processlist;\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#tuer-un-process","title":"Tuer un process","text":"<pre><code>KILL QUERY id\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#tuer-plein-de-process","title":"Tuer plein de process","text":"<pre><code>select concat('KILL ',id,';') from information_schema.processlist where user='fronte' and command='Query' into outfile '/tmp/a.txt';\nsource /tmp/a.txt;\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#afficher-les-entetes-des-colonnes-dune-table","title":"Afficher les entetes des colonnes d\u2019une table","text":"<pre><code>select column_name from information_schema.columns where table_name='&lt;table_name&gt;';\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/MySQL/#voir-les-moteurs-de-table","title":"Voir les moteurs de table","text":"<pre><code>SELECT TABLE_NAME, ENGINE FROM information_schema.TABLES WHERE TABLE_SCHEMA = \\\"$DB\\\" ;\n</code></pre>","tags":["server","db","linux","cli"]},{"location":"SQL/PostgreSQL/","title":"PostgreSQL","text":"","tags":["server","linux","db","cli"]},{"location":"SQL/PostgreSQL/#postgresql","title":"PostgreSQL","text":"","tags":["server","linux","db","cli"]},{"location":"SQL/PostgreSQL/#gerer-postgresql","title":"G\u00e9rer PostGreSQL","text":"<ul> <li> <p>Se connecter en user postgres:</p> <pre><code>sudo -u postgres -i\n</code></pre> </li> <li> <p>Se connecter \u00e0 postgresql</p> <pre><code>psql\n</code></pre> </li> <li> <p>Lister les bases (une fois connect\u00e9) :</p> <pre><code>\\l\n</code></pre> </li> <li> <p>Lister tous les sch\u00e9mas :</p> <pre><code>\\dn\n</code></pre> </li> <li> <p>Lister les tables d\u2019un sch\u00e9ma\u202f:</p> <pre><code>\\dt nom_schema.*\n</code></pre> </li> </ul>","tags":["server","linux","db","cli"]},{"location":"SQL/PostgreSQL/#exporter-une-base-sans-etre-connecte","title":"Exporter une base (sans \u00eatre connect\u00e9)","text":"<pre><code>pg_dump NOM_BASE &gt; Fichier.sql\n</code></pre>","tags":["server","linux","db","cli"]},{"location":"SQL/PostgreSQL/#importer-des-donnees-dans-une-base-existante","title":"Importer des donn\u00e9es dans une base existante","text":"<pre><code>psql -U USERNAME NOM_BASE &lt; Fichier.sql\n\nCREATE USER davide WITH PASSWORD 'pass';\n\nGRANT ALL PRIVILEGES ON DATABASE kinds TO manuel;\n\nALTER DATABASE kanboard OWNER TO u_base;\n</code></pre>","tags":["server","linux","db","cli"]},{"location":"SQL/PostgreSQL/#mettre-a-jour-un-mot-de-passe","title":"Mettre \u00e0 jour un mot de passe","text":"<pre><code>CREATE EXTENSION pgcrypto;\nupdate users set password = crypt('pass', gen_salt('bf')) where username = 'admin';\n</code></pre>","tags":["server","linux","db","cli"]},{"location":"SQL/PostgreSQL/#passer-des-commandes-en-cli-sans-auth-interactive","title":"Passer des commandes en cli sans auth interactive","text":"<pre><code>PGPASSFILE=&lt;(echo localhost:5432:db_siao_extraction:u_siao_extraction:MON_PASS) psql -h localhost -p 5432 -d db_siao_extraction  -U u_siao_extraction -c \"delete from urg_extraction_info;\"\n</code></pre>","tags":["server","linux","db","cli"]},{"location":"SQL/PostgreSQL/#requeete-les-requetes-en-cours-ordonnees-par-age-en-excluant-la-requete-de-requete","title":"Reque\u00eate les requ\u00eates en cours ordonn\u00e9es par \u00e2ge en excluant la requ\u00eate de requ\u00eate","text":"<pre><code>SELECT pid, age(query_start, clock_timestamp()), usename, query FROM pg_stat_activity WHERE query != '&lt;IDLE&gt;' AND query NOT ILIKE '%pg_stat_activity%' AND query NOT ILIKE '%SET extra%' ORDER BY query_start asc;\n</code></pre>","tags":["server","linux","db","cli"]},{"location":"SQL/PostgreSQL/#tuer-une-requete-en-cours","title":"Tuer une requ\u00eate en cours","text":"<pre><code>select pg_terminate_backend (N\u00b0 requ\u00eate);\n</code></pre>","tags":["server","linux","db","cli"]},{"location":"Systemd/Mount_Shares/","title":"Mount via Systemd Units","text":"<p>Si vous connectez des partages r\u00e9seau NFS ou CIFS (Samba) via une connexion Wi-Fi g\u00e9r\u00e9e par Network-Manager, vous avez peut-\u00eatre constat\u00e9 qu\u2019\u00e0 l\u2019extinction de votre machine, le d\u00e9montage du partage ne se fait pas correctement et bloque l\u2019arr\u00eat durant un certain laps de temps (g\u00e9n\u00e9ralement 1min30). Ceci est d\u00fb au fait que l\u2019acc\u00e8s au r\u00e9seau Wi-Fi est stopp\u00e9 avant le d\u00e9montage propre du partage.</p> <p>C\u2019est un probl\u00e8me qui m\u2019a emb\u00eat\u00e9 de temps en temps \u00e0 la maison, voici une parade simple. Elle consiste \u00e0 cr\u00e9er un service systemd qui ne fait rien en d\u00e9marrant mais force le d\u00e9montage des partages lorsque vous fermez votre session (d\u00e9connexion ou arr\u00eat/red\u00e9marrage de la machine).</p> <p>Il faut cr\u00e9er le fichier <code>/etc/systemd/system/umount-shares.service</code> avec le contenu suivant :</p> <pre><code># /etc/systemd/system/umount_nfs.servic e\n[Unit]\nDescription=Force umount NFS shares\nBefore=network.target graphical.target\n\n[Service]\nType=oneshot\nRemainAfterExit=yes\nExecStart=/bin/true\nExecStop=/usr/bin/umount -a -f -t nfs,nfs4,cifs\n\n[Install]\nWantedBy=default.target\n\nPuis l'activer et le d\u00e9marrer :\n\nsystemctl enable umount-shares.service\nsystemctl start umount-shares.service\n</code></pre> <p>Ainsi plus d\u2019arr\u00eat qui attend dans le vide un stop job for xxx parce qu\u2019un partage r\u00e9seau ne peut se d\u00e9monter.</p>"},{"location":"Virt/Libvirt_cert/","title":"How to generate and use a cert for Libvirt","text":"<pre><code>#!/bin/bash\n\nSERVER_KEY=server-key.pem\n\n# creating a key for our ca\nif [ ! -e ca-key.pem ]; then\nopenssl genrsa -des3 -out ca-key.pem 1024\nfi\n# creating a ca\nif [ ! -e ca-cert.pem ]; then\nopenssl req -new -x509 -days 1095 -key ca-key.pem -out ca-cert.pem  -subj \"/C=IL/L=Raanana/O=Red Hat/CN=my CA\"\nfi\n# create server key\nif [ ! -e $SERVER_KEY ]; then\nopenssl genrsa -out $SERVER_KEY 1024\nfi\n# create a certificate signing request (csr)\nif [ ! -e server-key.csr ]; then\nopenssl req -new -key $SERVER_KEY -out server-key.csr -subj \"/C=IL/L=Raanana/O=Red Hat/CN=my server\"\nfi\n# signing our server certificate with this ca\nif [ ! -e server-cert.pem ]; then\nopenssl x509 -req -days 1095 -in server-key.csr -CA ca-cert.pem -CAkey ca-key.pem -set_serial 01 -out server-cert.pem\nfi\n\n# now create a key that doesn't require a passphrase\nopenssl rsa -in $SERVER_KEY -out $SERVER_KEY.insecure\nmv $SERVER_KEY $SERVER_KEY.secure\nmv $SERVER_KEY.insecure $SERVER_KEY\n\n# show the results (no other effect)\nopenssl rsa -noout -text -in $SERVER_KEY\nopenssl rsa -noout -text -in ca-key.pem\nopenssl req -noout -text -in server-key.csr\nopenssl x509 -noout -text -in server-cert.pem\nopenssl x509 -noout -text -in ca-cert.pem\n\n# copy *.pem file to /etc/pki/libvirt-spice\nif [[ ! -d \"/etc/pki/libvirt-spice\" ]] \nthen\nmkdir -p /etc/pki/libvirt-spice\nfi\ncp ./*.pem /etc/pki/libvirt-spice\n\n# echo --host-subject\necho \"your --host-subject is\" \\\"`openssl x509 -noout -text -in server-cert.pem | grep Subject: | cut -f 10- -d \" \"`\\\"\n\necho \"copy ca-cert.pem to %APPDATA%\\spicec\\spice_truststore.pem or ~/.spice/spice_truststore.pem in your clients\"\n</code></pre>","tags":["linux","server"]},{"location":"Virt/Qemu_mount_image/","title":"Mounting a QEMU Image","text":"<p>In order to mount a QUMU / KVM disk image you need to use qemu-nbd, which lets you use the NBD protocol to share the disk image on the network.</p> <p>First you need the module loaded:</p> <pre><code>sudo modprobe nbd max_part=8\n</code></pre> <p>Then you can share the disk on the network and create the device entries:</p> <pre><code>sudo qemu-nbd --connect=/dev/nbd0 file.qcow2\n</code></pre> <p>Then you mount it:</p> <pre><code>sudo mount /dev/nbd0p1 /mnt/kvm\n</code></pre> <p>When done, unmount and unshare it:</p> <pre><code>sudo umount /mnt/kvm\nsudo nbd-client -d /dev/nbd0\n</code></pre>","tags":["virt","system","qemu","filesystem"]},{"location":"Virt/Sparse_file_copy/","title":"Copier un fichier sparse sur le r\u00e9seau","text":"<p>Les fichiers dits \u00ab sparse \u00bb sont allou\u00e9s avec une taille sup\u00e9rieur \u00e0 la taille r\u00e9ellement occup\u00e9e sur le disque dur. Cela permet de n\u2019occuper l\u2019espace disque que si le fichier fait face \u00e0 un accroissement. On les rencontre couramment en virtualisation o\u00f9 l\u2019on parle aussi de \u00ab thin provisioning \u00bb.</p> <p>Le terme \u00ab sparse \u00bb se traduit par \u00ab clairsem\u00e9 \u00bb en fran\u00e7ais et \u00ab thin provisionning \u00bb par \u00ab provisionnement all\u00e9g\u00e9 \u00bb.</p> <p>Avec rsync et l\u2019option -S ou \u2013sparse permet de respecter le caract\u00e8re \u00ab sparse \u00bb du fichier qui ne prendra pas plus de place disque sur la source que sur la cible. Cependant l\u2019utilisation de cette option a un inconv\u00e9nient : la taille d\u2019allocation totale transite par le r\u00e9seau, ce qui est peu efficient.</p> <p>Pour \u00e9viter ce d\u00e9sagr\u00e9ment on peut faire appel \u00e0 une archive tar en mode sparse (-S). Le fichier obtenu peut ainsi \u00eatre transf\u00e9r\u00e9 via n\u2019importe quel protocole pour \u00eatre d\u00e9-tar\u00e9 sur place.</p> <pre><code>tar Scvf image.qcow2.tar image.qcow2\nrsync image.qcow2.tar serveur-cible:/chemin/\n\ntar Scvf image.qcow2.tar image.qcow2\nrsync image.qcow2.tar serveur-cible:/chemin/\n</code></pre> <p>Une variante consiste \u00e0 utiliser tar en mode flux avec un pipe comme indiqu\u00e9 sur cette page \u00ab How to copy sparse files faster\u00ab .</p> <pre><code>tar cvzSpf \u2013 image.qcow2 | ssh user@serveur-distant \u2018(cd /tmp; tar xzSpf -)\u2019\n\ntar cvzSpf \u2013 image.qcow2 | ssh user@serveur-distant \u2018(cd /tmp; tar xzSpf -)\u2019\n</code></pre> <p>L\u2019utilisation de tar conjointement avec SSH est une bonne id\u00e9e afin de b\u00e9n\u00e9ficier de l\u2019option sparse, mais aussi pour remplir les trames r\u00e9seau et acc\u00e9l\u00e9rer les \u00e9changes par rapport \u00e0 rsync, en particulier en cas de petits fichiers. Voir diff\u00e9rent exemples ici ou encore celui qui suit.</p> <pre><code>tar -cS /dossier | ssh serveur-distant 'tar -xvf - -C /destination/'\ntar -cS /dossier | ssh serveur-distant 'tar -xvf - -C /destination/'\n</code></pre>","tags":["qemu","server","linux","fs"]},{"location":"Virt/Virt-Manager/","title":"Virt Manager","text":"","tags":["server","virt"]},{"location":"Virt/Virt-Manager/#virt-manager-tricks","title":"Virt-Manager tricks","text":"","tags":["server","virt"]},{"location":"Virt/Virt-Manager/#usb-redirection","title":"USB Redirection","text":"<ul> <li> <p>ACL Error :</p> <p>chmod u+s /usr/bin/spice-client-glib-usb-acl-helper</p> </li> <li> <p>No root password asked :</p> <p>/usr/share/polkit-1/actions/org.spice-spice.lowlevelusbaccess.policy.</p> </li> </ul> <p>Before changes I had follow</p> <pre><code>&lt;allow_any&gt;auth_admin&lt;/allow_any&gt;\n&lt;allow_inactive&gt;no&lt;/allow_inactive&gt;\n&lt;allow_active&gt;auth_admin&lt;/allow_active&gt;\n</code></pre> <p>After I have</p> <pre><code>&lt;allow_any&gt;yes&lt;/allow_any&gt;\n&lt;allow_inactive&gt;no&lt;/allow_inactive&gt;\n&lt;allow_active&gt;yes&lt;/allow_active&gt;\n</code></pre>","tags":["server","virt"]},{"location":"Web/Nginx/","title":"Nginx","text":"","tags":["web"]},{"location":"Web/Nginx/#list-served-sites","title":"List served sites","text":"<pre><code>grep server_name /etc/nginx/sites-enabled/* -RiI | column -t\n</code></pre>","tags":["web"]},{"location":"Web/Apache/LetsEncrypt/","title":"LetsEncrypt","text":"<p>Use LetsEncrypt with <code>webroot</code> and Apache2</p> <p><code>/etc/apache2/conf-available/le.conf</code></p> <pre><code>Alias /.well-known/acme-challenge/ \"/var/www/html/.well-known/acme-challenge/\"\n&lt;Directory \"/var/www/html/\"&gt;\n    AllowOverride None\n    Options MultiViews Indexes SymLinksIfOwnerMatch IncludesNoExec\n    Require method GET POST OPTIONS\n&lt;/Directory&gt;\n</code></pre> <p><code>a2enconf le</code></p> <p>Then use Certbot with the following option <code>--webroot --webroot-path /var/www/html</code></p>"},{"location":"Web/Apache/Mapping/","title":"Create an redirection mapping","text":"<pre><code>httxt2dbm -i url-communication.txt -o url-communication.map\n</code></pre>","tags":["apache"]},{"location":"Web/Apache/Redirection/","title":"Redirections Apache","text":""},{"location":"Web/Apache/Redirection/#http-https","title":"HTTP =&gt; HTTPS","text":"<pre><code>RewriteEngine On\nRewriteCond %{HTTPS} !=on\nRewriteRule ^/?(.*) https://%{SERVER_NAME}/$1 [R,L]\n</code></pre>"},{"location":"Web/Apache/Redirection/#pour-un-domaine-specifique","title":"Pour un domaine sp\u00e9cifique","text":"<pre><code>&lt;If \"%{HTTP_HOST} = 'www.example.com'\"&gt;\n    Redirect \"/\" \"http://www.new-example.com/\"\n&lt;/If&gt;\n</code></pre>"},{"location":"Web/HAProxy/Keepalived_VRRP_Config/","title":"Keepalived VRRP Config","text":"","tags":["haproxy","server"]},{"location":"Web/HAProxy/Keepalived_VRRP_Config/#config-for-vrpp-between-2-haproxies-with-keepalived","title":"Config for VRPP between 2 HAProxies with keepalived","text":"","tags":["haproxy","server"]},{"location":"Web/HAProxy/Keepalived_VRRP_Config/#assumptions","title":"Assumptions","text":"<ul> <li>This works on Ubuntu 14.04</li> <li>haproxy-primary IP: 198.51.100.10</li> <li>haproxy-secondary IP: 198.51.100.20</li> <li>shared IP: 198.51.100.50</li> <li>Any DNS rules should point to the shared IP (198.51.100.50)</li> </ul>","tags":["haproxy","server"]},{"location":"Web/HAProxy/Keepalived_VRRP_Config/#steps","title":"Steps","text":"<ul> <li> <p>Add a firewall rule for keepalived # 224.0.0.18 is the keepalived multicast address</p> <pre><code>sudo ufw allow in from 198.51.100.20 to 224.0.0.18 # on 198.51.100.10\nsudo ufw allow in from 198.51.100.10 to 224.0.0.18 # on 198.51.100.20\n</code></pre> </li> <li> <p>Allow access to a shared IP address</p> <pre><code>edit /etc/sysctl.conf\nset net.ipv4.ip_nonlocal_bind=1\nsudo sysctl -p # reload config change\n</code></pre> </li> <li> <p>Install keepalived</p> <pre><code>sudo apt-get install keepalived\n</code></pre> </li> <li> <p>Configure keepalived on both servers</p> <pre><code>Edit/create /etc/keepalived/keepalived.conf\nSee example file below # the priority MUST be different on the primary and secondary servers!\n</code></pre> </li> <li> <p>Restart keepalived</p> <pre><code>sudo service keepalived restart\n</code></pre> </li> <li> <p>Listen on the shared IP address</p> <pre><code>Edit /etc/haproxy/haproxy.cfg\nbind 198.51.100.50:80\n</code></pre> </li> <li> <p>Restart haproxy (on both haproxy servers)</p> <pre><code>sudo service haproxy restart\n</code></pre> </li> <li> <p>Verify proper failover</p> <pre><code>primary: sudo ip addr show | grep eth0 # should list the shared IP\nsecondary: sudo ip addr show | grep eth0 # should NOT list the shared IP\nprimary: sudo service haproxy stop\nprimary: sudo ip addr show | grep eth0 # should NOT list the shared IP\nsecondary: sudo ip addr show | grep eth0 # should list the shared IP\nprimary: sudo service haproxy start\nprimary: sudo ip addr show | grep eth0 # should list the shared IP\nsecondary: sudo ip addr show | grep eth0 # should NOT list the shared IP\n</code></pre> </li> </ul> <pre><code>/etc/keepalived/keepalived.conf\n\nvrrp_script chk_haproxy {      # Requires keepalived-1.1.13\nscript \"killall -0 haproxy\"  # cheaper than pidof\ninterval 2 # check every 2 seconds\nweight 2 # add 2 points of priority if OK\n}\nvrrp_instance VI_1 {\ninterface eth0\nstate MASTER\nvirtual_router_id 51\npriority 101 # 101 on primary, 100 on secondary\nvirtual_ipaddress {\n    198.51.100.50\n}\ntrack_script {\n    chk_haproxy\n}\n}\n</code></pre>","tags":["haproxy","server"]},{"location":"Web/HAProxy/LDAP_configuration/","title":"LDAP configuration","text":"<pre><code>global\n  log           /dev/log local6\n  pidfile       /var/run/haproxy.pid\n  chroot        /var/lib/haproxy\n  maxconn       8192\n  user          haproxy\n  group         haproxy\n  daemon\n  stats socket /var/lib/haproxy/stats.socket mode 660 level admin\n\n  # Default SSL material locations\n  ca-base /etc/ssl/certs\n  crt-base /etc/ssl/private\n\n  # Default ciphers to use on SSL-enabled listening sockets.\n  # For more information, see ciphers(1SSL). This list is from:\n  #  https://hynek.me/articles/hardening-your-web-servers-ssl-ciphers/\n  ####ssl-default-bind-ciphers ECDH+AESGCM:DH+AESGCM:ECDH+AES256:DH+AES256:ECDH+AES128:DH+AES:ECDH+3DES:DH+3DES:RSA+AESGCM:RSA+AES:RSA+3DES:!aNULL:!MD5:!DSS\n  ####ssl-default-bind-options no-sslv3\n\n  ####tune.ssl.default-dh-param 2048\n\n# LDAP and LDAP/STARTTLS\nfrontend ldap_service_front\n  mode                  tcp\n  log                   global\n  bind                  ldap.company.com:389\n  description           LDAP Service\n  option                tcplog\n  option                logasap\n  option                socket-stats\n  option                tcpka\n  timeout client        5s\n  default_backend       ldap_service_back\n\nbackend ldap_service_back\n  server                ldap-1 ad-dc01.company.com:389 check fall 1 rise 1 inter 2s\n  server                ldap-2 ad-dc02.company.com:389 check fall 1 rise 1 inter 2s\n  server                ldap-3 ad-dc03.company.com:389 check fall 1 rise 1 inter 2s\n  mode                  tcp\n  balance               leastconn\n  timeout server        2s\n  timeout connect       1s\n  option                tcpka\n  # https://www.mail-archive.com/haproxy@formilux.org/msg17371.html\n  option                tcp-check\n  tcp-check             connect port 389\n  tcp-check             send-binary 300c0201            # LDAP bind request \"&lt;ROOT&gt;\" simple\n  tcp-check             send-binary 01                  # message ID\n  tcp-check             send-binary 6007                # protocol Op\n  tcp-check             send-binary 0201                # bind request\n  tcp-check             send-binary 03                  # LDAP v3\n  tcp-check             send-binary 04008000            # name, simple authentication\n  tcp-check             expect binary 0a0100            # bind response + result code: success\n  tcp-check             send-binary 30050201034200      # unbind request\n\n# LDAPS\nfrontend ldapS_service_front\n  mode                  tcp\n  log                   global\n  bind                  ldap.company.com:636 ssl crt /etc/ssl/private/ldap_company_com.PEM\n  description           LDAPS Service\n  option                tcplog\n  option                logasap\n  option                socket-stats\n  option                tcpka\n  timeout client        5s\n  default_backend       ldaps_service_back\n\nbackend ldaps_service_back\n  server                ldapS-1 ad-dc01.company.com:636 check fall 1 rise 1 inter 2s verify none check check-ssl\n  server                ldapS-2 ad-dc02.company.com:636 check fall 1 rise 1 inter 2s verify none check check-ssl\n  server                ldapS-3 ad-dc03.company.com:636 check fall 1 rise 1 inter 2s verify none check check-ssl\n  mode                  tcp\n  balance               leastconn\n  timeout server        2s\n  timeout connect       1s\n  option                tcpka\n  #\n  option                tcp-check\n  tcp-check             connect port 636 ssl\n  tcp-check             send-binary 300c0201            # LDAP bind request \"&lt;ROOT&gt;\" simple\n  tcp-check             send-binary 01                  # message ID\n  tcp-check             send-binary 6007                # protocol Op\n  tcp-check             send-binary 0201                # bind request\n  tcp-check             send-binary 03                  # LDAP v3\n  tcp-check             send-binary 04008000            # name, simple authentication\n  tcp-check             expect binary 0a0100            # bind response + result code: success\n  tcp-check             send-binary 30050201034200      # unbind request\n</code></pre>","tags":["web","proxy","config"]}]}